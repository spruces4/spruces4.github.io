<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title></title>
        <link>undefined</link>
        <description>undefined</description>
        <lastBuildDate>Sun, 26 May 2024 14:52:39 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>Joplin Pages Publisher</generator>
        <item>
            <title><![CDATA[第六周作业]]></title>
            <guid>74ca6fa230ca4e5fbc649b002abdf83b</guid>
            <pubDate>Sun, 26 May 2024 14:44:40 GMT</pubDate>
            <content:encoded><![CDATA[<nav class="table-of-contents"><ul><li><a href="#mongodb">mongoDB</a><ul><li><a href="#复制集">复制集</a></li><li><a href="#原理">原理</a><ul><li><a href="#基本信息">基本信息</a></li><li><a href="#选举方式">选举方式</a></li><li><a href="#故障自恢复">故障自恢复</a></li><li><a href="#请求模式">请求模式</a></li></ul></li><li><a href="#案例操作">案例操作</a></li><li><a href="#管理操作">管理操作</a><ul><li><a href="#节点管理">节点管理</a></li><li><a href="#特殊节点管理">特殊节点管理</a></li><li><a href="#主节点降级">主节点降级</a></li><li><a href="#开启从库读取">开启从库读取</a></li></ul></li></ul></li><li><a href="#zookeeper">zookeeper</a><ul><li><a href="#集群架构">集群架构</a></li><li><a href="#集群角色">集群角色</a></li><li><a href="#选举过程">选举过程</a></li><li><a href="#事务日志与快照">事务日志与快照</a></li><li><a href="#环境要求">环境要求</a></li><li><a href="#集群部署">集群部署</a><ul><li><a href="#集群安装">集群安装</a></li><li><a href="#日志检查">日志检查</a></li><li><a href="#端口检查">端口检查</a></li><li><a href="#状态检查">状态检查</a></li></ul></li><li><a href="#命令行访问">命令行访问</a></li><li><a href="#gui访问">GUI访问</a></li><li><a href="#python-sdk访问">python SDK访问</a></li></ul></li><li><a href="#kafka">kafka</a><ul><li><a href="#消息队列">消息队列</a></li><li><a href="#简介">简介</a></li><li><a href="#角色流程">角色流程</a><ul><li><a href="#角色">角色</a></li><li><a href="#流程">流程</a></li></ul></li><li><a href="#部署">部署</a></li><li><a href="#检查">检查</a></li></ul></li></ul></nav><h1 id="mongodb">mongoDB</h1>
<h2 id="复制集">复制集</h2>
<blockquote>
<p>在 <code>MondDB</code> 的主从复制集架构中:<br />
!!! warning 复制集的职能</p>
</blockquote>
<ul>
<li><strong>数据冗余</strong>：MongoDB复制集通过在多个服务器间自动复制数据实现数据冗余，适用于需要数据备份和灾难恢复的场景。</li>
<li><strong>高可用性</strong>：MongoDB复制集通过在主节点故障时自动切换到副本节点确保高可用性，适用于需要无中断服务的生产环境。</li>
<li><strong>自动故障切换</strong>：MongoDB复制集在检测到主节点故障时自动将副本节点提升为主节点，实现快速故障恢复，适用于需要高可靠性的应用程序。<br />
!!!</li>
</ul>
<h2 id="原理">原理</h2>
<h3 id="基本信息">基本信息</h3>
<ul>
<li>主从关系
<ul>
<li>仅有<code>一个主节点</code>，其余<code>都是从节点</code></li>
<li>只有主节点能够<code>写入/读取</code></li>
<li>从节点能<code>读取数据</code>，但默认只有<code>主节点负责处理请求</code></li>
</ul>
</li>
<li>常见架构
<ul>
<li>一主一从</li>
<li>一主二从</li>
</ul>
</li>
<li>复制本质
<ul>
<li>所有的操作都有<code>oplog</code>，从节点定期轮询主节点<code>获取这些操作</code>，然后对自己的数据副本<code>执行这些操作</code>。</li>
</ul>
</li>
<li>主要特征
<ul>
<li>N 个<code>奇数节点</code>的集群</li>
<li>基于选举机制，<code>任何节点可作为主节点</code></li>
<li>所有写入操作都在主节点上，所以增加节点<code>不会提高系统写性能</code>，可以<code>提升读性能</code></li>
<li>主节点故障时，会<code>自动选举出新节点代替</code>，<code>自动故障转移</code></li>
</ul>
</li>
</ul>
<h3 id="选举方式">选举方式</h3>
<blockquote>
<p>选举算法：<code>Raft</code></p>
</blockquote>
<p>!!! info 角色与操作</p>
<ul>
<li>主节点 Master
<ul>
<li>数量：1</li>
<li>作用：
<ul>
<li>默认回应<code>读写请求</code></li>
<li>与<code>副本节点</code>通信同步操作，同步存活信息</li>
</ul>
</li>
<li>失效后：
<ul>
<li>触发选举执行</li>
</ul>
</li>
</ul>
</li>
<li>副本节点 Secondary
<ul>
<li>数量：N (无仲裁者下 N+1 应为奇数)
<ul>
<li>最多只能有<code>7个节点有选举权</code>，但副本可大于该数值</li>
<li><img src="/_resources/72ce64e9f8804fa9b1f5b5e26a0e6451.png" /></li>
</ul>
</li>
<li>作用：
<ul>
<li>执行主节点下发操作，维护副本数据</li>
<li>当主节点故障时，触发选举选定下一个<code>Master</code></li>
</ul>
</li>
<li>失效后：
<ul>
<li>不被关心</li>
</ul>
</li>
</ul>
</li>
<li>仲裁者 Arbiter
<ul>
<li>数量：M (M+N+1 应为奇数)</li>
<li>作用：
<ul>
<li>仅参与选主投票</li>
<li>不保存数据</li>
</ul>
</li>
<li>失效后：
<ul>
<li>不被关心<br />
!!!</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>!!! success 选举流程</p>
<ol>
<li>具有投票权的节点之间两两互相发送心跳</li>
<li>当<code>5次心跳</code>未收到时判断为节点失联</li>
<li>如果失联的是主节点，从节点会发起选举，选出新的主节点</li>
<li>如果失联的是从节点则不会产生新的选举</li>
<li>选举基于RAFT一致性算法实现，选举成功的必要条件是大多数投票节点存活</li>
<li>复制集中最多可以有50个节点，但具有投票权的节点最多7个，且为奇数个投票成员<br />
!!!</li>
</ol>
<p>!!! warning priority0 节点</p>
<ul>
<li>图解
<ul>
<li><img src="/_resources/7c1319130e6a4081b22e3b98fb163628.png" /></li>
</ul>
</li>
<li>说明
<ul>
<li>默认Priority为1，值最大优先级越高。</li>
<li>设置Priority为0节点的选举优先级为0，<code>不会被选举为Primary</code>，但可以投票</li>
</ul>
</li>
<li>身份特征
<ul>
<li><code>priority:0</code></li>
</ul>
</li>
<li>常见场景
<ul>
<li>跨机房A、B部署了一个复制集，并且希望 <code>Primary</code> 必须在 A机房；这时可以将B机房的复制集成员Priority设置为0<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! warning hidden 节点</p>
<ul>
<li>图解
<ul>
<li><img src="/_resources/56d623daf4cb416a8c5c4b54e8b75de3.png" /></li>
</ul>
</li>
<li>说明
<ul>
<li>不接受<code>Driver</code>的请求</li>
<li><code>不参与选主</code>，也<code>不对外提供服务</code>。</li>
</ul>
</li>
<li>身份特征
<ul>
<li>priority:0</li>
<li><code>hiddent: true</code></li>
</ul>
</li>
<li>常见场景
<ul>
<li>做一些数据备份、离线计算的任务，不会影响复制集的服务<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! warning Delayed 节点</p>
<ul>
<li>图解
<ul>
<li><img src="/_resources/183768eff74642f59a002bce7c6a3589.png" /></li>
</ul>
</li>
<li>说明
<ul>
<li>Delayed节点必须是Hidden节点，并且其数据落后与Primary一段时间</li>
<li><code>不应该提供服务或参与选主</code></li>
</ul>
</li>
<li>身份特征
<ul>
<li>priority: 0</li>
<li>hidden: ture</li>
<li><code>slaveDelay: 3600</code></li>
</ul>
</li>
<li>常见场景
<ul>
<li>延时节点的数据集是延时的，因此它可以帮助我们在人为<code>误操作或是其他意外情况下恢复数据</code>。</li>
<li>当应用升级失败，或是误操作删除了表和数据库时，可以通过延时节点进行数据恢复<br />
!!!</li>
</ul>
</li>
</ul>
<h3 id="故障自恢复">故障自恢复</h3>
<p><img src="/_resources/ec2921b2284a496ea341509e5e8dc79e.png" /></p>
<ol>
<li><code>Master</code> 发生故障</li>
<li>复制集内部会进行投票选举</li>
<li>一个<code>Secondary</code>替代原有主库对外提供服务</li>
<li>复制集会自动通知客户端程序主库已切换</li>
<li>应用就会连接到新的主库</li>
</ol>
<h3 id="请求模式">请求模式</h3>
<blockquote>
<p>默认情况下，应用程序将其读取操作指向复制集的主节点<br />
但是，客户端可以通过<code>read preference</code> 模式指定将读取操作发送给到从节点</p>
</blockquote>
<table>
<thead>
<tr>
<th>Read Preference Mode</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>primary</td>
<td>主节点，默认模式，读操作只在主节点，如果主节点不可用，报错或者抛出异常。</td>
</tr>
<tr>
<td>primaryPreferred</td>
<td>首选主节点，大多情况下读操作在主节点，如果主节点不可用，如故障转移，读操作在从节点。</td>
</tr>
<tr>
<td>secondary</td>
<td>从节点，读操作只在从节点， 如果从节点不可用，报错或者抛出异常。</td>
</tr>
<tr>
<td>secondaryPreferred</td>
<td>首选从节点，大多情况下读操作在从节点，特殊情况（如单主节点架构）读操作在主节点。</td>
</tr>
<tr>
<td>nearest</td>
<td>最邻近节点，读操作在最邻近的成员，可能是主节点或者从节点。</td>
</tr>
</tbody>
</table>
<h2 id="案例操作">案例操作</h2>
<ol>
<li>安装<code>mongodb</code></li>
</ol>
<div><pre class="hljs"><code><span class="hljs-comment"># 关闭防火墙和SELinux</span>
setenforce 0
systemctl stop firewalld

<span class="hljs-comment"># 调整内核HPG</span>
cat &gt;&gt; /etc/rc.local &lt;&lt;<span class="hljs-string">EOF
echo never &gt; /sys/kernel/mm/transparent hugepage/enabled
EOF</span>
chmod a+x /etc/rc.local

<span class="hljs-comment"># 创建用户</span>
useradd mongod

<span class="hljs-comment"># 创建目录</span>
mkdir -p /mongodb/{conf,data,<span class="hljs-built_in">log</span>}

<span class="hljs-comment"># 创建配置文件</span>
cat &gt; /mongodb/conf/mongo.conf &lt;&lt;<span class="hljs-string">EOF
systemLog:
  destination: file
  path: /mongodb/log/mongodb.log
  logAppend: true
storage:
  dbPath: /mongodb/data/
processManagement:
  timeZoneInfo: /usr/share/zoneinfo
  fork : true
net:
  port: 27017
  bindIp: 0.0.0.0
security:
  authorization: disabled
replication:
  replSetName: alfieRepl
EOF</span>

<span class="hljs-comment"># 下载源代码</span>
wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel80-7.0.11.tgz

<span class="hljs-comment"># 解压包</span>
tar xf mongodb-linux-x86_64-rhel80-7.0.11.tgz -C /usr/<span class="hljs-built_in">local</span>
ln -s /usr/<span class="hljs-built_in">local</span>/mongodb-linux-x86_64-rhel80-7.0.11/ /usr/<span class="hljs-built_in">local</span>/mongodb

<span class="hljs-comment"># 设置PATH变量</span>
<span class="hljs-built_in">echo</span> PATH=/usr/<span class="hljs-built_in">local</span>/mongodb/bin/:<span class="hljs-string">'$PATH'</span> &gt; /etc/profile.d/mongodb.sh
. /etc/profile.d/mongodb.sh

<span class="hljs-comment"># systemd管理文件</span>
cat &gt; /lib/systemd/system/mongod.service &lt;&lt;<span class="hljs-string">EOF
[Unit]
Description=mongodb
After=network.target remote-fs.target nss-lookup.target

[Service]
Type=forking
User=mongod
Group=mongod
ExecStart=/usr/local/mongodb/bin/mongod --config /mongodb/conf/mongo.conf
ExecReload=/bin/kill -s HUP \$MAINPID
ExecStop=/usr/local/mongodb/bin/mongod --config /mongodb/conf/mongo.conf -- shutdown
PrivateTmp=true
LimitFSIZE=infinity
LimitCPU=infinity
LimitAS=infinity
LimitNOFILE=64000
LimitNPROC=64000
LimitMEMLOCK=infinity
TasksMax=infinity
TasksAccounting=false

[Install]
WantedBy=multi-user.target
EOF</span>

<span class="hljs-comment"># 文件归属修改</span>
chown -R mongod:mongod /usr/<span class="hljs-built_in">local</span>/mongodb/
chown -R mongod:mongod /mongodb/

<span class="hljs-comment"># 启动服务</span>
systemctl daemon-reload
systemctl <span class="hljs-built_in">enable</span> --now mongod.service</code></pre></div>
<ol start="2">
<li>配置一主二从</li>
</ol>
<div><pre class="hljs"><code>mongo --port <span class="hljs-number">27017</span> admin

config = { <span class="hljs-attr">_id</span>: <span class="hljs-string">'alfieRepl'</span>, <span class="hljs-attr">members</span>: [
{<span class="hljs-attr">_id</span>: <span class="hljs-number">0</span>, <span class="hljs-attr">host</span>: <span class="hljs-string">'192.168.100.101:27017'</span>},
{<span class="hljs-attr">_id</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">host</span>: <span class="hljs-string">'192.168.100.102:27017'</span>} ,
{<span class="hljs-attr">_id</span>: <span class="hljs-number">2</span>, <span class="hljs-attr">host</span>: <span class="hljs-string">'192.168.100.103:27017'</span>}]
}

<span class="hljs-title function_">printjson</span>(config)

rs.<span class="hljs-title function_">initiate</span>(config)

&gt;&gt; <span class="hljs-variable constant_">OR</span>
rs.<span class="hljs-property">initiate</span> ( )
rs.<span class="hljs-title function_">add</span>(<span class="hljs-string">"ip.ip.ip.ip:port"</span>)
...</code></pre></div>
<p><img src="/_resources/b4f1e19c839c43c78cf72e279de042cc.png" /></p>
<ol start="3">
<li>配置一主一从一仲裁</li>
</ol>
<div><pre class="hljs"><code>config = { <span class="hljs-attr">_id</span>: <span class="hljs-string">'alfieRepl'</span>, <span class="hljs-attr">members</span>: [
{<span class="hljs-attr">_id</span>: <span class="hljs-number">0</span>, <span class="hljs-attr">host</span>: <span class="hljs-string">'192.168.100.101:27017'</span>},
{<span class="hljs-attr">_id</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">host</span>: <span class="hljs-string">'192.168.100.102:27017'</span>} ,
{<span class="hljs-attr">_id</span>: <span class="hljs-number">2</span>, <span class="hljs-attr">host</span>: <span class="hljs-string">'192.168.100.103:27017'</span>, <span class="hljs-string">"arbiterOnly"</span>: <span class="hljs-literal">true</span>}]
}

rs.<span class="hljs-title function_">initiate</span>(config)</code></pre></div>
<ol start="4">
<li>复制集状态</li>
</ol>
<ul>
<li>rs.hello() // 常规信息<br />
<img src="/_resources/a6792e56d18b45e1ada3a4058f93e9a6.png" /></li>
<li>rs.isMaster() // 查主<br />
<img src="/_resources/345d1c628c36465996b9481c6b40aef9.png" /></li>
<li>rs.config() // 配置信息<br />
<img src="/_resources/f18346fbb47341f79f2fb5a499affb3b.png" /></li>
<li>rs.printSecondaryReplicationInfo()<br />
<img src="/_resources/37184b37ea1a48b08e900d29a4ceaba7.png" /></li>
<li>db.printReplicationInfo()<br />
<img src="/_resources/68917025db9f43c9adda24eabe68a098.png" /></li>
</ul>
<h2 id="管理操作">管理操作</h2>
<h3 id="节点管理">节点管理</h3>
<ul>
<li>
<p>rs.remove ("ip: port") // 删除节点</p>
<ul>
<li><img src="/_resources/0ad7c2cdce914ad1b1b3540645177586.png" /></li>
<li><img src="/_resources/332daf88a12843258e35353d30000530.png" /></li>
</ul>
</li>
<li>
<p>rs.add ("ip: port")  // 增加节点</p>
<ul>
<li><img src="/_resources/f4b52218c9cf4c868300f70f55a55788.png" /></li>
</ul>
</li>
<li>
<p>rs.addArb ("ip: port") // 增加arb节点</p>
<ul>
<li><img src="/_resources/93bf9ed9084f4eafa8de28a01140b34f.png" /></li>
<li><img src="/_resources/bf679885b4cc4b4686ee02650256940a.png" /></li>
</ul>
</li>
</ul>
<h3 id="特殊节点管理">特殊节点管理</h3>
<div><pre class="hljs"><code><span class="hljs-comment">// 获得当前复制集点配置</span>
config=rs.<span class="hljs-title function_">conf</span>()

<span class="hljs-comment">// 对节点属性进行修改</span>
<span class="hljs-comment">// 修改节点3为hidden节点</span>
config.<span class="hljs-property">members</span>[<span class="hljs-number">2</span>].<span class="hljs-property">hidden</span>=<span class="hljs-literal">true</span></code></pre></div>
<ul>
<li>config.members[2].hidden=true<br />
<img src="/_resources/599fa2af5faa462f9e72f855d8903ee6.png" /></li>
<li>从Hideen节点恢复为常规节点
<ul>
<li>config.members[2].hidden=false</li>
<li>config.members[2].arbiterOnly=false</li>
<li>config.members[2].priority=1<br />
<img src="/_resources/54cf876fcade4895b52acc3d5789fa42.png" /><br />
<img src="/_resources/88515e10c07745c49b98110362c5b5d7.png" /></li>
<li>由于与此前配置不同需要通过reconfig，删除再添加节点
<ul>
<li><img src="/_resources/3a1991e0a6354df09c71991f2d8ff5e7.png" /></li>
<li><img src="/_resources/d788a679190247cd8e30871f2ba6ecf5.png" /></li>
<li><img src="/_resources/d8cebb3092ab4ad580f1b5d3234217fe.png" /></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="主节点降级">主节点降级</h3>
<ul>
<li>rs.stepDown()<br />
<img src="/_resources/b5a7e7c4868443c1b5886cedfd8543ca.png" /></li>
</ul>
<h3 id="开启从库读取">开启从库读取</h3>
<div><pre class="hljs"><code>#打开从节点读支持
#<span class="hljs-number">7</span>版本命令
db.<span class="hljs-title function_">getMongo</span>().<span class="hljs-title function_">setReadPref</span>(<span class="hljs-string">'secondary'</span>)
db.<span class="hljs-title function_">getMongo</span>().<span class="hljs-title function_">getReadPref</span>()

#<span class="hljs-number">5</span>版命令
<span class="hljs-attr">myrepl</span>:<span class="hljs-variable constant_">SECONDARY</span>&gt; rs.<span class="hljs-title function_">secondaryOk</span>()

#旧版命令已废弃
<span class="hljs-attr">myrepl</span>:<span class="hljs-variable constant_">SECONDARY</span>&gt; rs.<span class="hljs-title function_">slaveOk</span>()</code></pre></div>
<ul>
<li>rs.secondaryOK() 已被抛弃<br />
<img src="/_resources/28bc4e8fcf5c45ffaa65931fe6dbb678.png" /></li>
<li>7版本的切换命令<br />
<img src="/_resources/c349465d57ff4d5bbca0d57b58b13685.png" /></li>
</ul>
<h1 id="zookeeper">zookeeper</h1>
<h2 id="集群架构">集群架构</h2>
<p><img src="/_resources/400aad1a64f241e78c73de1828640e8f.png" /></p>
<p>!!! tip 基本信息</p>
<ul>
<li>
<p>集群模型</p>
<ul>
<li>Master/Slave 模型</li>
</ul>
</li>
<li>
<p>Master</p>
<ul>
<li>负责写操作，同时被称为<code>Leader</code>节点</li>
</ul>
</li>
<li>
<p>Slave</p>
<ul>
<li>负责读操作，同时被称为<code>follower</code>节点</li>
</ul>
</li>
<li>
<p>写操作同步</p>
<ul>
<li>写操作由<code>Master</code>处理完成，再同步给<code>Slave</code>节点</li>
<li>当写操作大于半数节点时，<code>写操作</code>判定为成功</li>
</ul>
</li>
<li>
<p>可用性</p>
<ul>
<li>当 <code>可用节点 &gt; (总节点数/2) </code> 才认定 <code>zookeeper</code>系统可用</li>
</ul>
</li>
<li>
<p>性能</p>
<ul>
<li><img src="/_resources/459ac9e84f274c3197fac4e805f93678.png" /></li>
<li><code>增加服务器数量可以提高读请求处理能力</code>，但其效果在服务器数量增加时逐渐减弱。<br />
!!!</li>
</ul>
</li>
</ul>
<h2 id="集群角色">集群角色</h2>
<p><img src="/_resources/dc084b33ba0e413da44614440a9251bb.png" /></p>
<table>
<thead>
<tr>
<th>序号</th>
<th>状态</th>
<th>角色</th>
<th>职责描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>稳定状态</td>
<td>领导者(Leader)</td>
<td>负责处理写入请求的，事务请求的<code>唯一调度和处理者</code>,负责进行投票发起和决议，更新系统状态</td>
</tr>
<tr>
<td>2</td>
<td>稳定状态</td>
<td>跟随者(Follower)</td>
<td>接收客户请求并向客户端返回结果，在<code>选Leader过程中参与投票</code></td>
</tr>
<tr>
<td>3</td>
<td>稳定状态</td>
<td>观察者(Observer)</td>
<td>转交客户端写请求给leader节点，和同步leader状态。<br class="jop-noMdConv" /> 和Follower唯一区别就是<code>不参与Leader投票</code>,也<code>不参与写操作的"过半写成功"策略</code></td>
</tr>
<tr>
<td>4</td>
<td>中间状态</td>
<td>学习者(Learner)</td>
<td>和leader<code>进行状态同步的节点统称Learner</code>，包括:<code>Follower和Observer</code></td>
</tr>
<tr>
<td>5</td>
<td>NA</td>
<td>客户端(client)</td>
<td>请求发起方</td>
</tr>
</tbody>
</table>
<h2 id="选举过程">选举过程</h2>
<p>!!! info 选举状态和依据</p>
<ul>
<li>状态
<ul>
<li><code>LOOKING</code>：寻找 <code>Leader</code> 状态，处于该状态需要进入选举流程</li>
<li><code>LEADING</code>：领导者状态，处于该状态的节点说明是角色已经是 <code>Leader</code></li>
<li><code>FOLLOWING</code>：跟随者状态，表示 <code>Leader</code> 已经选举出来，当前节点角色是 <code>follower</code></li>
<li><code>OBSERVER</code>：观察者状态，表明当前节点角色是 <code>observer</code></li>
</ul>
</li>
<li>依据
<ul>
<li><code>zxid</code>的优先级高于<code>myid</code>，<code>zxid相同时</code>比较<code>myid</code>大小</li>
<li><code>zxid</code> (zookeeper transaction id):
<ul>
<li>产生方式：代表了该服务器处理的<code>最后一个事务的ID</code></li>
<li>值含义：值越大表示它的<code>数据最完整</code>，<code>最新</code></li>
<li><code>zxid</code> 最大的节点优先选为 <code>Leader</code></li>
</ul>
</li>
<li><code>myid</code> 服务器的唯一标识(SID):
<ul>
<li>产生方式：通过配置 <code>myid 文件指定</code></li>
<li>值含义：没特定意义，常用于<code>人为操作选举</code></li>
<li><code>myid</code> 最大的节点优先选为 <code>Leader</code><br />
!!!</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>!!! success 首次选举<br />
0. 配置文件会决定有选举权限的 zookeeper 节点</p>
<ol>
<li>每个zookeeper 的投票中都会<code>包含自己的myid和zxid</code></li>
<li>每个节点接受并检查对方的投票信息，比如投票时间、是否状态为<code>LOOKING状态的投票</code></li>
<li>对比投票，优先检查zxid，如果zxid 不一样则 zxid 大的为leader</li>
<li>如果zxid相同则继续对比myid，myid 大的一方为 leader</li>
</ol>

				<div>
					
					<pre class="mermaid">sequenceDiagram
    participant ZK1 as ZooKeeper 1 &lt;br&gt;(myid=1, zxid=0x0)
    participant ZK2 as ZooKeeper 2 &lt;br&gt;(myid=2, zxid=0x0)
    participant ZK3 as ZooKeeper 3 &lt;br&gt;(myid=3, zxid=0x0)
    
    ZK1-&gt;&gt;All: 发出投票 (myid=1, zxid=0x0)
    ZK2-&gt;&gt;All: 发出投票 (myid=2, zxid=0x0)
    ZK3-&gt;&gt;All: 发出投票 (myid=3, zxid=0x0)
    
    Note right of All: 每个节点接收并检查对方的投票
    
    alt 比较 zxid
        ZK1-&gt;&gt;ZK2: 检查投票 (zxid=0x0)
        ZK1-&gt;&gt;ZK3: 检查投票 (zxid=0x0)
        ZK2-&gt;&gt;ZK1: 检查投票 (zxid=0x0)
        ZK2-&gt;&gt;ZK3: 检查投票 (zxid=0x0)
        ZK3-&gt;&gt;ZK1: 检查投票 (zxid=0x0)
        ZK3-&gt;&gt;ZK2: 检查投票 (zxid=0x0)
        
        Note right of All: 所有 zxid 相同，比较 myid
    end
    
    alt 比较 myid
        ZK1-&gt;&gt;ZK2: 检查 myid (myid=1)
        ZK1-&gt;&gt;ZK3: 检查 myid (myid=1)
        ZK2-&gt;&gt;ZK1: 检查 myid (myid=2)
        ZK2-&gt;&gt;ZK3: 检查 myid (myid=2)
        ZK3-&gt;&gt;ZK1: 检查 myid (myid=3)
        ZK3-&gt;&gt;ZK2: 检查 myid (myid=3)
        
        Note right of All: ZK3 的 myid 最大，成为 leader
    end
    
    ZK1-&gt;&gt;ZK3: 选出 ZK3 作为 Leader
    ZK2-&gt;&gt;ZK3: 选出 ZK3 作为 Leader
    ZK3-&gt;&gt;All: 宣布成为 Leader

</pre>
				</div>
			<p>!!!</p>
<p>!!! warning 心跳保持</p>
<ul>
<li>保持方式
<ul>
<li>利用<code>ping</code>确认对方是否存活</li>
</ul>
</li>
<li>触发重新选举
<ul>
<li>当 <code>Leader无法响应PING</code> 时，将重新发起 Leader 选举</li>
</ul>
</li>
<li>Leader无法响应的原因
<ol>
<li>网络阻塞</li>
<li>网络中断</li>
<li>keepavlive程序故障</li>
<li>系统崩溃重启</li>
</ol>
</li>
</ul>

				<div>
					
					<pre class="mermaid">sequenceDiagram
    participant Leader
    participant Follower1
    participant Follower2
    
    Note right of Leader: Leader 定期发送心跳消息 (PING)
    Leader-&gt;&gt;Follower1: 发送 PING
    Leader-&gt;&gt;Follower2: 发送 PING
    
    Note right of Follower1: Follower1 返回心跳确认 (ACK)
    Follower1--&gt;&gt;Leader: 返回 ACK
    
    Note right of Follower2: Follower2 返回心跳确认 (ACK)
    Follower2--&gt;&gt;Leader: 返回 ACK
    
    Note right of Leader: Leader 检查心跳确认 (ACK)
    alt 超时未收到 ACK
        Note right of Leader: 标记 Follower 为失效
        Leader-&gt;&gt;Follower1: 重新尝试 PING 或标记失效
    else 收到 ACK
        Note right of Leader: 标记 Follower 正常
    end
    
    Note right of Follower1: Follower1 定期发送心跳消息 (PING)
    Follower1-&gt;&gt;Leader: 发送 PING
    
    Note right of Follower2: Follower2 定期发送心跳消息 (PING)
    Follower2-&gt;&gt;Leader: 发送 PING
    
    Note right of Leader: 返回心跳确认 (ACK)
    Leader--&gt;&gt;Follower1: 返回 ACK
    Leader--&gt;&gt;Follower2: 返回 ACK
    
    Note right of Follower1: Follower1 检查心跳确认 (ACK)
    alt 超时未收到 ACK
        Note right of Follower1: Follower1 进入 LOOKING 状态
        Follower1-&gt;&gt;Follower1: 开始新的 Leader 选举
    else 收到 ACK
        Note right of Follower1: 标记 Leader 正常
    end
    
    Note right of Follower2: Follower2 检查心跳确认 (ACK)
    alt 超时未收到 ACK
        Note right of Follower2: Follower2 进入 LOOKING 状态
        Follower2-&gt;&gt;Follower2: 开始新的 Leader 选举
    else 收到 ACK
        Note right of Follower2: 标记 Leader 正常
    end

</pre>
				</div>
			<p>!!!</p>
<p>!!! failure 重新选举</p>
<ul>
<li>异常情况出现
<ul>
<li>ZAB(Zookeeper Atomic Broadcast) 协议就会进入恢复模式并选举产生新的Leader服务器
<ul>
<li>ZAB协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。</li>
<li>在ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性</li>
<li>基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。</li>
</ul>
</li>
</ul>
</li>
</ul>

				<div>
					
					<pre class="mermaid">sequenceDiagram
    participant ZK1 as ZooKeeper 1
    participant ZK2 as ZooKeeper 2
    participant ZK3 as ZooKeeper 3
    participant Client as Client
    
    Note right of All: Leader Election（选举阶段）
    ZK1-&gt;&gt;All: 发出选举投票 (myid=1, zxid=0x0)
    ZK2-&gt;&gt;All: 发出选举投票 (myid=2, zxid=0x0)
    ZK3-&gt;&gt;All: 发出选举投票 (myid=3, zxid=0x0)
    
    Note right of All: ZK3 得到超半数票数，成为准 leader
    ZK1-&gt;&gt;ZK3: 投票 (myid=1)
    ZK2-&gt;&gt;ZK3: 投票 (myid=2)
    
    Note right of All: Discovery（发现阶段）
    ZK1-&gt;&gt;ZK3: 同步最近接收的事务提议
    ZK2-&gt;&gt;ZK3: 同步最近接收的事务提议
    
    ZK3-&gt;&gt;ZK1: 确认接收的事务提议
    ZK3-&gt;&gt;ZK2: 确认接收的事务提议
    
    Note right of All: Synchronization（同步阶段）
    ZK3-&gt;&gt;ZK1: 同步最新提议历史
    ZK3-&gt;&gt;ZK2: 同步最新提议历史
    
    ZK1-&gt;&gt;ZK3: 同步完成确认
    ZK2-&gt;&gt;ZK3: 同步完成确认
    
    Note right of All: 准 leader 成为真正的 leader
    ZK3-&gt;&gt;All: 宣布成为 Leader
    
    Note right of All: Broadcast（广播阶段）
    ZK3-&gt;&gt;ZK1: 广播事务
    ZK3-&gt;&gt;ZK2: 广播事务
    
    ZK1-&gt;&gt;ZK3: 确认事务
    ZK2-&gt;&gt;ZK3: 确认事务
    
    Client-&gt;&gt;ZK3: 发送请求
    ZK3-&gt;&gt;ZK1: 广播请求
    ZK3-&gt;&gt;ZK2: 广播请求
    
    ZK1-&gt;&gt;ZK3: 确认请求
    ZK2-&gt;&gt;ZK3: 确认请求
    
    ZK3-&gt;&gt;Client: 返回响应
    
    Note right of All: 新节点加入同步
    participant NewZK as 新节点
    NewZK-&gt;&gt;ZK3: 请求加入
    ZK3-&gt;&gt;NewZK: 同步最新提议历史
    NewZK-&gt;&gt;ZK3: 同步完成确认
</pre>
				</div>
			<p>!!!</p>
<h2 id="事务日志与快照">事务日志与快照</h2>
<ul>
<li>事务产生
<ul>
<li>当集群收到<code>写</code>操作时，请求将被转给<code>Leader</code></li>
<li><code>Leader</code>将把<code>写</code>操作转换为<code>带有状态的事务</code></li>
</ul>
</li>
<li>事物处理
<ul>
<li><code>Leader</code>对该<code>写</code>操作进行广播以便进行协调</li>
<li>当超过半数节点写入<code>表示协调通过</code></li>
<li><code>Leader</code>将通知服务器节点将不能次写操作应用到<code>内存</code>数据库中</li>
<li>将该记录写入到<code>事务日志</code>中</li>
</ul>
</li>
<li>快照的产生
<ul>
<li>当<code>事务日志</code>达到一定额数量（如10万次）</li>
<li>将<code>内存数据库序列化</code>永久保存到磁盘中</li>
<li>序列化后的文件称为<code>快照</code></li>
<li>拍快照的同时会生成<code>事务日志</code></li>
</ul>
</li>
</ul>

				<div>
					
					<pre class="mermaid">sequenceDiagram
    participant Client as Client
    participant Follower1 as ZooKeeper Follower1
    participant Follower2 as ZooKeeper Follower2
    participant Leader as ZooKeeper Leader
    
    Note right of Client: 发送写操作请求
    Client-&gt;&gt;Follower1: 发送写操作请求
    
    Note right of Follower1: 将请求转发给Leader
    Follower1-&gt;&gt;Leader: 转发写操作请求
    
    Note right of Leader: Leader 处理写操作
    Leader-&gt;&gt;Leader: 将写操作转换为带有状态的事务
    
    Note right of Leader: 广播事务给所有Follower
    Leader-&gt;&gt;Follower1: 广播事务
    Leader-&gt;&gt;Follower2: 广播事务
    
    Note right of All: Follower 接收并确认事务
    Follower1-&gt;&gt;Leader: 确认事务
    Follower2-&gt;&gt;Leader: 确认事务
    
    Note right of Leader: Leader 收集多数确认
    alt 大多数节点允许写操作
        Leader-&gt;&gt;All: 通知所有节点应用写操作
        Leader-&gt;&gt;Follower1: 应用写操作
        Leader-&gt;&gt;Follower2: 应用写操作
        
        Note right of Follower1: 将写操作应用到内存数据库并记录到事务日志
        Follower1-&gt;&gt;Follower1: 应用写操作并记录到事务日志
        
        Note right of Follower2: 将写操作应用到内存数据库并记录到事务日志
        Follower2-&gt;&gt;Follower2: 应用写操作并记录到事务日志
        
        Leader-&gt;&gt;Leader: 将写操作应用到内存数据库并记录到事务日志
        
        Note right of All: 客户端收到写操作成功响应
        Leader-&gt;&gt;Client: 返回写操作成功响应
        
        Note right of All: 事务日志记录达到一定次数
        alt 达到事务日志阈值 (默认10W次)
            Note right of All: 将内存数据库序列化保存到磁盘上
            Leader-&gt;&gt;Disk: 生成快照文件
            Follower1-&gt;&gt;Disk: 生成快照文件
            Follower2-&gt;&gt;Disk: 生成快照文件
        end
    else 未达到大多数确认
        Note right of Leader: Leader 返回写操作失败响应
        Leader-&gt;&gt;Client: 返回写操作失败响应
    end
</pre>
				</div>
			<h2 id="环境要求">环境要求</h2>
<p><img src="/_resources/d7d73ec396a14d0285679632224d8221.png" /></p>
<div><pre class="hljs"><code><span class="hljs-comment"># 最低JDK版本为1.8</span>
yum install java-1.8.0-openjdk

<span class="hljs-comment"># JDK 11 可使用以下命令</span>
yum install java-11-openjdk</code></pre></div>
<h2 id="集群部署">集群部署</h2>
<table>
<thead>
<tr>
<th>名称</th>
<th>IP</th>
<th>zxid</th>
<th>角色</th>
</tr>
</thead>
<tbody>
<tr>
<td>s1</td>
<td>192.168.100.101</td>
<td>1</td>
<td>Follower</td>
</tr>
<tr>
<td>s2</td>
<td>192.168.100.102</td>
<td>2</td>
<td>Follower</td>
</tr>
<tr>
<td>s2</td>
<td>192.168.100.103</td>
<td>3</td>
<td>Leader</td>
</tr>
</tbody>
</table>
<h3 id="集群安装">集群安装</h3>
<div><pre class="hljs"><code><span class="hljs-comment"># 最低JDK版本为1.8</span>
yum install java-1.8.0-openjdk

<span class="hljs-comment"># 下载二进制</span>
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.9.0/apache-zookeeper-3.9.0-bin.tar.gz

<span class="hljs-comment"># 解压包</span>
tar xf apache-zookeeper-3.9.0-bin.tar.gz -C /usr/<span class="hljs-built_in">local</span>/
ln -s /usr/<span class="hljs-built_in">local</span>/apache-zookeeper-3.9.0-bin /usr/<span class="hljs-built_in">local</span>/zookeeper

<span class="hljs-comment"># 路径追加</span>
<span class="hljs-built_in">echo</span> <span class="hljs-string">'PATH=/usr/local/zookeeper/bin:$PATH'</span> &gt; /etc/profile.d/zookeeper.sh
<span class="hljs-built_in">source</span>  /etc/profile.d/zookeeper.sh

<span class="hljs-comment"># 配置文件获得</span>
cp /usr/<span class="hljs-built_in">local</span>/zookeeper/conf/zoo_sample.cfg /usr/<span class="hljs-built_in">local</span>/zookeeper/conf/zoo.cfg

mkdir /usr/<span class="hljs-built_in">local</span>/zookeeper/data
<span class="hljs-comment"># 修改配置文件 /usr/local/zookeeper/conf/zoo.cfg </span>
<span class="hljs-comment"># 格式: server.MyID服务器唯一编号=服务器IP:Leader和Follower的数据同步端口</span>
sed -i -e <span class="hljs-string">'s!dataDir=.*!dataDir=/usr/local/zookeeper/data!'</span> \
-e <span class="hljs-string">'$ a server.1=192.168.100.101:2888:3888\nserver.2=192.168.100.102:2888:3888\nserver.3=192.168.100.103:2888:3888'</span> \
/usr/<span class="hljs-built_in">local</span>/zookeeper/conf/zoo.cfg

<span class="hljs-comment"># 生成ZXID文件</span>
<span class="hljs-comment"># 各个myid文件的内容要和zoo.cfg文件相匹配</span>
<span class="hljs-comment"># server1 为1, server2 为2， server3 为3</span>
<span class="hljs-built_in">echo</span> 1 &gt; /usr/<span class="hljs-built_in">local</span>/zookeeper/data/myid

<span class="hljs-comment"># 启动服务</span>
zkServer.sh start</code></pre></div>
<h3 id="日志检查">日志检查</h3>
<blockquote>
<p>/usr/local/zookeeper/logs/zookeeper-root-server-s1.out<br />
<img src="/_resources/cf0b1d273b644674939ede8bb327626d.png" /></p>
</blockquote>
<h3 id="端口检查">端口检查</h3>
<p><img src="/_resources/380fce39b20a45e39ee6a99d0da5ae3d.png" /></p>
<h3 id="状态检查">状态检查</h3>
<ul>
<li>slave 状态，监听<code>3888</code>端口<br />
<img src="/_resources/a86550daadc64994b18dd3b9c6a5881b.png" /></li>
<li>master 状态，监听<code>2888</code>,<code>3888</code>端口<br />
<img src="/_resources/02f0b099f9de4c9499373ae90417e6b3.png" /></li>
</ul>
<h2 id="命令行访问">命令行访问</h2>
<ul>
<li>进入交互命令
<ul>
<li>zkCli.sh -server node:2181<br />
<img src="/_resources/4fd637354fb347958d1fecb2391ca8d7.png" /></li>
</ul>
</li>
<li>创建节点/查看节点/修改节点/删除节点（默认持久节点）<br />
<img src="/_resources/2c57a45e22fc445e82b55d2479116ac0.png" /></li>
<li>查看节点元数据<br />
<img src="/_resources/b78d5f9a63334cd79c6a4a6ff0705c10.png" /></li>
<li>查看配置<br />
<img src="/_resources/a864cd1d0d4b4a8cb7a157503a0a8383.png" /></li>
</ul>
<h2 id="gui访问">GUI访问</h2>
<div><pre class="hljs"><code><span class="hljs-comment"># 准备终端转发环境</span>
dnf install xauth -y
ssh -X root@192.168.100.101

<span class="hljs-comment"># 准备maven环境</span>
dnf install maven -y
/etc/maven/settings.xml
  &lt;mirrors&gt;
    &lt;mirror&gt;
      &lt;id&gt;aliyun&lt;/id&gt;
      &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;
      &lt;name&gt;Nexus <span class="hljs-keyword">for</span> aliyun&lt;/name&gt;
      &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;
    &lt;/mirror&gt;
  &lt;/mirrors&gt;

<span class="hljs-comment"># 下载源代码</span>
dnf install -y git
git <span class="hljs-built_in">clone</span> https://github.com/zzhang5/zooinspector.git
<span class="hljs-built_in">cd</span> zooinspector

<span class="hljs-comment"># 编译安装</span>
mvn clean package -Dmaven.test.skip=<span class="hljs-literal">true</span>

<span class="hljs-comment"># 图形界面启动</span>
chmod +x target/zooinspector-pkg/bin/zooinspector.sh
target/zooinspector-pkg/bin/zooinspector.sh</code></pre></div>
<p><img src="/_resources/7764f38ab3ac49cda5163a82d0b03459.png" /></p>
<h2 id="python-sdk访问">python SDK访问</h2>
<ul>
<li>准备工作<div><pre class="hljs"><code><span class="hljs-comment"># 安装python和相关库</span>
dnf install python3 
pip3 install kazoo</code></pre></div>
</li>
<li>测试调用<div><pre class="hljs"><code><span class="hljs-comment">#!/usr/bin/python3</span>
<span class="hljs-keyword">from</span> kazoo.client <span class="hljs-keyword">import</span> KazooClient
zk = KazooClient(hosts=<span class="hljs-string">'192.168.100.101:2181'</span>)

zk.start()
<span class="hljs-comment"># 创建节点：makepath 设置为 True ，父节点不存在则创建，其他参数不填均为默认</span>
zk.create(<span class="hljs-string">'/zkapp/test'</span>,<span class="hljs-string">b'this is a test'</span>,makepath=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># 操作完后关闭zk连接</span>
data=zk.get(<span class="hljs-string">'/zkapp/test'</span>)
<span class="hljs-built_in">print</span>(data)
zk.stop()</code></pre></div>
</li>
</ul>
<p><img src="/_resources/6c141fda964a4ef2a945a4fb5ef6c634.png" /></p>
<h1 id="kafka">kafka</h1>
<h2 id="消息队列">消息队列</h2>
<blockquote>
<p>软件之间互相通信如今就像呼吸一样简单，但回到<code>80年代</code>这是一个头疼的事情。<br />
不同软件之间通信需要实现不同的协议，软件通信没有任何组织可言，面对这个局面。<br />
有人率先打开局面，既然主机有<code>总线</code>，那么软件之间也可以有，这便诞生了<code>消息队列</code><br />
<code>消息队列</code>的出现使软件通信出现的曙光，但很快大公司也进来了，各家的<code>消息队列</code>粉末登场各部兼容<br />
在这个背景下，规范组织插手推出<code>AMQP</code>，消息队列迎来了规范化发展时代</p>
</blockquote>
<blockquote>
<p>主流的消息队列工具: <code>Kafka</code>、<code>RabbitMQ</code>、<code>ActiveMQ</code>、<code>RocketMQ</code>等</p>
</blockquote>
<p>!!! tip MQ摘要信息</p>
<ul>
<li>本质
<ul>
<li>消息队列是一种异步的服务间通信方式</li>
</ul>
</li>
<li>适用场合
<ul>
<li>适用于无服务器和微服务架构。</li>
</ul>
</li>
<li>使用方式
<ul>
<li>消息在被处理和删除之前一直存储在队列上，每条消息仅可被一位用户处理一次用户处理一次。</li>
</ul>
</li>
<li>业务场景
<ol>
<li>重量级访问请求处理(削峰填谷)</li>
<li>请求按时排队（顺序收发）</li>
<li>异步通信需求（异步解耦）</li>
<li>数据分析处理（大数据分析）</li>
<li>缓存信息降低数据库压力（分布式缓存同步）</li>
<li>链路访问压力测试（蓄流压测）<br />
!!!</li>
</ol>
</li>
</ul>
<h2 id="简介">简介</h2>
<blockquote>
<p>Kafka 是一个<code>事件流平台</code>(event streaming platform)</p>
</blockquote>
<ul>
<li>用于<code>发布</code>（写入）和<code>订阅</code>（读取）事件流，包括从其他系统持续导入/导出数据。</li>
<li>用于持久可靠地<code>存储事件流</code>，只要你需要可以一直保存。</li>
<li>用于在<code>事件发生时</code>或<code>事后</code>处理事件流。</li>
</ul>
<p>!!! tip kafka摘要信息</p>
<ul>
<li>
<p>开发语言:</p>
<ul>
<li><code>scala</code> 和 <code>java</code></li>
</ul>
</li>
<li>
<p>MQ对别<br />
<img src="/_resources/99ed43bc2b224e9180348874cf62ffda.png" /></p>
</li>
<li>
<p>特点</p>
<ul>
<li><code>分布式</code>: 多机实现,不允许单机</li>
<li><code>分区</code>: 一个消息.可以拆分出多个，分别存储在多个位置</li>
<li><code>多副本</code>: 防止信息丢失，可以多来几个备份</li>
<li><code>多订阅者</code>: 可以有很多应用连接kafka</li>
<li><code>Zookeeper</code>: 早期版本的Kafka依赖于zookeeper, <code>v2.8.0</code> (2021) 后<code>可单独部署</code></li>
</ul>
</li>
<li>
<p>优势</p>
<ul>
<li>优秀的数据结构: 通过 <code>O(1)</code> 的磁盘数据结构提供消息的持久化</li>
<li>高吞吐量: 支持每秒数百万的消息</li>
<li>分布式: 基于分布式集群实现高可用的容错机制，可以实现<code>自动的故障转移</code></li>
<li>顺序保证: 保证数据会按照特定的顺序来处理</li>
<li>大数据友好: 支持 Hadoop <code>并行数据加载</code></li>
</ul>
</li>
<li>
<p>常用场景</p>
<ul>
<li>大数据<br />
!!!</li>
</ul>
</li>
</ul>
<h2 id="角色流程">角色流程</h2>
<h3 id="角色">角色</h3>
<p>!!! info 操作</p>
<ul>
<li>Producer (写)
<ul>
<li>Producer即生产者，消息的产生者，是消息的入口。负责发布消息到Kafka</li>
</ul>
</li>
<li>Consumer (读)
<ul>
<li>消费者，用于消费消息，即处理消息<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! info 对象</p>
<ul>
<li>Broker
<ul>
<li>Broker是kafka实例，每个服务器上可以有一个或多个kafka的实例</li>
<li>Broker需要通过<code>唯一的</code>编号区分</li>
</ul>
</li>
<li>Topic
<ul>
<li>消息的主题，可以理解为消息的分类，<code>数据库上的一张表</code></li>
<li>一个消息即为<code>topic</code>上的一条记录</li>
<li>一个<code>broker</code>对应多个<code>topic</code></li>
<li>一个<code>topic</code>可对应多个<code>broker</code> （分布式存放）</li>
<li><code>consumer</code> 通过 <code>topic</code>访问数据，不关系存放地<code>broker</code></li>
</ul>
</li>
<li>consumer group
<ul>
<li><code>consumer</code> 需要属于<code>一个</code>特定的组（不指定则为默认组）</li>
<li>同一个<code>topic</code>的一条消息只能被一个<code>consumer group</code>一个<code>consuer</code>消费</li>
<li>多个<code>consumer group</code>可同时消费一个消息<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! info 存储方式</p>
<ul>
<li>Partition -- 分区存储提高读取
<ul>
<li><code>topic</code>可以拆分为<code>一个或多个</code> <code>Partition</code></li>
<li>创建<code>topic</code>可指定<code>partition</code>数量</li>
<li>表现形式为<code>文件夹</code></li>
<li>目的是实现<code>负载均衡</code>，提高<code>吞吐量</code></li>
<li>同一个<code>topic</code>在不同的<code>partition</code>唯一</li>
<li><code>partition</code> 数量应该<code>不超过节点数量</code></li>
<li><code>partition</code> 没有顺序</li>
</ul>
</li>
<li>Replication -- 分片备份提高可用性
<ul>
<li>本质是<code>同样数据的副本</code></li>
<li>建议设定至少<code>2</code>个</li>
<li><code>kafka</code>的副本数量<code>包含主分片数</code></li>
<li>分区角色:
<ul>
<li><code>AR</code>(总分片): <code>Assigned Replicas</code> 分区中的所有副本的统称，包括leader和 follower
<ul>
<li>AR= lSR+ OSR</li>
</ul>
</li>
<li><code>ISR</code>(可用分片): <code>ln Sync Replicas</code> 与leader副本保持同步的副本 本 follower和leader本身组成的集合</li>
<li><code>OSR</code>(不可用分片): <code>out-of-Sync Replied</code> 与leader副本同步不能同步的 follower的集合<br />
!!!</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/_resources/1bbf2a96ffbf474380e0897cdeafebc0.png" /></p>
<h3 id="流程">流程</h3>
<p><img src="/_resources/4a6183953a2b4d698f097885741a9477.png" /></p>
<ol>
<li><code>produceer</code>从集群中获知<code>leader</code>信息</li>
<li><code>producer</code>将<code>消息</code>发送给<code>leader</code></li>
<li><code>leader</code>将消息写入本地文件</li>
<li><code>follower</code>从<code>leader</code>处<code>pull</code>同步<code>消息</code></li>
<li><code>follower</code>将<code>消息</code>写入的确认返回给<code>leader</code></li>
<li><code>leader</code>收到所有<code>replication</code>的确认后，返回<code>producer</code>回复消息已写入</li>
</ol>
<h2 id="部署">部署</h2>
<table>
<thead>
<tr>
<th>名称</th>
<th>IP</th>
</tr>
</thead>
<tbody>
<tr>
<td>s1</td>
<td>192.168.100.101</td>
</tr>
<tr>
<td>s2</td>
<td>192.168.100.102</td>
</tr>
<tr>
<td>s2</td>
<td>192.168.100.103</td>
</tr>
</tbody>
</table>
<p>!!! warning 版本名称</p>
<blockquote>
<p>kafka由<code>scale</code>开发，<code>scale</code>存在多版本，因此其版本名称会包含<code>scale</code>版本呢<br />
<code>kafka_&lt;scala 版本&gt;-&lt;kafka 版本&gt;</code><br />
目前主流<code>scale</code>版本 <code>2.12 / 2.13</code><br />
!!!</p>
</blockquote>
<div><pre class="hljs"><code><span class="hljs-comment"># java环境准备 Java8</span>
yum install java-1.8.0-openjdk

<span class="hljs-comment"># 下载kafka包</span>
wget https://downloads.apache.org/kafka/3.6.2/kafka_2.13-3.6.2.tgz

<span class="hljs-comment"># 解压链接</span>
tar xf kafka_2.13-3.6.2.tgz -C /usr/<span class="hljs-built_in">local</span>/
ln -s /usr/<span class="hljs-built_in">local</span>/kafka_2.13-3.6.2/ /usr/<span class="hljs-built_in">local</span>/kafka

<span class="hljs-comment"># 配置PATH</span>
<span class="hljs-built_in">echo</span> <span class="hljs-string">'PATH=/usr/local/kafka/bin:$PATH'</span> &gt; /etc/profile.d/kafka.sh
<span class="hljs-built_in">source</span> /etc/profile.d/kafka.sh

<span class="hljs-comment"># 修改配置</span>
vim /usr/<span class="hljs-built_in">local</span>/kafka/config/server.properties
<span class="hljs-comment">#每个broker在集群中每个节点的正整数唯一标识，此值保存在log.dirs下的meta.properties文件 --&gt; 节点定制修改</span>
broker.id=1 
<span class="hljs-comment">#指定当前主机的IP做为监听地址,注意:不支持0.0.0.0 ---&gt; 节点定制修改</span>
listeners=PLAINTEXT://192.168.100.101:9092 
<span class="hljs-comment">#kakfa用于保存数据的目录，所有的消息都会存储在该目录当中</span>
log.dirs=/usr/<span class="hljs-built_in">local</span>/kafka/data 
<span class="hljs-comment">#设置创建新的topic时默认分区数量,建议和kafka的节点数量一致</span>
num.partitions=1 
<span class="hljs-comment">#指定默认的副本数为3，可以实现故障的自动转移</span>
default.replication.factor=3 
<span class="hljs-comment">#设置kafka中消息保留时间，默认为168小时即7天</span>
log.retention.hours=168 
<span class="hljs-comment">#指定连接的zk的地址,zk中存储了broker的元数据信息 --&gt; 设置相同即可</span>
zookeeper.connect=192.168.100.101:2181,192.168.100.102:2181,192.168.100.103:2181 
<span class="hljs-comment">#设置连接zookeeper的超时时间，单位为ms,默认6秒钟</span>
zookeeper.connection.timeout.ms=6000 

<span class="hljs-comment"># 准备数据目录</span>
mkdir /usr/<span class="hljs-built_in">local</span>/kafka/data

<span class="hljs-comment"># 调整JAVA内存</span>
vim /usr/<span class="hljs-built_in">local</span>/kafka/bin/kafka-server-start.sh
<span class="hljs-keyword">if</span>[ <span class="hljs-string">" x<span class="hljs-variable">$KAFKA_HEAP_OPTS</span>"</span>=<span class="hljs-string">"x"</span>] ; <span class="hljs-keyword">then</span>
  <span class="hljs-built_in">export</span> KAFKA_HEAP_OPTS=<span class="hljs-string">" -Xmx1G -Xms1G"</span>
<span class="hljs-keyword">fi</span>

<span class="hljs-comment"># 启动服务</span>
kafka-server-start.sh -daemon /usr/<span class="hljs-built_in">local</span>/kafka/config/server.properties

<span class="hljs-comment"># 错误查看文件</span>
/usr/<span class="hljs-built_in">local</span>/kafka/logs/kafkaServer.out

<span class="hljs-comment"># 关闭服务，使用systemd接管</span>
kafka-server-stop.sh

<span class="hljs-comment"># 准备service文件</span>
cat &gt; /lib/systemd/system/kafka.service &lt;&lt;<span class="hljs-string">EOF
[Unit]
Description=Apache kafka
After=network.target

[Service]
Type=simple
PIDFile=/usr/local/kafka/kafka.pid
ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties
ExecStop=/bin/kill -TERM 
Restart=always
RestartSec=20

[Installed]
wantedBy=multi-user.target
EOF</span>

systemctl daemon-reload
systemctl start kafka.service</code></pre></div>
<p><img src="/_resources/960e988a5d1944d79febd6ea772dd403.png" /></p>
<h2 id="检查">检查</h2>
<blockquote>
<p>zookeeper 此时多出 kafka的信息<br />
<img src="/_resources/774dec40289a4488986a49cb8407adb8.png" /></p>
</blockquote>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[第五周作业]]></title>
            <guid>5d1c252ce2fa414e967c0ac378c05689</guid>
            <pubDate>Sun, 12 May 2024 14:14:29 GMT</pubDate>
            <content:encoded><![CDATA[<nav class="table-of-contents"><ul><li><a href="#keepalived-nginx-高可用">keepalived nginx 高可用</a><ul><li><a href="#创建脚本执行用户">创建脚本执行用户</a></li><li><a href="#nginx代理服务配置">Nginx代理服务配置</a></li><li><a href="#应用服务配置">应用服务配置</a></li><li><a href="#keepalived-服务配置">Keepalived 服务配置</a></li><li><a href="#测试检查">测试检查</a></li></ul></li><li><a href="#keepalived-haproxy-高可用">keepalived haproxy 高可用</a><ul><li><a href="#haproxy-服务配置">HAProxy 服务配置</a></li><li><a href="#应用服务配置-1">应用服务配置</a></li><li><a href="#keepalived-服务配置-1">Keepalived 服务配置</a></li><li><a href="#检查测试">检查测试</a></li></ul></li><li><a href="#redis-集群部署">Redis 集群部署</a><ul><li><a href="#部署">部署</a></li></ul></li><li><a href="#cluster-多主节点分区存放">cluster  (多主节点分区存放)</a><ul><li><a href="#数据分布">数据分布</a></li><li><a href="#搭建部署">搭建部署</a><ul><li><a href="#修改参数">修改参数</a></li><li><a href="#创建集群">创建集群</a></li><li><a href="#验证集群">验证集群</a></li></ul></li><li><a href="#集群命令">集群命令</a></li><li><a href="#读写操作">读写操作</a><ul><li><a href="#写入数据">写入数据</a></li><li><a href="#计算slot">计算slot</a></li><li><a href="#集群方式链接">集群方式链接</a></li><li><a href="#python客户端访问">python客户端访问</a></li></ul></li><li><a href="#管理">管理</a><ul><li><a href="#增加slave节点">增加slave节点</a></li><li><a href="#故障迁移">故障迁移</a></li><li><a href="#集群扩容">集群扩容</a></li><li><a href="#集群缩容">集群缩容</a></li><li><a href="#集群倾斜">集群倾斜</a></li></ul></li></ul></li></ul></nav><h1 id="keepalived-nginx-高可用">keepalived nginx 高可用</h1>
<p>!!! warning SElinux<br />
该配置需要关闭<code>SELINXU</code>，否则会出现 <code>503</code> 告警。<br />
<img src="/_resources/dbf08aa9cd4d4fd9bb217974e8feab11.png" /><br />
!!!</p>
<h2 id="创建脚本执行用户">创建脚本执行用户</h2>
<div><pre class="hljs"><code>useradd -r -s <span class="hljs-regexp">/sbin/</span>nologin keepalived_script
chown keepalived_script:keepalived_script <span class="hljs-regexp">/etc/</span>keepalived/check_nginx.sh
chmod <span class="hljs-number">655</span> <span class="hljs-regexp">/etc/</span>keepalived/check_nginx.sh</code></pre></div>
<h2 id="nginx代理服务配置">Nginx代理服务配置</h2>
<div><pre class="hljs"><code><span class="hljs-regexp">/etc/</span>nginx/nginx.conf

user nginx;
worker_processes auto;
error_log <span class="hljs-regexp">/var/</span>log<span class="hljs-regexp">/nginx/</span>error.log;
pid <span class="hljs-regexp">/run/</span>nginx.pid;

<span class="hljs-comment"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span>
include <span class="hljs-regexp">/usr/</span>share<span class="hljs-regexp">/nginx/m</span>odules/*.conf;

events {
    worker_connections <span class="hljs-number">1024</span>;
}

http {
    upstream demos {
        server <span class="hljs-number">192.168</span>.<span class="hljs-number">100.103</span>:<span class="hljs-number">80</span> weight=<span class="hljs-number">1</span>;  <span class="hljs-comment"># 后端web服务器</span>
        server <span class="hljs-number">192.168</span>.<span class="hljs-number">100.104</span>:<span class="hljs-number">80</span> weight=<span class="hljs-number">1</span>;  <span class="hljs-comment"># 后端web服务器</span>
    }
    server {
        listen <span class="hljs-number">80</span>;
        location /{
                proxy_pass http:<span class="hljs-regexp">//</span>demos/;
        }
    }
}
~           </code></pre></div>
<h2 id="应用服务配置">应用服务配置</h2>
<div><pre class="hljs"><code>yum -y install nginx
systemctl start nginx 

<span class="hljs-built_in">echo</span> <span class="hljs-string">"&lt;h1&gt;`hostname -I`&lt;/h1&gt;"</span> &gt; /usr/share/nginx/html/index.html</code></pre></div>
<h2 id="keepalived-服务配置">Keepalived 服务配置</h2>
<div><pre class="hljs"><code>! Configuration File for keepalived

<span class="hljs-keyword">global_defs</span> {
   router_id alfie_keepalive_1  <span class="hljs-comment"># 备用节点修改名称</span>
   vrrp_skip_check_adv_addr
   vrrp_garp_interval <span class="hljs-number">0</span>
   vrrp_gna_interval <span class="hljs-number">0</span>
   vrrp_mcast_group4 <span class="hljs-number">224.0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">18</span>
}

<span class="hljs-keyword">vrrp_script</span> <span class="hljs-keyword">check_nginx</span> {
    script <span class="hljs-string">"/etc/keepalived/check_nginx.sh"</span>  <span class="hljs-comment"># 使用 kill 发送 0 信号 确认程序是否工作正常</span>
    interval <span class="hljs-number">1</span>
    weight -<span class="hljs-number">30</span>  <span class="hljs-comment"># 失败后降低 30 权重</span>
    fall <span class="hljs-number">3</span>
    rise <span class="hljs-number">5</span>
    timeout <span class="hljs-number">2</span>
}

<span class="hljs-keyword">vrrp_instance</span> <span class="hljs-keyword">alfie_ka1</span> {
    state MASTER  <span class="hljs-comment"># 备用节点为 BACKUP</span>
    interface ens33
    virtual_router_id <span class="hljs-number">61</span>
    <span class="hljs-literal">priority</span> <span class="hljs-number">100</span>  <span class="hljs-comment"># 备用节点默认权重 80</span>
    advert_int <span class="hljs-number">1</span>
    authentication {
        <span class="hljs-literal">auth_type</span> PASS
        auth_pass alopex
    }
    <span class="hljs-keyword">virtual_ipaddress</span> {
        <span class="hljs-number">192.168</span>.<span class="hljs-number">100.111</span>/<span class="hljs-number">24</span>
    }
    <span class="hljs-keyword">unicast_src_ip</span> 192.168.100.101  <span class="hljs-comment"># 备用节点修改本地IP</span>
    unicast_peer{
        192.168.100.102  <span class="hljs-comment"># 备用节点此处填写主节点IP</span>
    }
    <span class="hljs-keyword">track_script</span> {
        check_nginx
    }
}
include /etc/keepalived/conf.d/*.conf</code></pre></div>
<div><pre class="hljs"><code>chmod a+x /etc/keepalived/check_nginx.sh
<span class="hljs-comment"># 文件 /usr/bin/killall -0 nginx</span>

<span class="hljs-comment">#!/bin/bash</span>
/usr/bin/killall -0 nginx</code></pre></div>
<h2 id="测试检查">测试检查</h2>
<p><img src="/_resources/02644064d4744c069321d380e5dcf46e.png" /></p>
<ul>
<li>
<p>关闭DS1 keepalived</p>
<ul>
<li>地址切换正常<br />
<img src="/_resources/7386e8bfcea140429ef7d280c8768e6e.png" /></li>
<li>应用访问正常<br />
<img src="/_resources/353ef8cfcc7d4909ad78c168887f27f7.png" /></li>
</ul>
</li>
<li>
<p>关闭RS1</p>
<ul>
<li>应用访问正常<br />
<img src="/_resources/4975aad83b4d4d4bb10466d0c26ecbf3.png" /></li>
</ul>
</li>
<li>
<p>健康检查 （恢复DS1 keepalived 关闭 nginx）<br />
<img src="/_resources/bd151b80681648659c49ae8a57c14836.png" /></p>
</li>
</ul>
<h1 id="keepalived-haproxy-高可用">keepalived haproxy 高可用</h1>
<h2 id="haproxy-服务配置">HAProxy 服务配置</h2>
<p>!!! warning 注意事项</p>
<div><pre class="hljs"><code><span class="hljs-comment"># 绑定非自身IP地址</span>
vim /etc/sysctl.conf
net.ipv4.ip_nonlocal_bind = 1

sysctl -p

<span class="hljs-comment"># 在防火墙上放行通对VIP的访问</span>
firewall-cmd --permanent --add-rich-rule=<span class="hljs-string">'rule family="ipv4" destination address="192.168.100.111" accept'</span> 
firewall-cmd --reload</code></pre></div>
<p>!!!</p>
<div><pre class="hljs"><code>global
  daemon
  stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin
  nbthread  5

  user haproxy
  group haproxy
  maxconn 100000

defaults
  option http-keep-alive
  maxconn 100000
  mode http
  timeout connect 300000ms
  timeout client 300000ms
  timeout server 300000ms

frontend demo-web-port
  bind 192.168.100.111:80
  mode http
  use_backend demo-web

backend demo-web
  mode http
  default-server inter 1000 weight 6
  server web2 192.168.100.103:80 weight 2<span class="hljs-built_in"> check </span>addr 192.168.100.103 port 80
  server web3 192.168.100.104:80 weight 2<span class="hljs-built_in"> check </span>addr 192.168.100.104 port 80</code></pre></div>
<h2 id="应用服务配置-2">应用服务配置</h2>
<div><pre class="hljs"><code>yum -y install nginx
systemctl start nginx 

<span class="hljs-built_in">echo</span> <span class="hljs-string">"&lt;h1&gt;`hostname -I`&lt;/h1&gt;"</span> &gt; /usr/share/nginx/html/index.html</code></pre></div>
<h2 id="keepalived-服务配置-2">Keepalived 服务配置</h2>
<div><pre class="hljs"><code>! Configuration File for keepalived

<span class="hljs-keyword">global_defs</span> {
   router_id alfie_keepalive_1  <span class="hljs-comment"># 备用节点修改名称</span>
   vrrp_skip_check_adv_addr
   vrrp_garp_interval <span class="hljs-number">0</span>
   vrrp_gna_interval <span class="hljs-number">0</span>
   vrrp_mcast_group4 <span class="hljs-number">224.0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">18</span>
}

<span class="hljs-keyword">vrrp_script</span> <span class="hljs-keyword">check_haproxy</span> {
    script <span class="hljs-string">"/etc/keepalived/check_haproxy.sh"</span>
    interval <span class="hljs-number">1</span>
    weight -<span class="hljs-number">30</span>
    fall <span class="hljs-number">3</span>
    rise <span class="hljs-number">5</span>
    timeout <span class="hljs-number">2</span>
}

<span class="hljs-keyword">vrrp_instance</span> <span class="hljs-keyword">alfie_ka1</span> {
    state MASTER <span class="hljs-comment"># 备用节点修改为 BACKUP</span>
    interface ens33
    virtual_router_id <span class="hljs-number">61</span>
    <span class="hljs-literal">priority</span> <span class="hljs-number">100</span>  <span class="hljs-comment"># 备用节点修改 80</span>
    advert_int <span class="hljs-number">1</span>
    authentication {
        <span class="hljs-literal">auth_type</span> PASS
        auth_pass alopex
    }
    <span class="hljs-keyword">virtual_ipaddress</span> {
        <span class="hljs-number">192.168</span>.<span class="hljs-number">100.111</span>/<span class="hljs-number">24</span>
    }
    <span class="hljs-keyword">unicast_src_ip</span> 192.168.100.101 <span class="hljs-comment"># 备用节点修改为本地IP</span>
    unicast_peer{
        192.168.100.102   <span class="hljs-comment"># 备用节点填主用节点IP</span>
    }
    <span class="hljs-keyword">track_script</span> {
        check_haproxy
    }
}

include /etc/keepalived/conf.d/*.conf
</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-regexp">/etc/</span>keepalived/check_haproxy.sh
chmod <span class="hljs-number">655</span> <span class="hljs-regexp">/etc/</span>keepalived/check_haproxy.sh
<span class="hljs-comment">#!/bin/bash</span>

<span class="hljs-keyword">if</span> <span class="hljs-regexp">/usr/</span>bin/killall -<span class="hljs-number">0</span> haproxy
then
    <span class="hljs-keyword">exit</span> <span class="hljs-number">0</span>
<span class="hljs-keyword">else</span>
    systemctl restart haproxy
fi</code></pre></div>
<h2 id="检查测试">检查测试</h2>
<p><img src="/_resources/aa5decab6b8c4d828fb3a154308eb261.png" /><br />
<img src="/_resources/7c834cb7de134b1683b558970392f65a.png" /></p>
<ul>
<li>
<p>关闭DS1 (keepalived)</p>
<ul>
<li>地址切换正常<br />
<img src="/_resources/a4f2580fe24b4e779c67ea07eb3b2d6b.png" /></li>
<li>应用访问正常<br />
<img src="/_resources/5c8b13fe78504bd7a986bb2dbd2cc2fc.png" /></li>
</ul>
</li>
<li>
<p>关闭RS1</p>
<ul>
<li>应用访问正常<br />
<img src="/_resources/6129d9ac06564637b7b5c57dbecd1816.png" /></li>
</ul>
</li>
<li>
<p>健康检查（恢复keepalived 关闭DS1 (Haproxy)）<br />
<img src="/_resources/7e40a06eaf5a443fb144d21f35b41832.png" /></p>
</li>
</ul>
<h1 id="redis-集群部署">Redis 集群部署</h1>
<h2 id="部署">部署</h2>
<table>
<thead>
<tr>
<th>主机</th>
<th>ip</th>
</tr>
</thead>
<tbody>
<tr>
<td>s2</td>
<td>192.168.100.102</td>
</tr>
<tr>
<td>s3</td>
<td>192.168.100.103</td>
</tr>
<tr>
<td>s4</td>
<td>192.168.100.104</td>
</tr>
</tbody>
</table>
<h1 id="cluster-多主节点分区存放">cluster  (多主节点分区存放)</h1>
<h2 id="数据分布">数据分布</h2>
<blockquote>
<p>解决把<code>整个数据</code>集按照分区规则映射<code>到多个节点</code>的问题，每个节点负责整体数据的子集。</p>
</blockquote>
<p>!!! info 分区方式</p>
<ul>
<li>哈希分区
<ul>
<li>离散度好 / 数据分布与业务无关 / 无法顺序访问</li>
<li>代表产品： <code>redis cluster</code>，<code>Cassandra</code>， <code>Dynamo</code></li>
</ul>
</li>
<li>顺序分区
<ul>
<li>离散度容易倾斜 / 数据分布业务相关 / 可以顺序访问</li>
<li>代表产品：<code>Bigtable</code>，<code>HBase</code>，<code>Hypertable</code></li>
</ul>
</li>
</ul>
<p><img src="/_resources/2dbd60324b10451db234e0c59588ea5e.png" /><br />
!!!</p>
<p>!!! abstract 哈希分区规则</p>
<ul>
<li>
<p><strong>节点取余分区</strong></p>
<ul>
<li>
<p><strong>说明</strong><br />
节点取余分区方法通过简单的模运算将数据分布到不同的节点上。</p>
</li>
<li>
<p><strong>算法简述</strong></p>
<ol>
<li>计算数据的哈希值 <code>hash(key)</code>。</li>
<li>用节点的数量 <code>N</code> 对哈希值取模：<code>partition = hash(key) % N</code>。</li>
<li>将数据分配到 <code>partition</code> 对应的节点。</li>
</ol>
</li>
<li>
<p><strong>优点</strong></p>
<ul>
<li><strong>实现简单</strong>：算法非常直观，易于实现。</li>
<li><strong>查询性能好</strong>：在节点数量固定的情况下，查询和插入操作的性能都很好。</li>
</ul>
</li>
<li>
<p><strong>缺点</strong></p>
<ul>
<li><strong>扩展性差</strong>：当节点数量变化（增加或减少）时，大部分数据都需要重新分配，导致大量的数据迁移。</li>
<li><strong>负载不均衡</strong>：如果哈希函数不好，可能导致数据分布不均匀，某些节点负载较高。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>一致性哈希分区</strong></p>
<ul>
<li>
<p><strong>说明</strong><br />
一致性哈希分区方法通过环形哈希空间和节点的虚拟副本来实现数据的分布和负载均衡。</p>
</li>
<li>
<p><strong>算法简述</strong></p>
<ol>
<li>将所有节点映射到一个哈希环上。</li>
<li>计算数据的哈希值 <code>hash(key)</code> 并将其放置在哈希环上。</li>
<li>从数据的位置顺时针找到第一个节点，这个节点就是数据的目标节点。</li>
</ol>
</li>
<li>
<p><strong>优点</strong></p>
<ul>
<li><strong>扩展性好</strong>：当节点增加或减少时，只需要重新分配相邻节点的一部分数据，减少了数据迁移量。</li>
<li><strong>负载均衡</strong>：通过添加虚拟节点，可以改善数据分布的均衡性。</li>
</ul>
</li>
<li>
<p><strong>缺点</strong></p>
<ul>
<li><strong>实现复杂</strong>：相比节点取余分区，一致性哈希的实现要复杂得多。</li>
<li><strong>性能略低</strong>：由于需要在哈希环上查找节点位置，可能会导致性能稍低。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>虚拟槽分区</strong> <code>redis cluster实现</code></p>
<ul>
<li>
<p><strong>说明</strong><br />
虚拟槽分区方法通过将哈希空间划分为固定数量的槽，并将这些槽映射到实际节点上。</p>
</li>
<li>
<p><strong>算法简述</strong></p>
<ol>
<li>将哈希空间分成固定数量的槽（如 <code>M</code> 个）。</li>
<li>计算数据的哈希值 <code>hash(key)</code> 并将其映射到某个槽：<code>slot = hash(key) % M</code>。</li>
<li>将槽映射到实际的节点：<code>partition = slot_to_node(slot)</code>。</li>
</ol>
</li>
<li>
<p><strong>优点</strong></p>
<ul>
<li><strong>扩展性好</strong>：增加或减少节点时，只需重新分配一部分槽到新的节点，数据迁移量适中。</li>
<li><strong>负载均衡</strong>：通过合理地分配槽，可以实现较为均衡的负载分布。</li>
</ul>
</li>
<li>
<p><strong>缺点</strong></p>
<ul>
<li><strong>实现复杂</strong>：需要实现槽到节点的映射管理，增加了系统的复杂度。</li>
<li><strong>管理开销</strong>：需要维护槽和节点之间的映射关系，增加了系统的管理开销。<br />
!!!</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>!!! danger redis虚拟槽位信息<br />
设置有<code>0 ~ 16383</code>的槽，共 <code>16384</code> 个数据单元，每个槽映射一个数据子集。<br />
通过hash函数，将数据存放在不同的槽位中，每个集群的节点保存一部分的槽。</p>
<p><img src="/_resources/90f402256bf144aea7c7d4eeb45220f0.png" /></p>
<blockquote>
<p>集群之间的通信可以保证，最多两次就能命中对应槽所在的节点。<br />
!!!</p>
</blockquote>
<h2 id="搭建部署">搭建部署</h2>
<blockquote>
<p>需要先部署redis集群<br />
<a>0xff redis/脚本使用#个人源安装脚本</a></p>
</blockquote>
<p><img src="/_resources/ae607bd1a778464690c422cac7904d12.png" /></p>
<table>
<thead>
<tr>
<th>主机</th>
<th>ip</th>
</tr>
</thead>
<tbody>
<tr>
<td>s2</td>
<td>192.168.100.102</td>
</tr>
<tr>
<td>s3</td>
<td>192.168.100.103</td>
</tr>
<tr>
<td>s4</td>
<td>192.168.100.104</td>
</tr>
</tbody>
</table>
<h3 id="修改参数">修改参数</h3>
<div><pre class="hljs"><code><span class="hljs-comment"># 修改配置文件</span>
<span class="hljs-comment"># 以下与cluster相关，按需开启</span>
<span class="hljs-comment"># -e '/# cluster-enabled yes/a cluster-enabled yes' \</span>
<span class="hljs-comment"># -e '/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf' \</span>
<span class="hljs-comment"># -e '/cluster-require-full-coverage yes/a cluster-require-full-coverage no' \</span>

sed -i.bak \
-e <span class="hljs-string">'s/appendonly no/appendonly yes/'</span> \
-e <span class="hljs-string">'/masterauth/a masterauth alopex'</span> \
-e <span class="hljs-string">'s/bind 127.0.0.1/bind 0.0.0.0/'</span>  \
-e <span class="hljs-string">"/# requirepass/a requirepass alopex"</span> \
-e <span class="hljs-string">"/^dir .*/c dir /apps/redis/data/"</span>  \
-e <span class="hljs-string">"/logfile .*/c logfile /apps/redis/log/redis-6379.log"</span> \
-e <span class="hljs-string">"/^pidfile .*/c  pidfile /apps/redis/run/redis_6379.pid"</span> \
-e <span class="hljs-string">'/# cluster-enabled yes/a cluster-enabled yes'</span> \
-e <span class="hljs-string">'/# cluster-config-file nodes-6379.conf/a cluster-config-file /apps/redis/etc/nodes-6379.conf'</span> \
-e <span class="hljs-string">'/cluster-require-full-coverage yes/a cluster-require-full-coverage no'</span> \
/apps/redis/etc/redis.conf

<span class="hljs-comment"># 启动服务</span>
systemctl daemon-reload
systemctl <span class="hljs-built_in">enable</span> --now redis</code></pre></div>
<h3 id="创建集群">创建集群</h3>
<blockquote>
<p>集群功能已开启<br />
<img src="/_resources/c19ae1389de7408e9c222558607c2fd5.png" /></p>
</blockquote>
<blockquote>
<p>cluster 状态启动<br />
<img src="/_resources/b9f1e910b387463a99bb1e4735113051.png" /></p>
</blockquote>
<blockquote>
<p>16379 端口已启动<br />
<img src="/_resources/5fcb26c2c6a64ff4b64a96c08b461439.png" /></p>
</blockquote>
<blockquote>
<p>创建集群</p>
</blockquote>
<div><pre class="hljs"><code><span class="hljs-comment"># 三个节点不创建 slave 节点</span>
redis-cli -a alopex --cluster create 192.168.100.102:6379 192.168.100.103:6379 192.168.100.104:6379</code></pre></div>
<p><img src="/_resources/2ed8a09a9b764eeaa23c15b4952dad8e.png" /></p>
<h3 id="验证集群">验证集群</h3>
<blockquote>
<p>master1 节点查看<br />
<img src="/_resources/151237e673294a41ac73303f0289d04c.png" /></p>
</blockquote>
<blockquote>
<p>node节点状态查看<br />
<img src="/_resources/e51315eabfdd453ba2a6695626ea6781.png" /></p>
</blockquote>
<blockquote>
<p>Cluster info查看<br />
<img src="/_resources/80447bed281243d79e2fddc0b78dd33c.png" /></p>
</blockquote>
<blockquote>
<p>任意节点状态查看<br />
<img src="/_resources/080ae31c141c4219aca5fa734967b25d.png" /></p>
</blockquote>
<blockquote>
<p>查看node-port.conf日志<br />
<img src="/_resources/8a0ec890f9f64b59bf72200041aea0ee.png" /></p>
</blockquote>
<blockquote>
<p>查看对应关系<br />
<img src="/_resources/90b41a2d4dee4869b81e24891a246210.png" /></p>
</blockquote>
<h2 id="集群命令">集群命令</h2>
<div><pre class="hljs"><code><span class="hljs-comment">// 集群(cluster)  </span>
CLUSTER INFO                                打印集群的状态信息  
CLUSTER NODES                               列出集群当前已知的所有节点（node），以及这些节点的相关信息 

<span class="hljs-comment">// 节点(node)  </span>
CLUSTER MEET &lt;ip&gt; &lt;port&gt;                    将ip和port所指定的节点添加到集群当中，让它成为集群的一份子
CLUSTER FORGET &lt;node_id&gt;                    从集群中移除node_id指定的节点
CLUSTER REPLICATE &lt;node_id&gt;                 将当前节点设置为node_id指定节点的从节点
CLUSTER SAVECONFIG                          将当前节点的配置信息手动保存到硬盘（nodes-port.conf） 
CLUSTER SLAVES &lt;master_node_id&gt;             查询指定的master_node_id主节点有哪些从（slave）节点

<span class="hljs-comment">// 槽(slot)  </span>
CLUSTER ADDSLOTS &lt;slot&gt; [slot ...]          将一个或多个槽（slot）指派（assign）给当前节点
CLUSTER DELSLOTS &lt;slot&gt; [slot ...]          将一个或多个槽从当前节点移除
CLUSTER FLUSHSLOTS                          移除指派给当前节点的所有槽，让当前节点变成一个没有指派任何槽的节点
CLUSTER SETSLOT &lt;slot&gt; NODE &lt;node_id&gt;       将当前节点指定的槽（slot）指派给node_id指定的节点，如果槽已经指派给另一个节点，那么先让另一个节点删除该槽，然后再进行指派
CLUSTER SETSLOT &lt;slot&gt; MIGRATING &lt;node_id&gt;  将当前节点指定的槽（slot）迁移到node_id指定的节点中
CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;node_id&gt;  从node_id指定节点中的槽（slot）导入到当前节点
CLUSTER SETSLOT &lt;slot&gt; STABLE               取消对当前节点指定槽（slot）的导入（import）或者迁移（migrate）
CLUSTER SLOTS                               查看槽（slot）在集群中的分配情况

<span class="hljs-comment">// 键 (key)  </span>
CLUSTER KEYSLOT &lt;key&gt;                       计算键key应该被分配在哪个槽上  
CLUSTER COUNTKEYSINSLOT &lt;slot&gt;              返回指定槽（slot）保存key的数量  
CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;        获取指定槽（slot）中count个key，如果指定槽中大于count个key，则只返回前<span class="hljs-built_in">cout</span>个key，小于或为空，则返回最多数量的key </code></pre></div>
<h2 id="读写操作">读写操作</h2>
<h3 id="写入数据">写入数据</h3>
<ul>
<li>
<p>流程图<br />
<img src="/_resources/0813f71424fe4908a017f95c67848f24.png" /></p>
</li>
<li>
<p>写入实例<br />
<img src="/_resources/a2ab59b781f94d9aaf7fda7dfa4fd79f.png" /></p>
</li>
</ul>
<h3 id="计算slot">计算slot</h3>
<ul>
<li><code>keyslot KEY</code><br />
<img src="/_resources/a6c0c8b71c8c49b7b7a271828b1b2e3f.png" /></li>
</ul>
<h3 id="集群方式链接">集群方式链接</h3>
<ul>
<li><code>-c</code> 自动实现slot重定向<br />
<img src="/_resources/7370510502b14c0fbd2040d5ef610fef.png" /></li>
</ul>
<h3 id="python客户端访问">python客户端访问</h3>
<blockquote>
<p>需要先使用 pip 安装 <code>redis-py-cluster</code><br />
<a>0xff redis/脚本使用#cluster调用</a></p>
</blockquote>
<blockquote>
<p>测试结果可见分布较为平均<br />
<img src="/_resources/7c39be6a5a8841c6b824a1fec908fca9.png" /></p>
</blockquote>
<h2 id="管理">管理</h2>
<h3 id="增加slave节点">增加slave节点</h3>
<ol>
<li><a>0xff redis/脚本使用#源安装脚本</a></li>
<li><a title="#%E4%BF%AE%E6%94%B9%E5%8F%82%E6%95%B0" href="#%E4%BF%AE%E6%94%B9%E5%8F%82%E6%95%B0">修改参数</a></li>
<li>查询master节点的 master-id
<blockquote>
<p>redis-cli -h 127.0.0.1 -a alopex --no-auth-warning cluster nodes<br />
<img src="/_resources/6ac6c0e35a8543a38119a695af3bf404.png" /></p>
</blockquote>
</li>
<li>添加 slave 节点<div><pre class="hljs"><code>redis-cli -a &lt;auth-passwd&gt; \
--cluster add-node &lt;current-slave-node:6379&gt; &lt;oneof-cluster-node:6379&gt; \
--cluster-slave --cluster-master-id &lt;cluster-master-id&gt;</code></pre></div>
<img src="/_resources/1187f064af4640d69ca023d2ab1746e7.png" /></li>
<li>确认新增 slave<br />
<img src="/_resources/23df5f2ea33541618fe07d4b6321ff4b.png" /><br />
<img src="/_resources/1c6d4bba41c04581bbcca5c67f6d808b.png" /></li>
</ol>
<h3 id="故障迁移">故障迁移</h3>
<ul>
<li>
<p>全master集群 （无容错能力，节点故障后数据丢失）<br />
<img src="/_resources/fb1ec9a577e44a59bd1fa8b39230b678.png" /></p>
<ul>
<li>需要实现故障迁移，应在设计至少使用<code>6台主机</code>或为其增加<code>slave</code>节点<div><pre class="hljs"><code>redis-cli -a <span class="hljs-number">123456</span> --cluster-replicas \
--cluster-replicas \
--cluster create <span class="hljs-number">10.0.0.18</span>:<span class="hljs-number">6379 10.0</span>.<span class="hljs-number">0.28:6379</span> <span class="hljs-number">10.0.0.58</span>:<span class="hljs-number">6379</span> \
<span class="hljs-number">10.0.0.8</span>:<span class="hljs-number">6379 10.0</span>.<span class="hljs-number">0.38:6379</span> <span class="hljs-number">10.0.0.48</span>:<span class="hljs-number">6379</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p>拥有slave节点的master节点故障 (拥有容错能力，主节点故障后slave节点会顶替工作)</p>
<ul>
<li><img src="/_resources/877139df2eb8409bb45bec622a9c1c16.png" /></li>
<li><img src="/_resources/869d89fecd23456fb239298271015218.png" /></li>
</ul>
</li>
</ul>
<h3 id="集群扩容">集群扩容</h3>
<p>!!! success 场景思路</p>
<blockquote>
<p>场景：现有的Redis cluster架构已经无法满足越来越高的并发访问请求，需要添加新的主机提高并发能力。<br />
思路：先添加节点，在扩展槽位，最后为master加上slave。<br />
!!!</p>
</blockquote>
<p>!!! warning master数量<br />
注意: 生产环境一般建议master节点为<code>奇数</code>个,比如:<code>3,5,7</code>,以防止脑裂现象</p>
<p>&lt; 本地为实验环境，为方便操作仅添加一台master，凑成4台master。&gt;<br />
!!!</p>
<ul>
<li>步骤图解<br />
<img src="/_resources/379e373510bb4987a7e2364c8517e651.png" /><br />
<img src="/_resources/856df059cbb746b5b75831d9a0954e58.png" /></li>
</ul>
<p>!!! info 实际操作<br />
0. 查看当前 <code>slot</code> 分配信息<br />
<img src="/_resources/2ef43085795c4773a1a4c37435dd6a22.png" /><br />
2. 准备新的redis节点，配置使用cluster配置<br />
<a>0xff redis/脚本使用#个人源安装脚本</a><br />
<a title="#%E4%BF%AE%E6%94%B9%E5%8F%82%E6%95%B0" href="#%E4%BF%AE%E6%94%B9%E5%8F%82%E6%95%B0">修改参数</a><br />
2. 添加新的master节点到集群<br />
<code> 	redis-cli -a &lt;auth-passwd&gt; --cluster add-node &lt;current-node-ip:6379&gt; &lt;oneof-cluster-node-ip:6379&gt; 	</code><br />
<img src="/_resources/58c028a04a924d6399c6442fb098cbc6.png" /><br />
3. 检查是新节点是否连接<br />
&gt; redis-cli -h 192.168.100.102 -a alopex --no-auth-warning --cluster info 192.168.100.101:6379<br />
<img src="/_resources/abf41bb7073042468bc3764b678ae164.png" /><br />
4. 重新分配 <code>slot</code> （仅5+版本支持在线扩容，旧版本需要备份、清空槽数据、再恢复）<br />
<code> 	redis-cli -a &lt;auth-passwd&gt; --cluster reshard &lt;oneof-cluster-node-ip&gt;:6379 	</code><br />
* slot数量<br />
* 需要分配的 <code>slot</code> 数量 (16384/master个数)<br />
* 接收slot的ID<br />
* 新的master的ID (没有<code>slot</code>的主机，新加入的主机)<br />
* 接收slot的策略 (新增选择 <code>ALL</code>)<br />
* <strong>使用 "all"</strong>：当你想要将集群中所有现有节点都指定为哈希槽的源节点时，你会使用 "all"。<br />
* 这在你<code>向集群添加新节点时很有用</code>，你希望现有节点将它们的哈希槽<code>均匀地分配给它们自己和新节点</code>。<br />
* <strong>使用 "done"</strong>：当你<code>完成手动输入所有源节点ID的任务</code>时，你会使用 "done"。<br />
* 这表示你已经完成了指定哈希槽重新分配的源节点的任务。<br />
5. 检查新的 <code>slot</code> 分配信息<br />
<img src="/_resources/c5b46beb6e124feb994296b0dcd601a0.png" /><br />
6. 如集群中需要从节点，可选择对slave扩容<br />
<a title="#%E5%A2%9E%E5%8A%A0slave%E8%8A%82%E7%82%B9" href="#%E5%A2%9E%E5%8A%A0slave%E8%8A%82%E7%82%B9">增加slave节点</a><br />
!!!</p>
<h3 id="集群缩容">集群缩容</h3>
<p>!!! success 场景思路</p>
<blockquote>
<p>场景：随着业务萎缩用户量下降明显，redis服务器负载出现闲置，需要对其进行资源释放<br />
思路：再回收槽位，删除主节点，最后删除从节点。<br />
!!!</p>
</blockquote>
<p>!!! info 实际操作<br />
0. 当前集群情况 (master:4, slave:1)<br />
<img src="/_resources/f3ad8277303c40d5872211bcf89b59fd.png" /><br />
<img src="/_resources/6d25f75aa16f43148f77cd50b385f4ab.png" /></p>
<ol>
<li>
<p>回收槽位</p>
<div><pre class="hljs"><code>redis-<span class="hljs-keyword">cli</span> -a &lt;auth-passwd&gt; --<span class="hljs-keyword">cluster</span> reshard &lt;oneof-<span class="hljs-keyword">cluster</span>-node-ip&gt;:6379</code></pre></div>
<ul>
<li>slot数量
<ul>
<li>需要分配的 <code>slot</code> 数量 (回收主机拥有slot数/回收后master数量 --&gt; 4096/3=1365)</li>
<li>此处使用了均分的方式，因此每次<code>只移动1/3</code>的slot</li>
</ul>
</li>
<li>接受slot的ID (选择用于回收slot的master ID，多master可以任选)
<ul>
<li>用于接收释放的 <code>slot</code></li>
</ul>
</li>
<li>回收slot的策略 (删除写入<code>需要删除的节点</code>--&gt;<code>Done</code>)
<ul>
<li><strong>使用 "all"</strong>：当你想要将集群中所有现有节点都指定为哈希槽的源节点时，你会使用 "all"。
<ul>
<li>这在你<code>向集群添加新节点时很有用</code>，你希望现有节点将它们的哈希槽<code>均匀地分配给它们自己和新节点</code>。</li>
</ul>
</li>
<li><strong>使用 "done"</strong>：当你<code>完成手动输入所有源节点ID的任务</code>时，你会使用 "done"。
<ul>
<li>这表示你已经完成了指定哈希槽重新分配的源节点的任务。</li>
</ul>
</li>
</ul>
</li>
<li>交互式执行 (1次)
<ul>
<li><img src="/_resources/4e95461006de41bb8426ed5920148c21.png" /></li>
</ul>
</li>
<li>非交互形式执行 (2次)<div><pre class="hljs"><code>redis-cli -a &lt;auth-passwd&gt; --cluster reshard 192.168.100.102:6379 \
--cluster-slots 1365 --cluster-from &lt;node-need-to-delete-ID&gt; \
--cluster-to &lt;node-will-receive-slot-ID&gt; --cluster-yes

eg:
<span class="hljs-comment"># 103 接收 101 放弃的 1365 个 slot </span>
redis-cli -a alopex --cluster reshard 192.168.100.102:6379 \
--cluster-slots 1365 --cluster-from af550d85cf75582eb485b7c06924f22a8a1a8a87 \
--cluster-to 56ae4fbb871e4fb8a47cb06ef39d4387751efb60 --cluster-yes

<span class="hljs-comment"># 104 接收 101 放弃的 1366 个 slot </span>
redis-cli -a alopex --cluster reshard 192.168.100.102:6379 \
--cluster-slots 1366 --cluster-from af550d85cf75582eb485b7c06924f22a8a1a8a87 \
--cluster-to ee5da0388305257fee5b553ae56751e10ec344a8 --cluster-yes</code></pre></div>
</li>
</ul>
</li>
<li>
<p>确认slot已被回收</p>
<blockquote>
<p>redis-cli -h 127.0.0.1 -a alopex --no-auth-warning --cluster check 192.168.100.108:6379<br />
可以看到此前的 101 和 108 默认成为了 104 的 slave<br />
<img src="/_resources/93eec57ddea74ef6aee1e06547917777.png" /><br />
<img src="/_resources/455c780d2d934cc2be1858f20df14665.png" /></p>
</blockquote>
</li>
<li>
<p>删除slave节点</p>
<blockquote>
<p>redis-cli -a &lt;\auth-passwd&gt; --cluster del-node &lt;\oneof-cluster-node&gt;:6379 &lt;\slave-node-need-to-del-ID&gt;<br />
<img src="/_resources/8c2d81c82c794eb5ae84d8029dc3f94a.png" /></p>
</blockquote>
</li>
<li>
<p>节点信息更新</p>
<blockquote>
<p>redis-cli -a &lt;\auth-passwd&gt; --no-auth-warning cluster nodes<br />
<img src="/_resources/562a75690aa2485599b3235ae26cbb36.png" /><br />
!!!</p>
</blockquote>
</li>
</ol>
<h3 id="集群倾斜">集群倾斜</h3>
<blockquote>
<p>场景：多个节点运行一段时间后,可能会出现倾斜现象,某个节点数据偏多,内存消耗更大,</p>
</blockquote>
<ul>
<li>
<p>原因：</p>
<ul>
<li>节点和槽分配不均</li>
<li>不同槽对应键值数量差异较大</li>
<li>包含bigkey,建议少用</li>
<li>内存相关配置不一致</li>
<li>热点数据不均衡 : 一致性不高时,可以使用本缓存和MQ</li>
</ul>
</li>
<li>
<p>解决方式</p>
<ul>
<li>执行自动的槽位重新平衡分布,但<code>会影响客户端的访问</code></li>
<li>redis-cli --cluster rebalance &lt;集群节点IP:PORT&gt;</li>
</ul>
</li>
</ul>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[第四周作业]]></title>
            <guid>be327d9451b24263a584cc57ae4c5967</guid>
            <pubDate>Sat, 27 Apr 2024 23:58:08 GMT</pubDate>
            <content:encoded><![CDATA[<nav class="table-of-contents"><ul><li><a href="#dockerfile命令">Dockerfile命令.</a><ul><li><a href="#dockerfile命令-1">Dockerfile命令</a><ul><li><a href="#from">FROM</a></li><li><a href="#label">LABEL</a></li><li><a href="#run">RUN</a></li><li><a href="#env">ENV</a></li><li><a href="#copy">COPY</a></li><li><a href="#add">ADD</a></li><li><a href="#cmd">CMD</a></li><li><a href="#entrypoint">ENTRYPOINT</a></li><li><a href="#arg">ARG</a></li><li><a href="#volume">VOLUME</a></li><li><a href="#expose">EXPOSE</a></li><li><a href="#workdir">WORKDIR</a></li><li><a href="#onbuild">ONBUILD</a></li><li><a href="#user">USER</a></li><li><a href="#healthcheck">HEALTHCHECK</a></li><li><a href="#dockerignore-文件">.dockerignore 文件</a></li></ul></li></ul></li><li><a href="#docker-网络模式">Docker 网络模式</a><ul><li><a href="#默认网络">默认网络.</a><ul><li><a href="#容器间通信">容器间通信</a></li><li><a href="#自定义ip段">自定义IP段</a></li><li><a href="#自定义网桥">自定义网桥</a></li><li><a href="#容器间互联">容器间互联</a></li></ul></li><li><a href="#网络连接模式">网络连接模式.</a><ul><li><a href="#bridge-桥接模式">Bridge (桥接模式)</a></li><li><a href="#host-主机模式">Host (主机模式)</a></li><li><a href="#none-无网络">none (无网络)</a></li><li><a href="#container-容器网络">container (容器网络)</a></li><li><a href="#自定义网络">自定义网络</a></li></ul></li></ul></li><li><a href="#harbor私有仓库">Harbor私有仓库</a><ul><li><a href="#基本操作">基本操作</a><ul><li><a href="#上传镜像">上传镜像</a></li><li><a href="#下载镜像">下载镜像</a></li><li><a href="#更新配置">更新配置</a></li></ul></li><li><a href="#https请求实现">https请求实现.</a></li></ul></li><li><a href="#jumpserver安装和使用">JumpServer安装和使用</a><ul><li><a href="#部署">部署</a><ul><li><a href="#离线部署">离线部署</a></li><li><a href="#脚本部署">脚本部署</a></li><li><a href="#访问方式">访问方式</a></li><li><a href="#服务管理">服务管理</a></li></ul></li><li><a href="#常用功能">常用功能</a><ul><li><a href="#管理员">管理员</a><ul><li><a href="#创建用户组">创建用户组</a></li><li><a href="#配置用户-登录名称-leslie">配置用户 (登录名称 leslie)</a></li><li><a href="#创建资产">创建资产</a></li><li><a href="#账户模板">账户模板</a></li><li><a href="#账户推送">账户推送</a></li><li><a href="#用户登录">用户登录</a></li><li><a href="#创建授权策略">创建授权策略</a></li><li><a href="#命令执行限制">命令执行限制</a></li></ul></li><li><a href="#操作员">操作员</a><ul><li><a href="#登录账户">登录账户</a></li><li><a href="#webshell登录用户">webshell登录用户</a></li><li><a href="#webshell命令限制">webshell命令限制</a></li></ul></li><li><a href="#审计员">审计员</a><ul><li><a href="#会话查看">会话查看</a></li><li><a href="#命令记录">命令记录</a></li><li><a href="#查看录制视频">查看录制视频</a></li><li><a href="#登录日志">登录日志</a></li><li><a href="#操作日志">操作日志</a></li><li><a href="#改密日志">改密日志</a></li></ul></li></ul></li></ul></li></ul></nav><h1 id="dockerfile命令">Dockerfile命令.</h1>
<h2 id="dockerfile命令-2">Dockerfile命令</h2>
<h3 id="from">FROM</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>所有的镜像都通过基础镜像而来，该语句指定基础镜像是谁，基于什么镜像来做。</li>
</ul>
</li>
<li>格式
<ul>
<li>
<p>FROM [--platform=&lt;platform&gt;] &lt;image&gt; [AS &lt;name&gt;]</p>
</li>
<li>
<p>FROM [--platform=&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]</p>
</li>
<li>
<p>FROM [--platform=&lt;platform&gt;] &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;]</p>
</li>
<li>
<p><code>--platform</code> 指定镜像的平台，比如: <code>linux/amd64</code>, <code>linux/arm64</code>, or <code>windows/amd64</code></p>
</li>
<li>
<p><code>tag</code> 和 <code>digest</code>是可选项，如果不指定，默认为<code>latest</code><br />
!!!</p>
</li>
</ul>
</li>
</ul>
<p>!!! tip 常见用法</p>
<ol>
<li>
<p>完全自建镜像，需要空镜像<br />
FROM scratch</p>
<blockquote>
<p>scratch是一切镜像的起源，它本身无具体的操作系统，可以理解为一个占位符<br />
它本质上是一个 0 字节的镜像<br />
对于静态编译中，多阶段编译有奇效</p>
</blockquote>
<div><pre class="hljs"><code><span class="hljs-comment"># 使用 golang 基础镜像进行构建</span>
<span class="hljs-keyword">FROM</span> golang:<span class="hljs-number">1.16</span> AS builder

<span class="hljs-comment"># 设置工作目录</span>
<span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span>

<span class="hljs-comment"># 复制 Go 项目文件到容器中</span>
<span class="hljs-keyword">COPY</span><span class="language-bash"> . .</span>

<span class="hljs-comment"># 静态编译 Go 程序</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o myapp .</span>

<span class="hljs-comment"># 使用 scratch 空白镜像作为最终镜像</span>
<span class="hljs-keyword">FROM</span> scratch

<span class="hljs-comment"># 从构建阶段复制编译好的可执行文件到最终镜像</span>
<span class="hljs-keyword">COPY</span><span class="language-bash"> --from=builder /app/myapp /</span>

<span class="hljs-comment"># 定义容器启动时执行的命令</span>
<span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">"/myapp"</span>]</span></code></pre></div>
</li>
<li>
<p>从精简操作系统的基础下构建<br />
FROM busybox / FROM alpine</p>
<blockquote>
<p>精简操作系统一般在 <code>10M</code>之内，这些系统具备最基础的功能能够胜任一般的错误排查<br />
不至于如空白镜像，需要自行对工具进行选型、依赖解决等、可以较好地完成部署任务<br />
是一个性价比极高的基础镜像</p>
</blockquote>
</li>
<li>
<p>从完整操作系统镜像下构建<br />
FROM ubuntu / FROM Rockylinux</p>
<blockquote>
<p>这些一般为主流操作系统，用户最为熟悉，拥有的系统工具丰富，对于故障和配置排查提供了基础<br />
一般具备主流的bash，而不是精简系统的sh<br />
大小一般在<code>100M</code>到<code>500M</code>之间</p>
</blockquote>
</li>
<li>
<p>从应用镜像构建<br />
FROM redis / FROM jenkins</p>
<blockquote>
<p>这类镜像已经是完整的应用，其空间大小与应用和其选择的系统基座相关<br />
从这一类镜像进行构建，一般是为了实现告警的自定义功能或精简配置<br />
!!!</p>
</blockquote>
</li>
</ol>
<p>!!! warning 注意事项</p>
<ul>
<li>应尽量选择体积小的镜像构建，有助于提升性能和资源的使用比<br />
!!!</li>
</ul>
<h3 id="label">LABEL</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>指定元数据，用于标识系统地址、用户、帐号、维护者等公开信息</li>
</ul>
</li>
<li>格式
<ul>
<li>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! tip 常见用法</p>
<ul>
<li>维护者信息<div><pre class="hljs"><code><span class="hljs-keyword">LABEL</span><span class="language-bash"> maintainer=<span class="hljs-string">"alfiecheung &lt;root@alfiecheung.com&gt;"</span></span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! warning 注意事项<br />
无<br />
!!!</p>
<h3 id="run">RUN</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>用来在<code>构建镜像</code>阶段需要执行 FROM 指定镜像所支持的Shell命令</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-comment">#shell 格式: 相当于 /bin/sh -c</span>
&lt;命令&gt;
此种形式支持环境变量
<span class="hljs-keyword">RUN</span><span class="language-bash"> &lt;命令&gt;</span>
<span class="hljs-comment">#exec 格式: 此种形式不支持环境变量,注意:是双引号,不能是单引号</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> [<span class="hljs-string">"executable"</span>,<span class="hljs-string">"param1"</span>,<span class="hljs-string">"param2"</span>...]</span>
<span class="hljs-comment">#exec格式可以指定其它shell</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> [<span class="hljs-string">"/bin/bash"</span>,<span class="hljs-string">"-c"</span>,<span class="hljs-string">"echo hello wang"</span>]</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<div><pre class="hljs"><code><span class="hljs-comment"># 多个命令通过 &amp;&amp; 操作符联合，为的是减少构建时的层数</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> yum -y install epel-release \
    &amp;&amp; yum -y install nginx \
    &amp;&amp; rm -rf /usr/share/nginx/html/*</span>
    &amp;&amp; echo <span class="hljs-string">"&lt;h1&gt; docker test nginx &lt;/h1&gt;"</span> &gt; /usr/share/nginx/html/index.html</code></pre></div>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ul>
<li>
<p>shell格式命令，默认使用<code>/bin/sh</code>去解析，具有较多的限制性</p>
</li>
<li>
<p>exec格式命令，可通过修改<code>第一个变量</code>为所需的<code>shell</code>进行命令那个解析</p>
</li>
<li>
<p>命令执行没有上下文，如下执行是错误的</p>
</li>
</ul>
<div><pre class="hljs"><code><span class="hljs-comment">#world.txt并不存放在/app内</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /app</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">"hello"</span> &gt; world.txt</span>

<span class="hljs-comment"># 应修改为</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">"hello"</span> &gt; /app/world.txt</span></code></pre></div>
<p>!!!</p>
<h3 id="env">ENV</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>环境变量的设置</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-comment">#变量赋值格式1</span>
<span class="hljs-comment">#此格式只能对一个key赋值,&lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分</span>
<span class="hljs-keyword">ENV</span> &lt;key&gt; &lt;value&gt;

<span class="hljs-comment">#变量赋值格式2</span>
<span class="hljs-comment">#此格式可以支持多个key赋值,定义多个变量建议使用,减少镜像层</span>
<span class="hljs-keyword">ENV</span> &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;</code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ol>
<li>
<p>配置应用程序参数</p>
<div><pre class="hljs"><code><span class="hljs-keyword">ENV</span> DATABASE_HOST=localhost
<span class="hljs-keyword">ENV</span> DATABASE_PORT=<span class="hljs-number">5432</span>
<span class="hljs-keyword">ENV</span> API_KEY=abc123</code></pre></div>
</li>
<li>
<p>指定工作目录</p>
<div><pre class="hljs"><code><span class="hljs-keyword">ENV</span> APP_HOME=/app
<span class="hljs-keyword">WORKDIR</span><span class="language-bash"> <span class="hljs-variable">$APP_HOME</span></span></code></pre></div>
</li>
<li>
<p>设置语言环境</p>
<div><pre class="hljs"><code><span class="hljs-keyword">ENV</span> LANG=en_US.UTF-<span class="hljs-number">8</span>
<span class="hljs-keyword">ENV</span> LC_ALL=en_US.UTF-<span class="hljs-number">8</span></code></pre></div>
</li>
<li>
<p>传递构建参数</p>
<div><pre class="hljs"><code><span class="hljs-keyword">ARG</span> VERSION
<span class="hljs-keyword">ENV</span> APP_VERSION=$VERSION</code></pre></div>
</li>
</ol>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ul>
<li>ENV 可以定义环境变量和值</li>
<li>能被后续指令(如:ENV,ADD,COPY,RUN等)通过$KEY或${KEY}<code>进行引用</code>，并在容器<code>运行时保持</code><div><pre class="hljs"><code><span class="hljs-keyword">FROM</span>  rockylinux:<span class="hljs-number">9.3</span> 
<span class="hljs-keyword">LABEL</span><span class="language-bash"> maintainer=<span class="hljs-string">"alfiecheung &lt;root@alfiecheung.com&gt;"</span></span>
<span class="hljs-keyword">ENV</span> name=<span class="hljs-string">"leslie"</span> age=<span class="hljs-number">20</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">"<span class="hljs-variable">${name}</span>:<span class="hljs-variable">${age}</span>"</span> &gt; /tmp/test.txt</span>

<span class="hljs-comment"># 通过运行容器，查看 /tmp/test.txt</span>
<span class="hljs-comment"># docker run --rm rocky:env-test2 cat /tmp/test.txt</span>
<span class="hljs-comment"># leslie:20</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<h3 id="copy">COPY</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>本地宿主机与容器之间文件的互相复制</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-keyword">COPY</span><span class="language-bash"> [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span>
<span class="hljs-keyword">COPY</span><span class="language-bash"> [--chown=&lt;user&gt;:&lt;group&gt;] [<span class="hljs-string">"&lt;src&gt;"</span>,... <span class="hljs-string">"&lt;dest&gt;"</span>] <span class="hljs-comment">#路径中有空白字符时,建议使用此格式</span></span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ol>
<li>
<p><strong>复制单个文件</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">COPY</span><span class="language-bash"> source.txt /app/destination.txt</span></code></pre></div>
<p>将主机上的 <code>source.txt</code> 文件复制到容器中的 <code>/app/destination.txt</code>。</p>
</li>
<li>
<p><strong>复制整个目录</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">COPY</span><span class="language-bash"> source_directory /app/destination_directory</span></code></pre></div>
<p>将主机上的 <code>source_directory</code> 目录及其所有内容递归地复制到容器中的 <code>/app/destination_directory</code>。</p>
</li>
<li>
<p><strong>复制多个文件</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">COPY</span><span class="language-bash"> file1.txt file2.txt /app/</span></code></pre></div>
<p>将主机上的 <code>file1.txt</code> 和 <code>file2.txt</code> 文件复制到容器中的 <code>/app/</code> 目录。</p>
</li>
<li>
<p><strong>使用通配符复制多个文件</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">COPY</span><span class="language-bash"> *.txt /app/</span></code></pre></div>
<p>将主机上所有以 <code>.txt</code> 结尾的文件复制到容器中的 <code>/app/</code> 目录。</p>
</li>
<li>
<p><strong>复制远程文件</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">COPY</span><span class="language-bash"> https://example.com/file.txt /app/</span></code></pre></div>
<p>从远程 URL 下载文件 <code>file.txt</code> 并复制到容器中的 <code>/app/</code> 目录。</p>
</li>
<li>
<p><strong>复制文件并更改权限</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">COPY</span><span class="language-bash"> --chown=user:group source.txt /app/destination.txt</span></code></pre></div>
<p>将主机上的 <code>source.txt</code> 文件复制到容器中的 <code>/app/destination.txt</code>，并将文件的所有者设置为 <code>user</code>，组设置为 <code>group</code>。</p>
</li>
<li>
<p><strong>复制文件到特定构建阶段</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">FROM</span> builder as build
<span class="hljs-keyword">COPY</span><span class="language-bash"> source.txt /app/destination.txt</span></code></pre></div>
<p>在多阶段构建中，将 <code>source.txt</code> 文件从 <code>builder</code> 阶段复制到 <code>build</code> 阶段的容器中。<br />
!!!</p>
</li>
</ol>
<p>!!! warning 注意事项</p>
<ul>
<li><code>源文件路径</code>
<ul>
<li>COPY 命令的第一个参数是源文件或目录的路径。</li>
<li>在指定路径时，可以是相对于 <code>Dockerfile</code> 所在目录的相对路径，也可以是一个<code>绝对路径</code>。</li>
</ul>
</li>
<li><code>目标路径</code>
<ul>
<li>COPY 命令的第二个参数是目标路径，表示要将源文件或目录复制到容器中的位置。</li>
<li>这个路径可以是容器内的绝对路径，也可以是相对于容器工作目录的路径。如果目标路径不存在，则会<code>自动创建</code>。</li>
</ul>
</li>
<li><code>目录复制</code>
<ul>
<li>如果源路径是一个目录，COPY 命令将<code>递归地复制该目录及其所有内容</code>，但<code>不复制目录自身</code>。</li>
<li>目标路径必须是一个已存在的目录，或者在构建过程中已经创建。</li>
</ul>
</li>
<li><code>文件权限</code>
<ul>
<li>使用 COPY 命令复制文件时，文件的<code>权限将保持不变</code>。</li>
<li>如果需要更改文件的权限，可以<code>使用 RUN 命令在 Dockerfile 中进行相应的权限</code>更改操作。</li>
</ul>
</li>
<li><code>使用通配符</code>
<ul>
<li>COPY 命令支持使用通配符来复制多个文件。</li>
<li>例如，<code>COPY *.txt /app/</code> 将复制所有以 <code>.txt</code> 结尾的文件到容器的 <code>/app/</code> 目录。</li>
</ul>
</li>
<li><code>多个复制操作</code>
<ul>
<li>可以在 Dockerfile 中使用多个 COPY 命令来复制不同的文件或目录到容器中。</li>
<li>这些复制操作将按照在 Dockerfile 中的顺序依次执行。</li>
</ul>
</li>
<li><code>文件排除</code>
<ul>
<li>可以使用 <code>.dockerignore</code> 文件来排除不需要复制到镜像中的文件和目录。</li>
<li><code>.dockerignore</code> 文件的格式类似于 .gitignore 文件，可以通过添加规则来过滤文件和目录。</li>
</ul>
</li>
</ul>
<p>!!!</p>
<h3 id="add">ADD</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>支持将压缩文件进行复制解压</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-keyword">ADD</span><span class="language-bash"> [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span>
<span class="hljs-keyword">ADD</span><span class="language-bash"> [--chown=&lt;user&gt;:&lt;group&gt;] [<span class="hljs-string">"&lt;src&gt;"</span>,... <span class="hljs-string">"&lt;dest&gt;"</span>]</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ul>
<li>如果是一个 <code>URL</code> ，下载后的文件权限自动设置为 <code>600</code></li>
<li>如果是一个本地文件系统上的打包文件,如: gz, bz2 ,xz ，它将被解包 ，其行为类似于"tar -x"命令, 但是<code>通过URL获取到的tar文件</code>将<code>不会自动展开</code><br />
!!!</li>
</ul>
<h3 id="cmd">CMD</h3>
<p><img src="/_resources/1e3b9a8514b142cf874428f42050682d.png" /><br />
!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>设置容器启动时要执行的<code>默认命令</code></li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-comment"># 使用 exec 执行，推荐方式，第一个参数必须是命令的全路径,此种形式不支持环境变量</span>
<span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">"executable"</span>,<span class="hljs-string">"param1"</span>,<span class="hljs-string">"param2"</span>]</span>

<span class="hljs-comment"># 在 /bin/sh 中执行，提供给需要交互的应用；此种形式支持环境变量</span>
<span class="hljs-keyword">CMD</span><span class="language-bash"> <span class="hljs-built_in">command</span> param1 param2</span>

<span class="hljs-comment"># 提供给 ENTRYPOINT 命令的默认参数</span>
<span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">"param1"</span>,<span class="hljs-string">"param2"</span>]</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ol>
<li>
<p><strong>执行单个命令</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">CMD</span><span class="language-bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">"Hello, Docker!"</span></span></code></pre></div>
<p>在容器启动时执行 <code>echo "Hello, Docker!"</code> 命令。</p>
</li>
<li>
<p><strong>执行可执行文件</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">CMD</span><span class="language-bash"> ./myapp</span></code></pre></div>
<p>在容器启动时执行名为 <code>myapp</code> 的可执行文件。</p>
</li>
<li>
<p><strong>指定命令和参数</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">"python"</span>, <span class="hljs-string">"app.py"</span>]</span></code></pre></div>
<p>在容器启动时执行 <code>python app.py</code> 命令。</p>
</li>
<li>
<p><strong>使用 Shell 执行命令</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">CMD</span><span class="language-bash"> bash -c <span class="hljs-string">"echo Welcome; echo to Docker"</span></span></code></pre></div>
<p>在容器启动时使用 Shell 执行复杂的命令或命令序列。</p>
</li>
<li>
<p><strong>覆盖 CMD</strong>:<br />
在运行容器时，可以使用 <code>docker run</code> 命令的参数来覆盖 <code>CMD</code> 命令。例如：</p>
<div><pre class="hljs"><code>docker run myimage echo "Hello, World!"</code></pre></div>
<p>这将在容器运行时覆盖默认的 <code>CMD</code> 命令，并执行 <code>echo "Hello, World!"</code>。</p>
</li>
<li>
<p><strong>作为ENTRYPOINT的参数</strong>:</p>
<div><pre class="hljs"><code><span class="hljs-keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="hljs-string">"echo"</span>, <span class="hljs-string">"Hello,"</span>]</span>
<span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">"Docker!"</span>]</span></code></pre></div>
</li>
</ol>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ol>
<li>作为默认执行命令
<ul>
<li><code>dockerfile</code> 里面没有<code>ENTRYPOINT命令</code> 且 <code>docker run</code>没有指定执行命令时</li>
</ul>
</li>
<li>最有最后一条生效
<ul>
<li>如果在<code>dockerfile</code> 中添加多个 <code>CMD</code>命令，后添加的<code>CMD</code>命令将覆盖前面添加的</li>
</ul>
</li>
<li>可以被替换
<ul>
<li><code>docker run</code>运行容器的过程中，可以指定<code>需要执行的命令</code>，这个命令将替代<code>dockerfile CMD</code>命令<br />
!!!</li>
</ul>
</li>
</ol>
<h3 id="entrypoint">ENTRYPOINT</h3>
<p><img src="/_resources/29ff5ff778c24015b5cffb4ccd8033ee.png" /><br />
!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>用于指定在容器启动时要<code>执行的可执行命令或脚本</code>。</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-comment"># 使用 exec 执行</span>
<span class="hljs-keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="hljs-string">"executable"</span>, <span class="hljs-string">"param1"</span>, <span class="hljs-string">"param2"</span>...]</span>
<span class="hljs-comment"># shell中执行</span>
<span class="hljs-keyword">ENTRYPOINT</span><span class="language-bash"> <span class="hljs-built_in">command</span> param1 param2</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ul>
<li>
<p>运行环境配置</p>
<div><pre class="hljs"><code><span class="hljs-keyword">FROM</span>  rockylinux:<span class="hljs-number">9.3</span>
<span class="hljs-keyword">LABEL</span><span class="language-bash"> maintainer=<span class="hljs-string">"alfiecheung &lt;root@alfiecheung.com&gt;"</span></span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> sed -e <span class="hljs-string">'s|^mirrorlist=|#mirrorlist=|g'</span> \
    -e <span class="hljs-string">'s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g'</span> \
    -i.bak /etc/yum.repos.d/rocky-*.repo </span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> dnf install -y nginx &amp;&amp;  rm -rf /var/cache/dnf/*</span>

<span class="hljs-keyword">COPY</span><span class="language-bash"> entry.sh /tmp</span>
<span class="hljs-keyword">RUN</span><span class="language-bash"> chmod a+x /tmp/entry.sh</span>

<span class="hljs-keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="hljs-string">"/tmp/entry.sh"</span>]</span>
<span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">"nginx"</span>, <span class="hljs-string">"-g"</span>, <span class="hljs-string">"daemon off;"</span>]</span></code></pre></div>
<div><pre class="hljs"><code><span class="hljs-meta">#!/bin/sh</span>
<span class="hljs-comment"># 创建nginx配置文件</span>
<span class="hljs-comment"># 变量可以使用默认变量值（即 :- 后的内容）</span>
<span class="hljs-comment"># 或通过 ENV / docker run -e 提供变量内容进行覆盖</span>
cat &gt; /etc/nginx/conf.d/custome.conf &lt;&lt;<span class="hljs-string">EOF
server {
  server_name ${HOSTNAME:-"wwww.alopex.com"};
  listen ${IP:-"0.0.0.0"}:${PORT:-8080};
  root ${DOC_ROOT:-"/usr/share/nginx/html"};
}
EOF</span>

<span class="hljs-comment"># 创建目录</span>
mkdir -p <span class="hljs-variable">${DOC_ROOT:-/usr/share/nginx/html}</span>

<span class="hljs-comment"># 自定义主页</span>
<span class="hljs-built_in">echo</span> <span class="hljs-variable">${HOSTNAME:-"www.alopex.com"}</span> &gt; <span class="hljs-variable">${DOC_ROOT:-/usr/share/nginx/html}</span>/index.html

<span class="hljs-comment"># 通过exec接受CMD“参数”/ docker run “命令”</span>
<span class="hljs-comment"># 由于exec 内建命令可替换当前shell，因此首命令可由用户指定需要执行的命令，而不仅仅只是参数传递</span>
<span class="hljs-comment"># 提高了脚本的灵活性，是一个约定成俗的操作</span>
<span class="hljs-built_in">exec</span> <span class="hljs-string">"<span class="hljs-variable">$@</span>"</span></code></pre></div>
<div><pre class="hljs"><code><span class="hljs-comment"># 创建镜像</span>
docker build -t rocky-nginx:entry-v2 .

<span class="hljs-comment"># 启动容器</span>
<span class="hljs-comment">## 自定义hostname和port变量，能够在配置中修改</span>
docker run -d -e PORT=9090 \
-e HOSTNAME=<span class="hljs-string">"www.leslie.com"</span> \
-e DOC_ROOT=<span class="hljs-string">"/tmp/cc"</span> rocky-nginx:entry-v2

<span class="hljs-comment"># 测试容器</span>
curl ip.ip.ip.ip:9090</code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ol>
<li>ENTRYPOINT接收docker run参数
<ul>
<li><code>docker run</code>提供的命令无法替换<code>ENTRYPOINT</code>，相反该命令将作为参数传递给<code>ENTRYPOINT</code></li>
<li>参数优先级
<ul>
<li><code>docker run</code></li>
<li><code>CMD</code></li>
</ul>
</li>
</ul>
</li>
<li>最有最后一条生效
<ul>
<li>如果在<code>dockerfile</code> 中添加多个 <code>ENTRYPOINT</code>命令，后添加的<code>ENTRYPOINT</code>命令将覆盖前面添加的<br />
!!!</li>
</ul>
</li>
</ol>
<h3 id="arg">ARG</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>Build 阶段指定变量</li>
</ul>
</li>
<li>格式
<ul>
<li>ARG &lt;name&gt;[=&lt;default value&gt;]<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! tip 常见用法</p>
<ul>
<li>与FROM结合，在构建时始终使用追新的images<div><pre class="hljs"><code><span class="hljs-keyword">ARG</span> CODE_VERSION=latest
<span class="hljs-keyword">FROM</span> base:${CODE_VERSION}</code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ul>
<li>唯一可以放置在<code>FROM</code>命令前的指令</li>
<li>ARG指令在build 阶段指定变量</li>
<li>和ENV不同的是，容器运行时并不存在ARG定义的环境变量</li>
<li>可以用 docker build --build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖<br />
!!!</li>
</ul>
<h3 id="volume">VOLUME</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>创建匿名卷</li>
<li>容器删除后默认将删除容器内数据，匿名卷是数据持久话的一个实现手段</li>
<li>持久化可以使得容器在删除后，挂载的匿名卷目录将继续保留</li>
<li>更多详细内容 <a>0x06 docker/存储管理</a></li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-keyword">VOLUME</span><span class="language-bash"> &lt;容器内路径&gt;</span>
<span class="hljs-keyword">VOLUME</span><span class="language-bash"> [<span class="hljs-string">"&lt;容器内路径1&gt;"</span>, <span class="hljs-string">"&lt;容器内路径2&gt;"</span>...]</span>
注意:
&lt;容器内路径&gt;如果在容器内不存在,在创建容器时会自动创建
&lt;容器内路径&gt;如果是存在的,同时目录内有内容,将会把此目录的内容复制到宿主机的实际目录</code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ul>
<li>挂载两个匿名卷
<ul>
<li>VOLUME [ "/data1","/data2" ]<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! warning 注意事项</p>
<ol>
<li>匿名卷默认路径<code>/var/lib/docker/volumes</code></li>
<li>数据存储目录 <code>/var/lib/docker/volumes/&lt;container-id&gt;/_data</code></li>
<li>匿名卷创建宿主机和镜像都<code>不需要要事先存在真实目录</code></li>
<li>挂载的匿名卷目录将在容器内自动创建</li>
<li>匿名卷无有效名称虽然<code>可保留数据</code>但<code>复用性不强</code>，容器删除后难以获取卷名称 (即数据保留的匿名卷)
<ul>
<li>容器挂载卷名称获取: <code>docker inspect --format '{{range .Mounts}}{{.Name}}{{end}}' &lt;container-id&gt;</code></li>
<li>名称例子：<code>9bcb9d85be8480d83e31ba6f08ba08c5669220c424a6313b318b2850e24353ba</code><br />
!!!</li>
</ul>
</li>
</ol>
<h3 id="expose">EXPOSE</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>用于启动容器时，端口暴露的标识</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-keyword">EXPOSE</span> &lt;port&gt;[/ &lt;protocol&gt;] [&lt;port&gt;[/ &lt;protocol&gt;] ..]</code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ul>
<li>暴露特定端口和协议
<ul>
<li>EXPOSE 11211/udp 11211/tcp<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! warning 注意事项</p>
<ol>
<li>EXPOSE仅仅只是一个便捷标识，并不意味这容器就使用其暴露的端口</li>
<li>EXPOSE主要是和<code>—P</code>临时端口映射配合使用，使用端口并非一定需要通过该语句暴露，也可以使用<code>-p host-port:container-port</code><br />
!!!</li>
</ol>
<h3 id="workdir">WORKDIR</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>指定工作目录</li>
<li>为后续的 <code>RUN, CMD, ENTRYPOINT</code> 指令配置工作目录，当容器运行后，进入容器内WORKDIR指定的默认目录</li>
</ul>
</li>
<li>格式
<ul>
<li></li>
</ul>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ul>
<li>指定当前的工作目录
<ul>
<li>WORKDIR /path/to/workdir<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! warning 注意事项</p>
<ol>
<li>指定存在的<code>workdir</code>将会被自动创建</li>
<li>在RUN可以生效,在CMD、ENTRYPOINT可能会有问题<br />
!!!</li>
</ol>
<h3 id="onbuild">ONBUILD</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>子镜像调用父镜像是执行的命令</li>
</ul>
</li>
<li>格式
<ul>
<li>ONBUILD [INSTRUCTION]<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! tip 常见用法</p>
<ul>
<li>通过该父镜像创建的子镜像都需要打上标签
<ul>
<li>ONBUILD RUN echo "alopex copyright C" &gt; /etc/parent-os<br />
!!!</li>
</ul>
</li>
</ul>
<p>!!! warning 注意事项</p>
<ol>
<li>ONBUILD不能自我能套，且不会触发FROM和MAINTAINER指令</li>
<li>推荐在标签中注明，例如 <code>ruby:1.9-onbuild</code></li>
<li>ONBUILD命令只能实现单次传递(直接继承的子代)，不会持续传递(间接继承的子代)<br />
!!!</li>
</ol>
<h3 id="user">USER</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>指定默认的容器运行用户名称或UID</li>
<li>后续dockerfile中的 RUN ，CMD和ENTRYPOINT指令时使用此用户</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-keyword">USER</span> &lt;<span class="hljs-keyword">user</span>&gt;[:&lt;group&gt;]
<span class="hljs-keyword">USER</span> &lt;UID&gt;[:&lt;GID&gt;]</code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ul>
<li>为数据库用户创建<code>musql</code>用户<div><pre class="hljs"><code><span class="hljs-keyword">RUN</span><span class="language-bash"> groupadd -r mysql &amp;&amp; useradd -r -g mysql mysql</span>
<span class="hljs-keyword">USER</span> mysql</code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<p>!!!</p>
<h3 id="healthcheck">HEALTHCHECK</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>容器启动后的状态检测，确认容器是否按照预订要求运行</li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code><span class="hljs-keyword">HEALTHCHECK</span><span class="language-bash"> [选项] CMD &lt;命令&gt; <span class="hljs-comment">#设置检查容器健康状况的命令,如果命令执行失败,则返回1,即 unhealthy</span></span>
<span class="hljs-keyword">HEALTHCHECK</span><span class="language-bash"> NONE <span class="hljs-comment">#如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令</span></span>

<span class="hljs-keyword">HEALTHCHECK</span><span class="language-bash"> 支持下列选项:</span>
--interval=&lt;间隔&gt; <span class="hljs-comment">#两次健康检查的间隔，默认为 30 秒</span>
--timeout=&lt;时长&gt; <span class="hljs-comment">#健康检查命令运行超时时间，如果超过这个时间，本次健康检查就被视为失败，默认 30 秒</span>
--retries=&lt;次数&gt; <span class="hljs-comment">#当连续失败指定次数后，则将容器状态视为 unhealthy，默认3次</span>
--start-period=&lt;FDURATION&gt; <span class="hljs-comment">#default: 0s </span>

<span class="hljs-comment">#检查结果返回值:</span>
<span class="hljs-number">0</span>  <span class="hljs-comment">#success the container is healthy and ready for use</span>
<span class="hljs-number">1</span>  <span class="hljs-comment">#unhealthythe container is not working correctly</span>
<span class="hljs-number">2</span>  <span class="hljs-comment">#reserveddo not use this exit code</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<ul>
<li>检测80请求是否正常<div><pre class="hljs"><code><span class="hljs-keyword">HEALTHCHECK</span><span class="language-bash"> --interval=5s --timeout=3s CMD curl -fs http://127.0.0.1:90/</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ol>
<li>healthcheck 是认为设定检测规则，unhealthy表示检测状态异常但不代表容器服务不可用</li>
<li>对于启动时间较长的容器，建起增大<code>timeout</code>时间</li>
<li>容器检查会造成额外的内部资源消耗<br />
!!!</li>
</ol>
<h3 id="dockerignore-文件">.dockerignore 文件</h3>
<p>!!!  note 基本信息</p>
<ul>
<li>用途
<ul>
<li>生成构建上下文时Docker客户端<code>忽略指定模式文件和文件夹</code></li>
</ul>
</li>
<li>格式<div><pre class="hljs"><code>#	#以#开头的行为注释
*	#匹配任何非分隔符字符序列
?	#匹配任何单个非分隔符
\\	#表示
**	#匹配任意数量的目录（包括零）例如，**<span class="hljs-comment">/*.go将排除在所有目录中以.go结尾的所有文件，包括构建上下文的根。
!	#表示取反，可用于排除例外情况</span></code></pre></div>
</li>
</ul>
<p>!!!</p>
<p>!!! tip 常见用法</p>
<div><pre class="hljs"><code><span class="hljs-comment">#排除 test 目录下的所有文件</span>
test/*
<span class="hljs-comment">#排除 md 目录下的 xttblog.md 文件</span>
md/xttblog.md
<span class="hljs-comment">#排除 xttblog 目录下的所有 .md 的文件</span>
xttblog/*<span class="hljs-string">.md</span>
<span class="hljs-comment">#排除以 xttblog 为前缀的文件和文件夹</span>
xttblog?
<span class="hljs-comment">#排除所有目录下的 .sql 文件夹</span>
**/*<span class="hljs-string">.sql</span></code></pre></div>
<p>!!!</p>
<p>!!! warning 注意事项</p>
<ul>
<li>通过创建<code>.dockerignore</code>文件实现<br />
!!!</li>
</ul>
<h1 id="docker-网络模式">Docker 网络模式</h1>
<h2 id="默认网络">默认网络.</h2>
<h3 id="容器间通信">容器间通信</h3>
<ul>
<li>容器之间默认互联互通，使用参数<code>--icc=true</code></li>
<li>修改容器之间不互联互通
<ul>
<li>启动文件修改 <code>/usr/lib/systemd/system/docker.service</code>
<ul>
<li><code>ExecStart=usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --icc=false</code></li>
<li><code>systemctl daemon-reload &amp;&amp; systemctl restart docker</code></li>
</ul>
</li>
<li>配置文件修改 <code>/etc/docker/daemon.json</code><div><pre class="hljs"><code><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">"icc"</span><span class="hljs-punctuation">:</span> <span class="hljs-keyword">false</span>
<span class="hljs-punctuation">}</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="自定义ip段">自定义IP段</h3>
<ul>
<li>默认IP段：<code>172.17.0.1/16</code></li>
<li>查看默认网段
<ul>
<li>
<p>ip addr show docker0<br />
<img src="/_resources/26cb8497733d45a2a3aaaac0963c73c0.png" /></p>
</li>
<li>
<p>docker network inspect &lt;bridge-name&gt;</p>
</li>
</ul>
</li>
<li>修改方式
<ul>
<li>启动文件修改 <code>/usr/lib/systemd/system/docker.service</code>
<ul>
<li><code>ExecStart=usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --bip=192.168.100.1/24</code></li>
<li><code>systemctl daemon-reload &amp;&amp; systemctl restart docker</code></li>
</ul>
</li>
<li>配置文件修改 <code>/etc/docker/daemon.json</code><div><pre class="hljs"><code><span class="hljs-punctuation">{</span>
    <span class="hljs-attr">"bip"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"192.168.100.1/24"</span>
<span class="hljs-punctuation">}</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="自定义网桥">自定义网桥</h3>
<ul>
<li>默认网桥名称：<code>docker0</code></li>
<li>内容查看
<ul>
<li><code>brctl show</code><br />
<img src="/_resources/59bf014a22f74b0cb1236fb62e0f58e3.png" /></li>
</ul>
</li>
<li>自定义网桥<div><pre class="hljs"><code><span class="hljs-comment"># 自定义网桥 my-br0</span>
brctl addbr my-br0 

<span class="hljs-comment"># 为网桥设定IP地址段 192.168.100.1/24</span>
ip a a 192.168.100.1/24 dev my-br0</code></pre></div>
</li>
<li>默认网桥修改
<ul>
<li>配置文件 ``</li>
<li>启动文件 <code>/lib/systemd/system/docker.service</code>
<ul>
<li><code>ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock -b my-br0</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="容器间互联">容器间互联</h3>
<blockquote>
<p>让数据库和wordpress两个容器实现互联</p>
</blockquote>
<p>!!! info  互联方式</p>
<ul>
<li>
<p>环境准备</p>
<div><pre class="hljs"><code>mkdir -p /tmp/cc/lamp_docker/mysql
mkdir -p /tmp/cc/{mysql,wordpress}

cat &gt; lamp_docker/env_mysql.list &lt;&lt;EOF
<span class="hljs-attribute">MYSQL_ROOT_PASSWORD</span>=alopex
<span class="hljs-attribute">MYSQL_DATABASE</span>=wordpress
<span class="hljs-attribute">MYSQL_USER</span>=wpuser
<span class="hljs-attribute">MYSQL_PASSWORD</span>=alopex
EOF

cat &gt; lamp_docker/env_wordpress.list &lt;&lt;EOF
<span class="hljs-attribute">WORDPRESS_DB_HOST</span>=mysql:3306  # 此处 mysql为容器名称，将被接写为IP地址在（/etc/hosts中被定义）
<span class="hljs-attribute">WORDPRESS_DB_NAME</span>=wordpress
<span class="hljs-attribute">WORDPRESS_DB_USER</span>=wpuser
<span class="hljs-attribute">WORDPRESS_DB_PASSWORD</span>=alopex
<span class="hljs-attribute">WORDPRESS_TABLE_PREFIX</span>=wp_
EOF

cat &gt; lamp_docker/mysql/mysql_test.cnf &lt;&lt;EOF
[mysqld]
<span class="hljs-attribute">server-id</span>=100
<span class="hljs-attribute">log-bin</span>=mysql-bin
EOF

tree /tmp/cc/
/tmp/cc/
├── lamp_docker
│   ├── env_mysql.list
│   ├── env_wordpress.list
│   └── mysql
│       └── mysql_test.cnf
├── mysql
└── wordpress

3 directories, 3 files</code></pre></div>
</li>
<li>
<p>名称互联</p>
<ul>
<li>
<p>使用<code>--link</code>选项实现容器名称的引用</p>
</li>
<li>
<p>其本质为在容器内的/etc/hosts中添加<code>--link</code>后指定的容器的IP和主机名的对应关系，从而实现名称解析</p>
</li>
<li>
<p>格式</p>
<div><pre class="hljs"><code>--link list   <span class="hljs-comment">#Add link to another container</span>

格式:
docker <span class="hljs-keyword">run</span><span class="language-bash"> --name &lt;容器名称&gt;    <span class="hljs-comment">#先创建指定名称的容器</span></span>
docker <span class="hljs-keyword">run</span><span class="language-bash"> --link &lt;目标通信的容器ID或容器名称&gt;  <span class="hljs-comment">#再创建容器时引用上面容器的名称</span></span></code></pre></div>
</li>
<li>
<p>例子</p>
<div><pre class="hljs"><code>docker run --name mysql \
-d -p 3306:3306 \
-v /tmp/cc/mysql:/var/lib/mysql \
-v /tmp/cc/lamp_docker/mysql/:/etc/mysql/conf.d  \
--env-file=/tmp/cc/lamp_docker/env_mysql.list \
mysql:8.0

<span class="hljs-comment"># 前端容器使用名称互联连接到mysql，</span>
<span class="hljs-comment"># 当前端需要访问mysql时，可通过其名称（mysql）访问，解决IP漂移问题</span>
docker run --name wordpress \
-d -p 80:80 \
--link mysql \
-v /tmp/cc/wordpress:/var/www/html/wp-content \
--env-file=/tmp/cc/lamp_docker/env_wordpress.list \
wordpress:php7.4-apache </code></pre></div>
<p><img src="/_resources/c5989b06e70840ad99950201ecb99523.png" /><br />
由于配置已经在容器阶段完成，因此登录页面填写好信息后，即会跳转到登录页面<br />
<img src="/_resources/fdc13c08e63a46c59ba09c844c832822.png" /></p>
</li>
</ul>
</li>
<li>
<p>别名互联</p>
<ul>
<li>
<p>容器名称是自身的一个特性，容器可对其进行修改，因此具备不稳定性</p>
</li>
<li>
<p>客户容器如果需要调用容器，应该为其配置一个别名</p>
</li>
<li>
<p>这样可以保证<code>被引用容器</code>修改名称时，不影响<code>调用容器</code>对被引容器名称的继续使用</p>
</li>
<li>
<p>格式</p>
<div><pre class="hljs"><code><span class="hljs-comment"># 先创建指定名称的容器</span>
docker <span class="hljs-keyword">run</span><span class="language-bash"> --name &lt;容器名称&gt;</span>

<span class="hljs-comment">#给上面创建的容器起别名,来创建新容器</span>
docker <span class="hljs-keyword">run</span><span class="language-bash"> --name &lt;容器名称&gt; --link &lt;目标容器名称&gt;:<span class="hljs-string">"&lt;容器别名1&gt; &lt;容器别名2&gt; ..."</span></span></code></pre></div>
</li>
<li>
<p>实例</p>
<div><pre class="hljs"><code><span class="hljs-comment"># 创建容器A，别名为 demo</span>
docker <span class="hljs-built_in">run</span> -d --name demo rocky:demo tail -f /etc/hosts

<span class="hljs-comment"># 创建容器B，关联容器A的别名 (A的别名为 my-demo)</span>
docker <span class="hljs-built_in">run</span> -d --name<span class="hljs-built_in"> client </span>--link demo:<span class="hljs-string">"my-demo"</span> rocky:demo tail -f /etc/hosts

<span class="hljs-comment"># 查看容器B上的hosts</span>
docker exec<span class="hljs-built_in"> client </span>cat /etc/hosts
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
ff00::0	ip6-mcastprefix
ff02::1	ip6-allnodes
ff02::2	ip6-allrouters
172.17.0.2	my-demo 1330796cbbdc demo
172.17.0.3	474584380ed6

<span class="hljs-comment"># 修改容器A的名称 为 new-demo</span>
docker rename demo new-demo

<span class="hljs-comment"># 容器B ping 容器A别名 my-demo 依然生效</span>
docker exec -it<span class="hljs-built_in"> client </span>/bin/bash<span class="hljs-built_in">
ping </span>my-demo<span class="hljs-built_in">
PING </span>my-demo (172.17.0.2) 56(84) bytes of data.
64 bytes <span class="hljs-keyword">from</span> my-demo (172.17.0.2): <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=64 <span class="hljs-attribute">time</span>=0.160 ms
64 bytes <span class="hljs-keyword">from</span> my-demo (172.17.0.2): <span class="hljs-attribute">icmp_seq</span>=2 <span class="hljs-attribute">ttl</span>=64 <span class="hljs-attribute">time</span>=0.108 ms
<span class="hljs-built_in">..</span>.</code></pre></div>
</li>
</ul>
</li>
</ul>
<p>!!!</p>
<h2 id="网络连接模式">网络连接模式.</h2>
<p><img src="/_resources/d1f3086b136b462d9d7c5b70082f6c4b.png" /></p>
<ul>
<li>模式语法<br />
<img src="/_resources/3c4b68ee7b5d4be19c9aa14679e1580b.png" /><div><pre class="hljs"><code>docker run --network &lt;mode&gt;
docker run --net=&lt;mode&gt;
&lt;mode&gt;:
    none
    bridge
    host
    container:&lt;容器名或容器ID&gt;
    &lt;自定义网络名称&gt;</code></pre></div>
</li>
</ul>
<h3 id="bridge-桥接模式">Bridge (桥接模式)</h3>
<p><img src="/_resources/75fdbfd2063e41efa480a49adbc28f72.png" /></p>
<p>!!! tip 场景说明</p>
<ul>
<li>
<p>语法声明</p>
<ul>
<li>docker  run --network= [docker0 | my-bridge] ...</li>
</ul>
</li>
<li>
<p>工作方式</p>
<ul>
<li>宿主机上创建默认的桥接器<code>docker0</code>，创建容器时将为<code>容器</code>创建<code>veth</code>并将该接口关联至<code>桥接器上</code></li>
<li><img src="/_resources/bf0a79c8186a42ff8631cbbfcd94e2a5.png" /></li>
</ul>
</li>
<li>
<p>配置查看</p>
<ul>
<li><img src="/_resources/0e2015e10b614871afdcec09bcb3ed30.png" /></li>
</ul>
</li>
<li>
<p>本质</p>
<ul>
<li>
<p>通过启用<code>ipforward</code>实现包在主机内转发</p>
<ul>
<li>cat /proc/sys/net/ipv4/ip_forward</li>
</ul>
</li>
<li>
<p>通过<code>iptables NAT chain</code> 对<code>docker0</code>网段IP进行<code>SNAT</code>实现与外部网络通信</p>
</li>
<li>
<p>实例说明，<code>nginx</code>容器内开启<code>80</code>端口，且使用宿主机<code>49153</code>端口</p>
<div><pre class="hljs"><code>docker port dazzling_margulis
<span class="hljs-number">80</span><span class="hljs-operator">/</span>tcp <span class="hljs-operator">-&gt;</span> <span class="hljs-number">0.0</span>.0.0<span class="hljs-operator">:</span><span class="hljs-number">49153</span>
<span class="hljs-number">80</span><span class="hljs-operator">/</span>tcp <span class="hljs-operator">-&gt;</span> <span class="hljs-operator">:::</span><span class="hljs-number">49153</span></code></pre></div>
<div><pre class="hljs"><code><span class="hljs-comment"># PREROUTING 的 NAT 表转发</span>
<span class="hljs-comment"># 目的地址是本机的数据包，都转发给 DOCKER 链处理</span>
sudo iptables -t nat -nL PREROUTING
Chain PREROUTING (policy ACCEPT)
target     prot opt <span class="hljs-built_in">source</span>               destination         
DOCKER     all  --  0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCAL

<span class="hljs-comment"># DOCKER 链的内容</span>
<span class="hljs-comment"># RETURN 规则：对于不匹配任何其他规则的数据包，应该立即返回到调用链的上一级</span>
<span class="hljs-comment"># DNAT 规则: 对于匹配 tcp协议目的端口 49153 的流量，转发到 172.17.0.2 主机的 80 端口</span>
sudo iptables -t nat -L DOCKER
Chain DOCKER (2 references)
target     prot opt <span class="hljs-built_in">source</span>               destination         
RETURN     all  --  anywhere             anywhere            
DNAT       tcp  --  anywhere             anywhere             tcp dpt:49153 to:172.17.0.2:80

<span class="hljs-comment"># MASQUERADE 改写包来源 IP 为防火墙 网卡 IP</span>
<span class="hljs-comment"># 功能与 SNAT 略有不同，当进行 IP 伪装时，不需指定要伪装成哪个 IP，IP 会从网卡直接读取</span>
sudo iptables -t nat -nvL POSTROUTING | column -t  | awk <span class="hljs-string">'NR &gt;1 {print}'</span>
pkts   bytes        target      prot    opt   <span class="hljs-keyword">in</span>        out       <span class="hljs-built_in">source</span>         destination       
0      0            MASQUERADE  all     --    *         !docker0  172.17.0.0/16  0.0.0.0/0         
0      0            MASQUERADE  tcp     --    *         *         172.17.0.2     172.17.0.2   tcp  dpt:80

<span class="hljs-comment"># 查看路由表</span>
<span class="hljs-comment"># 对于172.17.0.0网段，通过docker0接口访问</span>
route  -n | column -t | awk <span class="hljs-string">'NR &gt;1 {print}'</span>
Destination   Gateway         Genmask        Flags  Metric  Ref  Use  Iface
0.0.0.0       172.16.102.254  0.0.0.0        UG     600     0    0    wlp5s0
169.254.0.0   0.0.0.0         255.255.0.0    U      1000    0    0    wlp5s0
172.16.102.0  0.0.0.0         255.255.255.0  U      600     0    0    wlp5s0
172.17.0.0    0.0.0.0         255.255.0.0    U      0       0    0    docker0</code></pre></div>
</li>
</ul>
</li>
<li>
<p>配置参数</p>
<div><pre class="hljs"><code><span class="hljs-punctuation">{</span>
<span class="hljs-attr">"hosts"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">"tcp://0.0.0.0:2375"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"fd://"</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"bip"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"192.168.100.100/24"</span><span class="hljs-punctuation">,</span>        #分配docker0网卡的IP
<span class="hljs-attr">"fixed-cidr"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"192.168.100.128/26"</span><span class="hljs-punctuation">,</span> #分配容器IP范围<span class="hljs-punctuation">,</span><span class="hljs-number">26</span>不是容器IP的子网掩码<span class="hljs-punctuation">,</span>只表示地址范围
<span class="hljs-attr">"fixed-cidr-v6"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2001:db8::/64"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"mtu"</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1500</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"default-gateway"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"192.168.100.200"</span><span class="hljs-punctuation">,</span> #网关必须和bip在同一个网段
<span class="hljs-attr">"default-gateway-v6"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2001:db8:abcd::89"</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">"dns"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span> <span class="hljs-string">"1.1.1.1"</span><span class="hljs-punctuation">,</span> <span class="hljs-string">"8.8.8.8"</span><span class="hljs-punctuation">]</span>
<span class="hljs-punctuation">}</span></code></pre></div>
</li>
<li>
<p>通信</p>
<ul>
<li>内网 (默认可达)
<ul>
<li>容器间通信由网桥的<code>icc</code>参数决定
<ul>
<li><code>"com.docker.network.bridge.enable_icc": "true"</code></li>
</ul>
</li>
<li>宿主机与容器的联通性由<code>bridge</code>的路由决定</li>
</ul>
</li>
<li>外网 (默认可达)
<ul>
<li>外网的通信由 <code>iptable 的 SNAT</code>规则决定</li>
</ul>
</li>
</ul>
</li>
<li>
<p>特点</p>
<ul>
<li>缺省<code>默认配置</code>: 容器默认自动获取172.17.0.0/16的IP地址，此地址可以修改</li>
<li>可<code>访问外网</code>: 利用宿主机的物理网卡，SNAT连接外网</li>
<li>外部主机无法直接访问容器: 可以通过<code>配置DNAT</code>接受外网的访问</li>
<li>低性能较低: 通过<code>NAT转换</code>有转换消耗</li>
<li>端口管理繁琐: 每个容器必须手动指定唯一的端口容器产生端口冲容</li>
</ul>
</li>
<li>
<p>小结</p>
<ul>
<li><code>Bridge (桥接)</code>是默认网络链接模式，可实现内网和外网的通信</li>
<li>适用于希望<code>容器之间相互通信</code>，并且<code>与外部网络隔离</code>的场景<br />
!!!</li>
</ul>
</li>
</ul>
<h3 id="host-主机模式">Host (主机模式)</h3>
<p><img src="/_resources/8a4e16a8317c419695697a8c6371e1bb.png" /></p>
<p>!!! tip 场景说明</p>
<ul>
<li>语法声明
<ul>
<li>docker  run --network=host ...</li>
</ul>
</li>
<li>工作方式
<ul>
<li>共享网络资源，访问主机地址即访问容器</li>
</ul>
</li>
<li>配置查看<br />
<img src="/_resources/d781b3ae10384dec83e6db69645e327e.png" /></li>
<li>本质
<ul>
<li>与<code>宿主机</code>共享网络地址、端口等信息，即不对容器进行<code>网络命名空间资源</code>进行隔离</li>
</ul>
</li>
<li>通信
<ul>
<li>内网 (无)</li>
<li>外网
<ul>
<li>跨主机间通信，只要能与<code>宿主机</code>通信即可访问容器</li>
<li><code>宿主机</code>可访问外网的前提下，容器可访问外网</li>
</ul>
</li>
</ul>
</li>
<li>特点
<ul>
<li>使用参数 <code>--network host</code> 指定</li>
<li>共享宿主机网络，各容器网络无隔离</li>
<li>网络性能无损耗</li>
<li>网络故障排除相对简单</li>
<li>容易产生<code>端口冲突</code></li>
<li>网络资源无法分别统计</li>
<li><code>不支持端口映射</code></li>
</ul>
</li>
<li>小结
<ul>
<li>适用于希望容器<code>直接使用主机网络栈</code>，与<code>主机共享网络</code>的场景<br />
!!!</li>
</ul>
</li>
</ul>
<h3 id="none-无网络">none (无网络)</h3>
<p>!!! tip 场景说明</p>
<ul>
<li>语法声明
<ul>
<li>docker  run --network=none ...</li>
</ul>
</li>
<li>工作方式
<ul>
<li>将容器置于一个<code>隔离的网络环境</code>中，该环境没有任何网络连接。</li>
</ul>
</li>
<li>内容查看<br />
<img src="/_resources/88d81efb15ca4c7f8b918c8b28f0e0a0.png" /></li>
<li>本质
<ul>
<li>在容器运行时<code>禁用容器的网络功能</code>，使得容器<code>无法进行网络通信</code>。</li>
</ul>
</li>
<li>通信
<ul>
<li>内网 (无)</li>
<li>外网 (无)</li>
</ul>
</li>
<li>特点
<ul>
<li>使用参数 <code>--network none</code> 指定</li>
<li>默认无网络功能，<code>无法和外部通信</code></li>
<li>无法实现<code>端口映射</code></li>
<li>适用于<code>测试环境</code></li>
</ul>
</li>
<li>小结
<ul>
<li>适用于<code>不需要网络连接</code>的容器，用于<code>隔离容器与网络的场景</code>。<br />
!!!</li>
</ul>
</li>
</ul>
<h3 id="container-容器网络">container (容器网络)</h3>
<p><img src="/_resources/0507f22f84d9468fa79c31c55976bc39.png" /></p>
<p>!!! tip 场景说明</p>
<ul>
<li>语法声明
<ul>
<li>docker  run --net=container:mycontainer ...</li>
</ul>
</li>
<li>工作方式
<ul>
<li>创建容器时，需要关联指定容器，并与该容器<code>共享网络资源</code></li>
<li>端口<code>不能和被指定容器的端口冲突</code>，除了网络之外的文件系统、进程信息等仍然保持相互隔离</li>
<li>两个容器的进程可以通过<code>lo网卡</code>进行通信</li>
</ul>
</li>
<li>本质
<ul>
<li>新建的容器与<code>被指定的容器</code>网络资源共享，其他<code>NS</code>资源保持独立</li>
</ul>
</li>
<li>通信
<ul>
<li>内网 (与关联容器保持一致)</li>
<li>外网 (与关联容器保持一致)</li>
</ul>
</li>
<li>特点
<ul>
<li>使用参数 <code>--network container:名称</code>或<code>ID</code> 指定</li>
<li>与宿主机网络空间隔离</li>
<li>容器间共享网络空间，直接<code>使用对方的网络</code></li>
<li>第一个容器的网络可能是<code>bridge</code>, <code>none</code>, <code>host</code>，而第二个容器模式依赖于第一个容器</li>
<li>如果第一个容器<code>停止</code>，将导致<code>无法创建第二个容器</code></li>
<li>第二个容器可以直接<code>使用127.0.0.1访问第一个容器</code></li>
<li>适合<code>频繁的容器间的网络通信</code></li>
<li>默认<code>不支持端口映射</code>，较少使用</li>
</ul>
</li>
<li>小结
<ul>
<li>适用于希望<code>多个容器共享相同网络栈</code>，直接通信的场景。</li>
</ul>
</li>
<li>案例<div><pre class="hljs"><code><span class="hljs-comment"># 创建前端容器 wordpress，开放宿主机端口80</span>
docker run -d \
-p 80:80 --name wordpress \
-v /data/wordpress:/var/www/html \
wordpress:php7.4-apache

<span class="hljs-comment"># 创建数据库容器 mysql，共享前端wordpress的网络</span>
<span class="hljs-comment"># 由于使用了 --network，后续链接数据库可使用 127.0.0.1</span>
docker run --network container:wordpress \
-e MYSQL_ROOT_PASSWORD=alopex \
-e MYSQL_DATABASE=wordpress \
-e MYSQL_USER=wordpress \
-e MYSQL_PASSWORD=alopex \
-v /data/mysql:/var/lib/mysql \
--name mysql -d \
mysql:8.0</code></pre></div>
<img src="/_resources/ffe109070cdb46b19af0075908ed9c83.png" /><br />
!!!</li>
</ul>
<h3 id="自定义网络">自定义网络</h3>
<p>!!! tip 场景说明</p>
<ul>
<li>语法声明<div><pre class="hljs"><code>docker network create -d &lt;mode&gt; --subnet &lt;CIDR&gt; --gateway &lt;网关&gt; &lt;自定义网络名称&gt;

<span class="hljs-comment"># 注意mode不支持host和none 默认是bridge模式</span>
-d &lt;mode&gt; 可省略，默认为bridge</code></pre></div>
<ul>
<li>docker  run --net= my-network ...</li>
</ul>
</li>
<li>工作方式
<ul>
<li>使用自定义网络模式, 实现<code>不同集群应用的独立网络管理</code>, 而互不影响在网一个网络内, 可以<code>直接利用容器名相互访问</code></li>
</ul>
</li>
<li>案例<div><pre class="hljs"><code><span class="hljs-comment"># 创建一个subnet 选择使用桥接模式，网段为 172.27.0.0/16</span>
docker network create -d bridge \
--subnet=172.27.0.0/16 \
--gateway=172.27.0.1 mynet

<span class="hljs-comment"># 查看自建网络</span>
[
    {
        <span class="hljs-string">"Name"</span>: <span class="hljs-string">"mynet"</span>,
        <span class="hljs-string">"Id"</span>: <span class="hljs-string">"38214b8ba881d2b919bf59c1e5e27d838c973967bd04b4456333388a93c1bc18"</span>,
        <span class="hljs-string">"Created"</span>: <span class="hljs-string">"2024-04-26T16:10:55.214517178+08:00"</span>,
        <span class="hljs-string">"Scope"</span>: <span class="hljs-string">"local"</span>,
        <span class="hljs-string">"Driver"</span>: <span class="hljs-string">"bridge"</span>,
        <span class="hljs-string">"EnableIPv6"</span>: <span class="hljs-literal">false</span>,
        <span class="hljs-string">"IPAM"</span>: {
            <span class="hljs-string">"Driver"</span>: <span class="hljs-string">"default"</span>,
            <span class="hljs-string">"Options"</span>: {},
            <span class="hljs-string">"Config"</span>: [
                {
                    <span class="hljs-string">"Subnet"</span>: <span class="hljs-string">"172.27.0.0/16"</span>,
                    <span class="hljs-string">"Gateway"</span>: <span class="hljs-string">"172.27.0.1"</span>
                }
            ]
        },
        <span class="hljs-string">"Internal"</span>: <span class="hljs-literal">false</span>,
        <span class="hljs-string">"Attachable"</span>: <span class="hljs-literal">false</span>,
        <span class="hljs-string">"Ingress"</span>: <span class="hljs-literal">false</span>,
        <span class="hljs-string">"ConfigFrom"</span>: {
            <span class="hljs-string">"Network"</span>: <span class="hljs-string">""</span>
        },
        <span class="hljs-string">"ConfigOnly"</span>: <span class="hljs-literal">false</span>,
        <span class="hljs-string">"Containers"</span>: {},
        <span class="hljs-string">"Options"</span>: {},
        <span class="hljs-string">"Labels"</span>: {}
    }
]
<span class="hljs-comment"># 创建容器使用自定义网络</span>
docker run --network=mynet -d rocky:demo tail -f /etc/hosts

<span class="hljs-comment"># 查看其网络配置</span>
<span class="hljs-string">"Networks"</span>: {
    <span class="hljs-string">"mynet"</span>: {
        <span class="hljs-string">"IPAMConfig"</span>: null,
        <span class="hljs-string">"Links"</span>: null,
        <span class="hljs-string">"Aliases"</span>: [
            <span class="hljs-string">"75be6bd6aaf4"</span>
        ],
        <span class="hljs-string">"NetworkID"</span>: <span class="hljs-string">"38214b8ba881d2b919bf59c1e5e27d838c973967bd04b4456333388a93c1bc18"</span>,
        <span class="hljs-string">"EndpointID"</span>: <span class="hljs-string">"89fd76bd5dd18ac24f89b498d3336901058171ec817eae905b7fc9c1eb5b3e55"</span>,
        <span class="hljs-string">"Gateway"</span>: <span class="hljs-string">"172.27.0.1"</span>,
        <span class="hljs-string">"IPAddress"</span>: <span class="hljs-string">"172.27.0.2"</span>,
        <span class="hljs-string">"IPPrefixLen"</span>: 16,
        <span class="hljs-string">"IPv6Gateway"</span>: <span class="hljs-string">""</span>,
        <span class="hljs-string">"GlobalIPv6Address"</span>: <span class="hljs-string">""</span>,
        <span class="hljs-string">"GlobalIPv6PrefixLen"</span>: 0,
        <span class="hljs-string">"MacAddress"</span>: <span class="hljs-string">"02:42:ac:1b:00:02"</span>,
        <span class="hljs-string">"DriverOpts"</span>: null
    }</code></pre></div>
</li>
</ul>
<p>!!!</p>
<h1 id="harbor私有仓库">Harbor私有仓库</h1>
<h2 id="基本操作">基本操作</h2>
<h3 id="上传镜像">上传镜像</h3>
<ol start="0">
<li>
<p>harbor创建项目和用户</p>
<ul>
<li>创建项目 <code>Projects</code>
<ul>
<li><img src="/_resources/189e8f836e3043f8a0d915d1befad0ef.png" /></li>
</ul>
</li>
<li>创建用户 <code>Administration</code> -&gt; <code>User</code>
<ul>
<li><img src="/_resources/2e26b6559d2b455ca33851f817cec8ec.png" /></li>
</ul>
</li>
<li>将现有用户<code>alfie</code>成为项目<code>member</code>赋予权限<code>Project Admin</code>
<ul>
<li><img src="/_resources/467e503d5d9a47cebebf38a02d82757d.png" /></li>
</ul>
</li>
</ul>
</li>
<li>
<p>登录harbor</p>
<ul>
<li>docker login <a title="http://192.168.66.101:80" href="http://192.168.66.101:80">http://192.168.66.101:80</a></li>
<li><img src="/_resources/af0a0fc69f3441e6a6e3976da9ccf48c.png" /></li>
</ul>
</li>
<li>
<p>本地镜像打标签</p>
<ul>
<li>标签格式
<ul>
<li><code>Harbor-host:port/project-name/image:tag</code></li>
<li>端口不能省略</li>
</ul>
</li>
<li>docker tag alpine:latest  192.168.66.101:80/alfie-app/alpine:v1</li>
</ul>
</li>
<li>
<p>insecurity设置</p>
<div><pre class="hljs"><code><span class="hljs-punctuation">{</span>
 <span class="hljs-attr">"insecure-registries"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">"10.0.0.10:80"</span><span class="hljs-punctuation">,</span><span class="hljs-string">"10.0.0.11:80"</span><span class="hljs-punctuation">]</span>  #说明<span class="hljs-punctuation">:</span> <span class="hljs-string">":80"</span>端口可省略
<span class="hljs-punctuation">}</span>

systemctl daemon-reload
systemctl restart docker</code></pre></div>
</li>
<li>
<p>上传镜像</p>
<ul>
<li>docker push 192.168.66.101:80/alfie-app/alpine:v1</li>
<li><img src="/_resources/2b2b5bfff4d246649858f069040bba3f.png" /></li>
</ul>
</li>
<li>
<p>harbor查看镜像</p>
<ul>
<li><img src="/_resources/97e3cb121dd6479ca220a7965c86fef3.png" /></li>
</ul>
</li>
<li>
<p>查看上传日志</p>
<ul>
<li><img src="/_resources/2aa1784a94f64bbd8359c3147e05d12b.png" /></li>
</ul>
</li>
</ol>
<h3 id="下载镜像">下载镜像</h3>
<ol start="0">
<li>
<p>docker security 开启（对于非443服务）</p>
<div><pre class="hljs"><code><span class="hljs-punctuation">{</span>
 <span class="hljs-attr">"insecure-registries"</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">"10.0.0.10:80"</span><span class="hljs-punctuation">,</span><span class="hljs-string">"10.0.0.11:80"</span><span class="hljs-punctuation">]</span>  #说明<span class="hljs-punctuation">:</span> <span class="hljs-string">":80"</span>端口可省略
<span class="hljs-punctuation">}</span>
OR 
/usr/lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd --containerd=/run/containerd/containerd.sock --insecure-registry <span class="hljs-number">192.168</span><span class="hljs-number">.66</span><span class="hljs-number">.101</span>

systemctl daemon-reload
systemctl restart docker</code></pre></div>
</li>
<li>
<p>登录harbor</p>
<ul>
<li>docker login <a title="http://192.168.66.101:80" href="http://192.168.66.101:80">http://192.168.66.101:80</a></li>
<li><img src="/_resources/af0a0fc69f3441e6a6e3976da9ccf48c.png" /></li>
</ul>
</li>
<li>
<p>拉去镜像</p>
<ul>
<li>docker pull 192.168.66.101:80/alfie-app/alpine@sha256:6457d53fb065d6f250e1504b9bc42d5b6c65941d57532c072d929dd0628977d0</li>
<li><img src="/_resources/11a45a1e4c9741958157ed380cdc071f.png" /></li>
</ul>
</li>
</ol>
<h3 id="更新配置">更新配置</h3>
<ol>
<li>
<p>关闭harbor<br />
cd /apps/harbor &amp;&amp; docker-compose down</p>
</li>
<li>
<p>修改harbor配置文件 <code>harbor.yml</code></p>
</li>
<li>
<p>配置重新生成</p>
<div><pre class="hljs"><code>./prepare
Clearing the configuration file: /config/portal/nginx.conf
Clearing the configuration file: /config/<span class="hljs-built_in">log</span>/logrotate.conf
Clearing the configuration file: /config/<span class="hljs-built_in">log</span>/rsyslog_docker.conf
Clearing the configuration file: /config/nginx/nginx.conf
Clearing the configuration file: /config/core/env
Clearing the configuration file: /config/core/app.conf
Clearing the configuration file: /config/registry/passwd
Clearing the configuration file: /config/registry/config.yml
Clearing the configuration file: /config/registry/root.crt
Clearing the configuration file: /config/registryctl/env
Clearing the configuration file: /config/registryctl/config.yml
Clearing the configuration file: /config/db/env
Clearing the configuration file: /config/jobservice/env
Clearing the configuration file: /config/jobservice/config.yml
Generated configuration file: /config/portal/nginx.conf
Generated configuration file: /config/<span class="hljs-built_in">log</span>/logrotate.conf
Generated configuration file: /config/<span class="hljs-built_in">log</span>/rsyslog_docker.conf
Generated configuration file: /config/nginx/nginx.conf
Generated configuration file: /config/core/env
Generated configuration file: /config/core/app.conf
Generated configuration file: /config/registry/config.yml
Generated configuration file: /config/registryctl/env
Generated configuration file: /config/registryctl/config.yml
Generated configuration file: /config/db/env
Generated configuration file: /config/jobservice/env
Generated configuration file: /config/jobservice/config.yml
loaded secret from file: /data/secret/keys/secretkey
Generated configuration file: /compose_location/docker-compose.yml</code></pre></div>
</li>
<li>
<p>启动harbor<br />
docker-compose up -d</p>
</li>
</ol>
<h2 id="https请求实现">https请求实现.</h2>
<ol start="0">
<li>配置域名</li>
</ol>
<blockquote>
<p>hostnamectl set-hostname www.my-harbor.com<br />
sed  -i '$a  192.168.66.101 www.my-harbor.com' /etc/hosts</p>
</blockquote>
<ol>
<li>
<p>生成证书<br />
<a>0x07 SSL/签署证书#制作根证书</a><br />
<a>0x07 SSL/签署证书#生成服务端证书</a></p>
<div><pre class="hljs"><code>#创建证书相关数据的目录
mkdir -p /data/harbor/certs
cd /data/harbor/certs

#生成ca的私钥
openssl genrsa -out ca.key <span class="hljs-number">4096</span>

#生成ca的自签名证书
openssl req -x509 -new -nodes -sha512 -days <span class="hljs-number">3650</span> \
-subj <span class="hljs-string">"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=ca.harbor.com"</span> \
-key ca.key \
-out ca.crt

#生成harbor主机的私钥
openssl genrsa -out my-harbor.key <span class="hljs-number">4096</span>

#生成harbor主机的证书申请
openssl req -sha512 -new \
-subj <span class="hljs-string">"/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=www.my-harbor.com"</span> \
-key my-harbor.key \
-out my-harbor.csr

#创建x509 v3 扩展文件(新版新增加的要求)
cat &gt; v3.ext &lt;&lt;-EOF
authorityKeyIdentifier=keyid,issuer
basicConstraints=CA:FALSE
keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment
extendedKeyUsage = serverAuth
subjectAltName = ip:<span class="hljs-number">192.168</span><span class="hljs-number">.66</span><span class="hljs-number">.101</span>, DNS:www.my-harbor.com

#[alt_names]
#DNS<span class="hljs-number">.1</span>=www.my-harbor.com      #此处必须和和harbor的网站名称一致
#DNS<span class="hljs-number">.2</span>=my-harbor.com                 #可选
EOF

#给 harbor主机颁发证书
openssl x509 -req -sha512 -days <span class="hljs-number">3650</span> \
-extfile v3.ext \
-CA ca.crt -CAkey ca.key -CAcreateserial \
-in my-harbor.csr \
-out my-harbor.crt

# 证书查看
openssl x509 -in my-harbor.crt -noout -text</code></pre></div>
</li>
<li>
<p>服务器使用证书</p>
<div><pre class="hljs"><code><span class="hljs-comment"># 在应用下创建证书目录</span>
mkdir  /apps/harbor/certs

<span class="hljs-comment"># 复制证书到该路径下</span>
cp my-harbor.crt my-harbor.key /apps/harbor/certs/

<span class="hljs-comment"># 修改配置 harbor.yml</span>
https:
  <span class="hljs-comment"># https port for harbor, default is 443</span>
  port: 443
  <span class="hljs-comment"># The path of cert and key files for nginx</span>
  certificate: /apps/harbor/certs/my-harbor.crt
  private_key: /apps/harbor/certs/my-harbor.key
  
<span class="hljs-comment"># 使配置生效</span>
<span class="hljs-built_in">cd</span> /apps/harbor/
./prepare
docker-compose down -v
docker-compose up -d</code></pre></div>
</li>
<li>
<p>客户端使用证书</p>
</li>
<li>
<p>浏览器使用证书</p>
</li>
</ol>
<ul>
<li><code>c:\Windows\System32\Drivers\etc\hosts</code>
<ul>
<li>追加主机解析记录</li>
<li>192.168.66.101  www.my-harbor.com</li>
<li><img src="/_resources/e4f2677ac2f04525b7fde6db0e7107dc.png" /><br />
*<img src="/_resources/d15b933e156e495db84f295a26c79aa3.png" /></li>
</ul>
</li>
<li>证书导入
<ul>
<li><img src="/_resources/51ac1adfd1c944babc6eed2b10e61afa.png" /></li>
<li><img src="/_resources/5672e3249f1e45b5b6afa6762b9cadcb.png" /></li>
<li><img src="/_resources/4a86feb039f04586b0599ff214b867fc.png" /></li>
<li><img src="/_resources/714545e9f28649d4b8f45c7f6d04d0dc.png" /></li>
</ul>
</li>
<li>再次访问
<ul>
<li><img src="/_resources/6b87c1d94ba545499b533ba31cad280d.png" /></li>
</ul>
</li>
</ul>
<ol start="5">
<li>
<p>客户端配置证书</p>
<div><pre class="hljs"><code><span class="hljs-comment"># 转换客户端证书(即后缀为 my-harbor.cert)</span>
<span class="hljs-built_in">cd</span> /data/harbor/certs
openssl x509 -inform PEM -<span class="hljs-keyword">in</span> my-harbor.crt -out my-harbor.cert

<span class="hljs-comment"># 创建和harbor服务器同名目录</span>
mkdir -pv /etc/docker/certs.d/www.my-harbor.com/

<span class="hljs-comment"># 将.cert, .key, ca.key 复制到该目录下</span>
cp my-harbor.cert my-harbor.key ca.crt /etc/docker/certs.d/www.my-harbor.com/</code></pre></div>
</li>
<li>
<p>推送镜像测试</p>
<ul>
<li>登录账号
<ul>
<li>docker login www.my-harbor.com</li>
<li><img src="/_resources/18bc7c3b790a404483f0f25b05729281.png" /></li>
</ul>
</li>
<li>修改镜像标签
<ul>
<li>docker tag busybox:latest www.my-harbor.com/alfie-app/busybox:v1</li>
</ul>
</li>
<li>推送镜像
<ul>
<li>docker push www.my-harbor.com/alfie-app/busybox:v1</li>
<li><img src="/_resources/bb487b357fd94546b246dfdf7be8c245.png" /></li>
</ul>
</li>
<li>获得镜像
<ul>
<li>docker pull www.my-harbor.com/alfie-app/busybox@sha256:db16cd196b8a37ba5f08414e6f6e71003d76665a5eac160cb75ad3759d8b3e29</li>
<li><img src="/_resources/065852849fd54c2caba3b29e5272253f.png" /></li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="jumpserver安装和使用">JumpServer安装和使用</h1>
<h2 id="部署">部署</h2>
<h3 id="离线部署">离线部署</h3>
<p><a title="https://docs.jumpserver.org/zh/v3/installation/setup_linux_standalone/offline_install/#1" href="https://docs.jumpserver.org/zh/v3/installation/setup_linux_standalone/offline_install/#1">离线部署介绍</a></p>
<h3 id="脚本部署">脚本部署</h3>
<div><pre class="hljs"><code>curl -sSL https://resource.fit2cloud.com/jumpserver/jumpserver/releases/latest/download/quick_start.sh | bash</code></pre></div>
<p>!!! tip 密钥和token信息</p>
<div><pre class="hljs"><code><span class="hljs-number">1</span>. Configure <span class="hljs-keyword">Private</span> <span class="hljs-keyword">Key</span>
<span class="hljs-symbol">SECRETE_KEY:</span>     <span class="hljs-number">216</span>aa1a921346036377a317f007a50330c84a85dea56d145
<span class="hljs-symbol">BOOTSTRAP_TOKEN:</span> jz0nNnx1Kts9v45233O8bHbZ
complete

# 应对此进行备份，因迁移请保证 SECRET_KEY和BOOTSTRAP_TOKEN与旧环境一致</code></pre></div>
<p>!!!</p>
<p>!!! tip 提示信息<br />
首次安装后需要修改配置文件，定义 <code>DOMAINS</code> 字段后即可正常使用。<br />
如果服务器是一键安装并且旧版本就已经使用 <code>JumpServer</code> 开启了 <code>HTTPS</code>，则不需要进行任何更改。<br />
需要使用 IP 地址来访问 <code>JumpServer</code> 的场景，可以根据自己的 <code>IP</code> 类型来填写 <code>config.txt</code> 配置文件中 <code>DOMAINS</code> 字段为公网 IP 还是内网 IP。</p>
<p>默认安装路径：<code>/opt/jumpserver</code></p>
<div><pre class="hljs"><code>vim /opt/jumpserver/config/config.txt 

<span class="hljs-comment"># 可信任 DOMAINS 定义,</span>
<span class="hljs-comment"># 定义可信任的访问 IP, 请根据实际情况修改, 如果是公网 IP 请改成对应的公网 IP,</span>
<span class="hljs-comment"># DOMAINS="demo.jumpserver.org"    # 使用域名访问</span>
<span class="hljs-comment"># DOMAINS="172.17.200.191"         # 使用 IP 访问</span>
<span class="hljs-comment"># DOMAINS="demo.jumpserver.org,172.17.200.191"    # 使用 IP 和 域名一起访问</span>
DOMAINS=<span class="hljs-string">"www.my-harbor.com,192.168.66.101:80"</span></code></pre></div>
<p>!!!</p>
<h3 id="访问方式">访问方式</h3>
<p>!!! info 访问登录</p>
<div><pre class="hljs"><code>地址: http:<span class="hljs-regexp">//</span>&lt;JumpServer服务器IP地址&gt;:&lt;服务运行端口&gt;
如上面配置：http:<span class="hljs-regexp">//</span>www.my-harbor.com:<span class="hljs-number">80</span>
用户名: admin
密码: admin</code></pre></div>
<p>!!!</p>
<h3 id="服务管理">服务管理</h3>
<div><pre class="hljs"><code>/opt/jumpserver-installer-v3.10.9/jmsctl.sh

JumpServer Deployment Management Script

Usage: 
  ./jmsctl.sh [COMMAND] [ARGS...]
  ./jmsctl.sh --<span class="hljs-built_in">help</span>

Installation Commands: 
  install           Install JumpServer

Management Commands: 
  config            Configuration  Tools
  start             Start     JumpServer
  stop              Stop      JumpServer
  restart           Restart   JumpServer
  status            Check     JumpServer
  down              Offline   JumpServer
  uninstall         Uninstall JumpServer

More Commands:
  load_image        Loading docker image
  backup_db         Backup database
  restore_db [file] Data recovery through database backup file
  raw               Execute the original docker-compose <span class="hljs-built_in">command</span>
  tail [service]    View <span class="hljs-built_in">log</span></code></pre></div>
<h2 id="常用功能">常用功能</h2>
<p><img src="/_resources/d3dfc36aa643419983e164abc45cd565.png" /></p>
<h3 id="管理员">管理员</h3>
<h4 id="创建用户组">创建用户组</h4>
<p><img src="/_resources/145ace43eba645db8d77a444109768fd.png" /></p>
<h4 id="配置用户-登录名称-leslie">配置用户 (登录名称 leslie)</h4>
<p><img src="/_resources/93ddd63e9b1149008a63cf784fa90078.png" /></p>
<h4 id="创建资产">创建资产</h4>
<p><img src="/_resources/3d0f32ad9fdb41d285896779b00229f5.png" /><br />
<img src="/_resources/67412e663d114f4a8e1ab4d04956c2ac.png" /><br />
<img src="/_resources/e926cb080ca44463951d21125ecf2f75.png" /></p>
<h4 id="账户模板">账户模板</h4>
<p><img src="/_resources/74b29985d55a4761a5e0097e9609f2ca.png" /></p>
<h4 id="账户推送">账户推送</h4>
<p><img src="/_resources/852ea0c104b149b3ab195b5851ba256a.png" /><br />
<img src="/_resources/d3f6d12d75264929903999ad1d33d03b.png" /><br />
<img src="/_resources/5b15a838c21b42a7bcf239ac039b4fcd.png" /></p>
<h4 id="用户登录">用户登录</h4>
<p><img src="/_resources/1a6eee195ff0494a9dfc2b3a0ea61ed3.png" /></p>
<h4 id="创建授权策略">创建授权策略</h4>
<p><img src="/_resources/00b5fe99c75940829492c1b0a5ffd2c6.png" /></p>
<h4 id="命令执行限制">命令执行限制</h4>
<p><img src="/_resources/5942e0724b5f4455855c545c856e696f.png" /><br />
<img src="/_resources/5a01778a7ba141fe9a19c24e91605253.png" /></p>
<h3 id="操作员">操作员</h3>
<h4 id="登录账户">登录账户</h4>
<p><img src="/_resources/a1ef8090428748fd8c528eb2adb27e42.png" /><br />
<img src="/_resources/d5d40705c7324d738f3852839c457545.png" /><br />
<img src="/_resources/f124487995294e348d5b886c56b29401.png" /><br />
<img src="/_resources/cbc29c145be74a9ea637e33ad4ebe74a.png" /></p>
<h4 id="webshell登录用户">webshell登录用户</h4>
<p><img src="/_resources/b5b81c27cee44a9ca3fbebfb34d884ce.png" /><br />
<img src="/_resources/d1829be34dfd46e886f07af77679f6c4.png" /></p>
<h4 id="webshell命令限制">webshell命令限制</h4>
<p><img src="/_resources/9b72090c0af24f6fbcb2e88e948e0725.png" /><br />
<img src="/_resources/ae1938a2f35c479fbde3208649ce979b.png" /></p>
<h3 id="审计员">审计员</h3>
<h4 id="会话查看">会话查看</h4>
<p><img src="/_resources/88e35cfe72a547e5be25f98a4665a867.png" /><br />
<img src="/_resources/bc89439f916f42c296a72a8ed1ef4bc3.png" /><br />
<img src="/_resources/fbbe8690459244e792be43a0b56adfe4.png" /><br />
<img src="/_resources/eff33335e53c42dea63023177e10a42b.png" /></p>
<h4 id="命令记录">命令记录</h4>
<p><img src="/_resources/121499c22adf4fdcaae5bbe94414d0ee.png" /><br />
<img src="/_resources/4c5ba478c22a48429d9ccdcf25020cc4.png" /><br />
<img src="/_resources/ff46aa8ddee54c46a3ff5791c1b6c23c.png" /></p>
<h4 id="查看录制视频">查看录制视频</h4>
<ul>
<li>对于下载的是视频，我们需要用特定的工具对其进行打开</li>
<li><a title="https://github.com/jumpserver/VideoPlayer/releases" href="https://github.com/jumpserver/VideoPlayer/releases">VideoPlayer</a>
<ul>
<li><a title="https://github.com/jumpserver/VideoPlayer/releases/download/v0.1.10/JumpServer-VideoPlayer-v0.1.10-win-x64.exe" href="https://github.com/jumpserver/VideoPlayer/releases/download/v0.1.10/JumpServer-VideoPlayer-v0.1.10-win-x64.exe">win-x64</a></li>
</ul>
</li>
</ul>
<h4 id="登录日志">登录日志</h4>
<p><img src="/_resources/c9d0e6c85d6a4d4d88e0f269c2a47df8.png" /></p>
<h4 id="操作日志">操作日志</h4>
<p><img src="/_resources/f6a5131cd2f44174939a87f8353809b3.png" /></p>
<h4 id="改密日志">改密日志</h4>
<p><img src="/_resources/7460ad58c0d14a4eb39788a8c5e4c11d.png" /></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[第三周作业]]></title>
            <guid>c04ff88c7f834e8ca064a0914a92744b</guid>
            <pubDate>Sun, 21 Apr 2024 14:24:41 GMT</pubDate>
            <content:encoded><![CDATA[<nav class="table-of-contents"><ul><li><a href="#虚拟机管理">虚拟机管理</a><ul><li><a href="#创建">创建</a></li><li><a href="#复制">复制</a><ul><li><a href="#磁盘复制实现">磁盘复制实现</a></li><li><a href="#右键clone">右键clone</a></li><li><a href="#virt-clone克隆">virt-clone克隆</a></li></ul></li><li><a href="#virtio驱动">virtio驱动</a></li><li><a href="#列出主机">列出主机</a></li><li><a href="#开启关闭">开启关闭</a></li><li><a href="#暂停恢复">暂停恢复</a></li><li><a href="#开机启动">开机启动</a></li><li><a href="#删除">删除</a></li><li><a href="#磁盘路径">磁盘路径</a></li><li><a href="#冷迁移">冷迁移</a></li><li><a href="#重要文件">重要文件</a></li><li><a href="#管理远程主机">管理远程主机</a></li></ul></li><li><a href="#镜像制作">镜像制作</a><ul><li><a href="#手动制作">手动制作</a><ul><li><a href="#制作步骤">制作步骤</a></li><li><a href="#操作案例-nginx容器制作">操作案例 (nginx容器制作)</a></li></ul></li></ul></li></ul></nav><h1 id="虚拟机管理">虚拟机管理</h1>
<h2 id="创建">创建</h2>
<div><pre class="hljs"><code><span class="hljs-comment"># 创建一个20G的 qcow2格式磁盘文件</span>
qemu-img create -f qcow2 /var/lib/libvirt/images/centos7.qcow2 20G

<span class="hljs-comment"># 查看系统支持的os版本</span>
virt-install --osinfo list  | grep <span class="hljs-string">'os-you-need'</span>

<span class="hljs-comment"># 采用已预先创建的磁盘</span>
<span class="hljs-comment"># 其中cdrom的权限 用户为libvirt-qemu 用户组为kvm</span>
virt-install \
--name centos7 \
--virt-type kvm \
--os-variant=centos7.0 \
--memory 1024 --vcpus 2 \
--cdrom=/data/isos/CentOS-7-x86_64-Minimal-2009.iso \
--disk path=/var/lib/libvirt/images/centos7.qcow2 \
--network network=default \
--graphics vnc,listen=0.0.0.0 --noautoconsole

<span class="hljs-comment"># 一步创建磁盘+虚拟机</span>
virt-install \
--name centos7 \
--virt-type kvm \
--os-variant=centos7.0 \
--memory 1024 --vcpus 2 \
--cdrom=/data/isos/CentOS-7-x86_64-Minimal-2009.iso \
--disk path=/var/lib/libvirt/images/centos7.qcow2,size=10,format=qcow2,bus=virtio \
--network network=default \
--graphics vnc,listen=0.0.0.0 --autoconsole graphical</code></pre></div>
<h2 id="复制">复制</h2>
<h3 id="磁盘复制实现">磁盘复制实现</h3>
<div><pre class="hljs"><code>cp -a /var/lib/libvirt/images/xxxx.qcow2 \
/var/lib/libvirt/images/xxxxx-2.qcow2</code></pre></div>
<p><img src="/_resources/670fe1ca49e14fb8be5f8e8fdd565522.png" /></p>
<p><img src="/_resources/b0ca3ddab6444678aab87c8094c42cd7.png" /></p>
<h3 id="右键clone">右键clone</h3>
<p><img src="/_resources/90530961e07b42e1a2e34c4298bc0145.png" /><br />
<img src="/_resources/0dfc39b892084bcabf5de423ed285200.png" /><br />
<img src="/_resources/308a3fe30ceb4efd9bcbb75e23d5c74b.png" /></p>
<h3 id="virt-clone克隆">virt-clone克隆</h3>
<div><pre class="hljs"><code>virt-clone -o rocky8 -n rocky8-3
-o rocky8   <span class="hljs-comment">#指已存在的虚拟机的名称</span>
-n rocky8-3 <span class="hljs-comment">#新虚拟机的名称</span>
-f /var/lib/libvirt/images/rocky8-3.qcow2 <span class="hljs-comment">#新虚拟机磁盘文件路径，此文件自动生成，不需要事先创建</span></code></pre></div>
<h2 id="virtio驱动">virtio驱动</h2>
<blockquote>
<p>virtio 是一种 <code>I/O 半虚拟化</code>解决方案，是一套通用 <code>I/O 设备虚拟化</code>的程序，是对半虚拟化 <code>Hypervisor</code> 中的一组通用 <code>I/O 设备的抽象</code>，提供了一套上层应用与各 <code>Hypervisor</code> 虚拟化设备（<code>KVM</code>，<code>Xen</code>， <code>VMware</code>等）之间的通信框架和编程接口，减少跨平台所带来的兼容性问题，大大提高驱动程序开发效率，<code>Windows</code> 系统需要单独安装<code>virtio驱动</code>，<code>Linux</code>系统自带<code>virtio驱动</code>。<br />
<img src="/_resources/a0267ce330ea4290956681fcf2ddf0f8.png" /></p>
</blockquote>
<blockquote>
<p>安装 virtio 的<a title="http://www.Linux-kvm.org/page/Downloads" href="http://www.Linux-kvm.org/page/Downloads">驱动</a></p>
</blockquote>
<ol>
<li>该驱动安装主要针对<code>windows</code>宿主机安装</li>
<li>需要在创建虚拟机的时候，创建两个光驱，一个放windows镜像，一个存放virtio驱动软件</li>
<li>安装系统时，在<code>硬盘安装驱动</code>，先安装<code>virtio</code>驱动</li>
<li>系统安装完成后，对网卡/PCIe等进行 <code>virtio</code>驱动的安装</li>
<li>（可选）对于需要<code>重置</code>/<code>作为模板</code>的windwos虚拟机使用 <code>sysprep</code> 对其进行重写包括<code>SID</code>在内的信息</li>
</ol>
<h2 id="列出主机">列出主机</h2>
<blockquote>
<p>virsh list --all<br />
virsh list --uuid --all --name</p>
</blockquote>
<h2 id="开启关闭">开启关闭</h2>
<blockquote>
<p>virsh start centos7<br />
virsh shutdown centos7<br />
virsh reboot centos7</p>
</blockquote>
<h2 id="暂停恢复">暂停恢复</h2>
<blockquote>
<p>virsh suspend centos7<br />
virsh resume centos7</p>
</blockquote>
<h2 id="开机启动">开机启动</h2>
<p><img src="/_resources/a17df8af72224835b2172b9d1c7b986a.png" /><br />
OR</p>
<blockquote>
<p>virsh autostart centos7</p>
</blockquote>
<p>OR</p>
<blockquote>
<p>通过将配置文件软链接到<code>/etc/libvirt/qemu/autostart/</code> 目录下<br />
ln -s /etc/libvirt/qemu/centos7.xml /etc/libvirt/qemu/autostart/centos7.xml</p>
</blockquote>
<h2 id="删除">删除</h2>
<blockquote>
<p>virsh undefine centos7 # 删除虚拟机配置，但不删除硬盘文件<br />
virsh undefine centos7 --remove-all-storage  # 删除虚拟机包括磁盘文件</p>
</blockquote>
<h2 id="磁盘路径">磁盘路径</h2>
<blockquote>
<p>virsh domblklist centos7</p>
</blockquote>
<h2 id="冷迁移">冷迁移</h2>
<ol>
<li>生成主机的<code>xml</code>文件</li>
</ol>
<blockquote>
<p>virsh dumpxml centos7 &gt; centos7.xml</p>
</blockquote>
<ol start="2">
<li>编辑按需修改
<ul>
<li>id // id是一个递增的唯一数字</li>
<li>disk.source // 磁盘文件ZQ</li>
<li>interface.mac //mac地址</li>
<li>interface.target //网络类型 vnetX</li>
</ul>
</li>
<li>将 <code>centos7.xml</code> 文件复制到另外一个主机上 （同系统）</li>
</ol>
<blockquote>
<p>scp centos7.xml root@192.168.1.1:/etc/libvirt/qemu/</p>
</blockquote>
<h2 id="重要文件">重要文件</h2>
<ol>
<li>主机配置XML文件 <code>/etc/libvirt/qemu/centos7.xml</code></li>
<li>开机启动的gust host 目录 <code>/etc/libvirt/qemu/autostart/</code></li>
</ol>
<h2 id="管理远程主机">管理远程主机</h2>
<ol>
<li>建立互信 (二选一)
<ul>
<li>通过openssh-askpass包
<ul>
<li>apt install -y ssh-askpass / yum -y install openssh-askpass</li>
</ul>
</li>
<li>基于本机到远程主机的key验证 ssh-copy-id
<ul>
<li>ssh-keygen</li>
<li>ssh-copy-id 192.168.1.1 #远程主机地址</li>
</ul>
</li>
</ul>
</li>
<li>File --&gt; Add Connection<br />
<img src="/_resources/89ce23fe6d934d168f0d115beaa78e7a.png" /></li>
<li>添加远程主机</li>
</ol>
<h1 id="镜像制作">镜像制作</h1>
<h2 id="手动制作">手动制作</h2>
<blockquote>
<p>基于容器制作</p>
</blockquote>
<p>!!! info commit 命令<br />
docker commit --help<br />
Usage:  docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</p>
<p>Create a new image from a container's changes</p>
<p>Options:<br />
-a, --author string    Author (e.g., "John Hannibal Smith <a title="mailto:hannibal@a-team.com" href="mailto:hannibal@a-team.com">hannibal@a-team.com</a>")<br />
-c, --change list      Apply Dockerfile instruction to the created image<br />
-m, --message string   Commit message<br />
-p, --pause            Pause container during commit (default true)<br />
!!!</p>
<h3 id="制作步骤">制作步骤</h3>
<ol>
<li>下载官方镜像</li>
<li>前台命令行方式启动</li>
<li>安装所需工具或应用包等</li>
<li>提交处理好的镜像</li>
<li>将新生成的镜像生成容器</li>
</ol>
<h3 id="操作案例-nginx容器制作">操作案例 (nginx容器制作)</h3>
<div><pre class="hljs"><code>1. 拉取centos基础镜像
docker pull rockylinux:9.3

2. 启动基础镜像进入容器
docker run -it --name rockylinux-base rockylinux:9.3 /bin/bash

3. 更改源
sed -e <span class="hljs-string">'s|^mirrorlist=|#mirrorlist=|g'</span> \
    -e <span class="hljs-string">'s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g'</span> \
    -i.bak \
    /etc/yum.repos.d/rocky-*.repo
    
sed -e <span class="hljs-string">'s|^mirrorlist=|#mirrorlist=|g'</span> \
    -e <span class="hljs-string">'s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g'</span> \
    -i.bak \
    /etc/yum.repos.d/rocky.repo

dnf makecache

5. 下载nginx
yum install nginx iproute net-tools -y

6. 清理缓存 （减少空间大小）
rm -rf /var/cache/dnf/*

7. 关闭nginx后台服务
<span class="hljs-comment"># sed 's!daemon on;!daemon off;!' /etc/nginx/nginx.conf</span>
<span class="hljs-comment"># 在全局设置  nginx/1.20.1</span>
sed -i <span class="hljs-string">'9a\daemon off;'</span>  /etc/nginx/nginx.conf
nginx -t

8. 准备自定义页面
<span class="hljs-built_in">echo</span> <span class="hljs-string">"&lt;h1&gt;Hello my container&lt;/h1&gt;"</span> &gt; /usr/share/nginx/html/index.html

9. 提交镜像
docker commit -a <span class="hljs-string">"root@alopex.com"</span> -m <span class="hljs-string">"rockylinux nginx v1"</span> -c <span class="hljs-string">"EXPOSE 80 443"</span> rockylinux-base alopex/rockylinux-nginx:v1

10. 启动容器
docker run -d -p 8080:80 \
--name rocky-base-nginx \
alopex/rockylinux-nginx:v1 \
/usr/sbin/nginx

11. 测试容器
curl 127.0.0.1:8080</code></pre></div>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[第二周作业]]></title>
            <guid>c512f8c02d02485293c57f2e4b863f51</guid>
            <pubDate>Sun, 14 Apr 2024 04:06:22 GMT</pubDate>
            <content:encoded><![CDATA[<nav class="table-of-contents"><ul><li><a href="#各版本zabbix安装">各版本zabbix安装</a><ul><li><a href="#安装">安装</a></li><li><a href="#rpm系包安装">rpm系包安装</a></li><li><a href="#dpkg系包安装">dpkg系包安装</a></li></ul></li><li><a href="#主动模式和被动模式比较与实现">主动模式和被动模式比较与实现</a><ul><li><a href="#被动模式默认">被动模式(默认)</a></li><li><a href="#主动模式">主动模式</a></li><li><a href="#配置">配置</a><ul><li><a href="#配置-1">配置</a></li></ul></li></ul></li><li><a href="#proxy主动被动模式案例">proxy主动被动模式案例</a><ul><li><a href="#原理">原理</a></li><li><a href="#架构">架构</a></li><li><a href="#安装proxy">安装proxy</a></li><li><a href="#工作模式">工作模式</a></li><li><a href="#主动模式-1">主动模式</a><ul><li><a href="#proxy文件">proxy文件</a></li><li><a href="#agent文件">agent文件</a></li><li><a href="#前端配置">前端配置</a></li><li><a href="#验证监控">验证监控</a></li></ul></li><li><a href="#被动模式">被动模式</a><ul><li><a href="#proxy数据库修改">proxy数据库修改</a></li><li><a href="#proxy文件-1">proxy文件</a></li><li><a href="#agent文件-1">agent文件</a></li><li><a href="#前端配置-1">前端配置</a></li><li><a href="#验证监控-1">验证监控</a></li></ul></li><li><a href="#参考">参考</a></li></ul></li><li><a href="#一键zabbix-agent脚本">一键zabbix agent脚本</a></li><li><a href="#一键zabbix-api添加zabbix-agent">一键zabbix api添加zabbix agent</a><ul><li><a href="#api_create-被动模式">api_create (被动模式)</a></li><li><a href="#api_create-主动模式">api_create (主动模式)</a></li></ul></li></ul></nav><h1 id="各版本zabbix安装">各版本zabbix安装</h1>
<h2 id="安装">安装</h2>
<blockquote>
<p><a title="https://www.zabbix.com/download" href="https://www.zabbix.com/download">官方下载链接</a></p>
</blockquote>
<p>!!! warning 注意事项</p>
<ol>
<li>font-end 为 apache, 前端访问地址： <a title="http://host/zabbix" href="http://host/zabbix">http://host/zabbix</a></li>
<li>font-end 为 nginx (zabbix 6.0 后支持), 前端访问地址 http://host_name/<br />
!!!</li>
</ol>
<h2 id="rpm系包安装">rpm系包安装</h2>
<div><pre class="hljs"><code><span class="hljs-comment"># 安装6.0LTS / Rocky Linux 8 / server, fronted, agent / mysql / Apache</span>

1. 关闭epel源的zabbix项
[epel]
...
excludepkgs=zabbix*

2. 安装zabbix仓库
rpm -Uvh https://repo.zabbix.com/zabbix/6.0/rhel/8/x86_64/zabbix-release-6.0-4.el8.noarch.rpm
dnf clean all

3. 安装
dnf install zabbix-server-mysql \
zabbix-web-mysql zabbix-apache-conf \
zabbix-sql-scripts zabbix-selinux-policy \
zabbix-agent mysql-server mysql

4. 创建数据库
mysql -uroot -p
&gt;  password
&gt;  mysql&gt; create database zabbix character <span class="hljs-built_in">set</span> utf8mb4 collate utf8mb4_bin; -- 创建用户zabbix设定字符集等
&gt;  mysql&gt; create user zabbix@localhost identified by <span class="hljs-string">'alopex'</span>; -- 修改用户zabbix的密码
&gt;  mysql&gt; grant all privileges on zabbix.* to zabbix@localhost; -- localhost修改为对应的主机
&gt;  mysql&gt; <span class="hljs-built_in">set</span> global log_bin_trust_function_creators = 1; -- 允许在MySQL服务器中创建并使用自定义函数
&gt;  mysql&gt; quit;

5. 导入数据库脚本
zcat /usr/share/zabbix-sql-scripts/mysql/server.sql.gz | mysql --default-character-set=utf8mb4 -uzabbix -p zabbix
mysql -uroot -p
&gt;  password
&gt;  mysql&gt; <span class="hljs-built_in">set</span> global log_bin_trust_function_creators = 0;  -- 关闭在MySQL服务器中创建并使用自定义函数
&gt;  mysql&gt; quit;

6. 修改zabbix server的DB密码
 /etc/zabbix/zabbix_server.conf
 DBPassword=alopex

7. 设置zabbix开机启动
systemctl restart zabbix-server zabbix-agent httpd php-fpm mysqld.service
systemctl <span class="hljs-built_in">enable</span> zabbix-server zabbix-agent httpd php-fpm mysqld.service

8. 打开zabbix UI访问界面，初始化数据库
...</code></pre></div>
<p><img src="/_resources/e1a831264873427984995344f79d2fb4.png" /><br />
<img src="/_resources/56c0a7b4e10e418eb136f9c2cdf49792.png" /></p>
<h2 id="dpkg系包安装">dpkg系包安装</h2>
<div><pre class="hljs"><code><span class="hljs-comment"># 安装6.0LTS / ubuntu 22.04 / server, fronted, agent / mysql / Nginx</span>

1. 安装zabbix仓库
wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-4+ubuntu22.04_all.deb
dpkg -i zabbix-release_6.0-4+ubuntu22.04_all.deb
apt update

2. 安装
apt install zabbix-server-mysql \
zabbix-frontend-php zabbix-nginx-conf \
zabbix-sql-scripts zabbix-agent \
mysql-server mysql-client

3. 创建数据库
mysql -uroot -p
&gt;  password
&gt;  mysql&gt; create database zabbix character <span class="hljs-built_in">set</span> utf8mb4 collate utf8mb4_bin; -- 创建用户zabbix设定字符集等
&gt;  mysql&gt; create user zabbix@localhost identified by <span class="hljs-string">'alopex'</span>; -- 修改用户zabbix的密码
&gt;  mysql&gt; grant all privileges on zabbix.* to zabbix@localhost; -- localhost修改为对应的主机
&gt;  mysql&gt; <span class="hljs-built_in">set</span> global log_bin_trust_function_creators = 1; -- 允许在MySQL服务器中创建并使用自定义函数
&gt;  mysql&gt; quit;

4. 导入数据库脚本
zcat /usr/share/zabbix-sql-scripts/mysql/server.sql.gz | mysql --default-character-set=utf8mb4 -uzabbix -p zabbix
mysql -uroot -p
&gt;  password
&gt;  mysql&gt; <span class="hljs-built_in">set</span> global log_bin_trust_function_creators = 0;  -- 关闭在MySQL服务器中创建并使用自定义函数
&gt;  mysql&gt; quit;

5. 修改zabbix server的DB密码
 /etc/zabbix/zabbix_server.conf
 DBPassword=alopex

6. 关闭apache2
systemctl <span class="hljs-built_in">disable</span> --now apache2
 
6. 配置PHP前端 
/etc/zabbix/nginx.conf 
listen 8080;
server_name my_zabbix.com;  <span class="hljs-comment"># 修改服务器名称</span>

7. 追加hosts解析
<span class="hljs-built_in">echo</span> <span class="hljs-string">"ip.ip.ip.ip my_zabbix.com"</span>  | sudo tee -a /etc/hosts
 
7. 设置zabbix开机启动
systemctl restart zabbix-server zabbix-agent nginx php8.1-fpm mysql-service
systemctl <span class="hljs-built_in">enable</span> zabbix-server zabbix-agent nginx php8.1-fpm mysql-service
 
8. 打开zabbix UI访问界面，初始化数据库
...</code></pre></div>
<p><img src="/_resources/c699e7e06aeb4e87be124b34c3dcc22a.png" /><br />
<img src="/_resources/3146565c6a6b42fba65abfc137551a3e.png" /></p>
<h1 id="主动模式和被动模式比较与实现">主动模式和被动模式比较与实现</h1>
<h3 id="被动模式默认">被动模式(默认)</h3>
<table>
<thead>
<tr>
<th>项目</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>通信方式</td>
<td>被动模式下,Zabbix Agent被动地等待来自Zabbix Server或Proxy的连接请求和数据收集指令。</td>
</tr>
<tr>
<td>工作特点</td>
<td>1) 定期被Zabbix Server或Proxy主动连接和查询 <br class="jop-noMdConv" /> 2) 监控本地资源和应用程序状态 <br class="jop-noMdConv" /> 3) 将收集的数据发送给Server或Proxy</td>
</tr>
<tr>
<td>适用场景</td>
<td>1) 中小规模环境,无需分布式监控 <br class="jop-noMdConv" /> 2) 防火墙限制,Agent无法主动连接Server <br class="jop-noMdConv" /> 3) 监控对象数量有限</td>
</tr>
<tr>
<td>系统负载</td>
<td>相对较低,Agent处理请求的负载较小</td>
</tr>
<tr>
<td>Agent监听端口</td>
<td>10050 (TCP) - 与Zabbix Server/Proxy通信 <br class="jop-noMdConv" /> 10049 (TCP) - 与Zabbix Server通信(仅被动模式)</td>
</tr>
<tr>
<td>Server/Proxy端口</td>
<td>10051 (TCP) - Zabbix Proxy的Trapper接收主动数据 <br class="jop-noMdConv" /> 10025 (TCP) - Server与Proxy、其他组件通信 <br class="jop-noMdConv" /> 10020 (TCP/UDP) - Server的SNMP Trapper与Agent通信</td>
</tr>
<tr>
<td>数据更新频率</td>
<td>由Zabbix Server或Proxy控制,默认60秒刷新一次被动项目。可根据需求进行配置调整。</td>
</tr>
</tbody>
</table>
<h3 id="主动模式">主动模式</h3>
<table>
<thead>
<tr>
<th>项目</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>通信方式</td>
<td>主动模式下,Zabbix Agent主动连接Zabbix Server,不需要Server端主动查询。</td>
</tr>
<tr>
<td>工作特点</td>
<td>1) 主动连接并主动将监控数据发送给Zabbix Server <br class="jop-noMdConv" /> 2) 可在防火墙后工作,只需开启出站连接 <br class="jop-noMdConv" /> 3) 支持主动发送Trapper数据给Zabbix Server</td>
</tr>
<tr>
<td>适用场景</td>
<td>1) 分布式大规模环境,大量被监控对象 <br class="jop-noMdConv" /> 2) 防火墙限制,只允许主动出站连接 <br class="jop-noMdConv" /> 3) 监控对象分散在广域网络中</td>
</tr>
<tr>
<td>系统负载</td>
<td>相比被动模式,Agent端负载较高,需要主动建立连接。</td>
</tr>
<tr>
<td>Agent监听端口</td>
<td>不适用,没有监听端口。</td>
</tr>
<tr>
<td>Server端口</td>
<td>10051 (TCP) - Zabbix Server Trapper接收主动数据</td>
</tr>
<tr>
<td>数据更新频率</td>
<td>由Agent端控制,可根据配置进行主动更新,默认120秒。</td>
</tr>
</tbody>
</table>
<h2 id="配置">配置</h2>
<h4 id="配置-2">配置</h4>
<p>!!! abstract 配置信息</p>
<ul>
<li>
<p>被动模式 （默认模式）</p>
<ul>
<li>agent端文件配置  <code>/etc/zabbix/zabbix_agentd.conf</code><div><pre class="hljs"><code><span class="hljs-attr">Server</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span> <span class="hljs-comment"># 指向zabbix server</span></code></pre></div>
</li>
<li>重启服务
<blockquote>
<p>systemctl restart zabbix-agent.service</p>
</blockquote>
</li>
<li>前端配置<br />
<img src="/_resources/67849c46e3dd4d82a45a7439f5157ed5.png" /><br />
<img src="/_resources/ed8fa3e798094f399af918df54701dda.png" /></li>
</ul>
</li>
<li>
<p>主动模式</p>
<ul>
<li>agent端文件配置  <code>/etc/zabbix/zabbix_agentd.conf</code><div><pre class="hljs"><code><span class="hljs-attr">Server</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span> <span class="hljs-comment"># !强制! 指向zabbix server</span>
<span class="hljs-attr">ServerActive</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span> <span class="hljs-comment"># !强制! zabbix服务器IP地址</span>
<span class="hljs-attr">Hostname</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.77</span> <span class="hljs-comment"># !强制! 当前主机IP，必须与zabbix server前端主机名称(Host name)相同</span>
<span class="hljs-attr">Timeout</span>=<span class="hljs-number">30</span>   <span class="hljs-comment"># （建议配置 超时时间）</span></code></pre></div>
</li>
<li>重启服务
<blockquote>
<p>systemctl restart zabbix-agent.service</p>
</blockquote>
</li>
<li>前端配置<br />
<img src="/_resources/aa0751cf9f3749cbb21777ada0e3828a.png" /><br />
<img src="/_resources/d240e7afc06c4a049de777af33d5aeb7.png" /></li>
</ul>
<blockquote>
<p>主动模式模板Linux by Zabbix agent active的agent.ping监控项ZBX标记不会变绿，需要修改<br />
为被动模式ZBX标记才能被绿 (可以通过添加 agent.ping 变绿)<br />
!!!</p>
</blockquote>
</li>
</ul>
<h1 id="proxy主动被动模式案例">proxy主动被动模式案例</h1>
<h2 id="原理">原理</h2>
<p>通过<code>zabbix proxy</code>将数据发送给<code>zabbix server</code>，一来减轻了<code>zabbix server</code>的负担，二来可以实现<code>分布式</code>监控，将分散在各处的数据汇集到同一个监控上。<br />
zabbix proxy 是一个数据收集器,它<code>不计算触发器</code>、<code>不处理事件</code>、<code>不发送报警</code>。</p>
<h2 id="架构">架构</h2>
<p><img src="/_resources/f0e00fc6403a489b8b81fdaa14e99036.png" /></p>
<ul>
<li><code>zabbix proxy</code>仅仅需要一条<code>tcp</code>连接到zabbix server，所以防火墙上仅仅需要加上一条规则即可。</li>
<li><code>zabbix proxy</code>数据库必须和<code>server</code>分开，否则数据会被破坏，毕竟这两个数据库的表大部分都相同。总之记住，数据库分开即可。</li>
<li><code>proxy</code>收集到数据之后，首先将数据缓存在本地，然后在<code>一定得时间</code>之后传递给<code>zabbix server</code>。</li>
<li>这个时间由proxy配置文件中参数<code>ProxyLocalBuffer</code> and <code>ProxyOfflineBuffer</code>决定。</li>
</ul>
<h2 id="安装proxy">安装proxy</h2>
<div><pre class="hljs"><code><span class="hljs-comment"># Rocky8 / Mysql</span>
1. 导入官方源
rpm -Uvh https://repo.zabbix.com/zabbix/6.0/rhel/8/x86_64/zabbix-release-6.0-4.el8.noarch.rpm
sed -i.bak <span class="hljs-string">'s/repo.zabbix.com/mirrors.aliyun.com\/zabbix/'</span> /etc/yum.repos.d/zabbix.repo
dnf clean all

2. 安装源
dnf install zabbix-proxy-mysql zabbix-sql-scripts zabbix-selinux-policy mysql-server

3. 创建数据库
<span class="hljs-comment"># mysql -uroot -p</span>
password
mysql&gt; create database zabbix_proxy character <span class="hljs-built_in">set</span> utf8mb4 collate utf8mb4_bin;
mysql&gt; create user zabbix@localhost identified by <span class="hljs-string">'alopex'</span>;
mysql&gt; grant all privileges on zabbix_proxy.* to zabbix@localhost;
mysql&gt; <span class="hljs-built_in">set</span> global log_bin_trust_function_creators = 1;
mysql&gt; quit;

4. 导入数据库脚本
cat /usr/share/zabbix-sql-scripts/mysql/proxy.sql | mysql --default-character-set=utf8mb4 -uzabbix -p zabbix_proxy
mysql -uroot -p
password
mysql&gt; <span class="hljs-built_in">set</span> global log_bin_trust_function_creators = 0;
mysql&gt; quit;

5. 配置数据库密码 
&gt; /etc/zabbix/zabbix_proxy.conf
DBPassword=alopex

6. 启动zabbix-proxy
systemctl restart zabbix-proxy
systemctl <span class="hljs-built_in">enable</span> zabbix-proxy</code></pre></div>
<h2 id="工作模式">工作模式</h2>
<blockquote>
<p>与<code>zabbix agent</code>定位类似</p>
</blockquote>
<ul>
<li>主动模式：<code>proxy</code>周期性主动发送数据给<code>server</code>，大幅降低<code>server</code>的压力。（<code>推介使用</code>）</li>
<li>被动模式：<code>server</code>通过发送监控项指令向<code>proxy</code>请求数据</li>
</ul>
<h2 id="主动模式-2">主动模式</h2>
<table>
<thead>
<tr>
<th>zabbix server</th>
<th>zabbix proxy</th>
<th>zabbix agent (被监控主机)</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.100.136</td>
<td>192.168.100.34</td>
<td>192.168.100.</td>
</tr>
</tbody>
</table>
<h3 id="proxy文件">proxy文件</h3>
<blockquote>
<p>前端配置后，需要重启proxy</p>
</blockquote>
<div><pre class="hljs"><code>grep -v '^<span class="hljs-comment">#\|^$' /etc/zabbix/zabbix_proxy.conf</span>

<span class="hljs-attr">ProxyMode</span>=<span class="hljs-number">0</span>  <span class="hljs-comment"># 开启主动模式（默认）</span>
<span class="hljs-attr">Server</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span> <span class="hljs-comment"># zabbix server IP地址</span>
<span class="hljs-attr">Hostname</span>=zabbix-proxy-active <span class="hljs-comment"># proxy的名称，需和前端配置一致</span>
<span class="hljs-attr">LogFile</span>=/var/log/zabbix/zabbix_proxy.log <span class="hljs-comment"># 日志文件路径</span>
<span class="hljs-attr">LogFileSize</span>=<span class="hljs-number">0</span> 
<span class="hljs-attr">PidFile</span>=/run/zabbix/zabbix_proxy.pid
<span class="hljs-attr">SocketDir</span>=/run/zabbix
<span class="hljs-attr">DBName</span>=zabbix_proxy
<span class="hljs-attr">DBUser</span>=zabbix
<span class="hljs-attr">DBPassword</span>=alopex
<span class="hljs-attr">SNMPTrapperFile</span>=/var/log/snmptrap/snmptrap.log
<span class="hljs-attr">Timeout</span>=<span class="hljs-number">4</span>
<span class="hljs-attr">LogSlowQueries</span>=<span class="hljs-number">3000</span>
<span class="hljs-attr">StatsAllowedIP</span>=<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>,<span class="hljs-number">192.168</span>.<span class="hljs-number">100.0</span>/<span class="hljs-number">24</span> <span class="hljs-comment"># 允许接受的agent网段</span></code></pre></div>
<h3 id="agent文件">agent文件</h3>
<div><pre class="hljs"><code>grep -Ev '^<span class="hljs-comment">#|^$' /etc/zabbix/zabbix_agentd.conf </span>

<span class="hljs-attr">PidFile</span>=/run/zabbix/zabbix_agentd.pid
<span class="hljs-attr">LogFile</span>=/var/log/zabbix/zabbix_agentd.log
<span class="hljs-attr">LogFileSize</span>=<span class="hljs-number">0</span>
<span class="hljs-attr">Server</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span>,<span class="hljs-number">192.168</span>.<span class="hljs-number">100.34</span>
<span class="hljs-attr">ServerActive</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span>,<span class="hljs-number">192.168</span>.<span class="hljs-number">100.34</span>
<span class="hljs-attr">Hostname</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.77</span>
<span class="hljs-attr">Timeout</span>=<span class="hljs-number">20</span>
<span class="hljs-attr">Include</span>=/etc/zabbix/zabbix_agentd.d/*.conf</code></pre></div>
<h3 id="前端配置">前端配置</h3>
<p><img src="/_resources/1d12cd7d87524ac4b7f8104ad4fc64ee.png" /><br />
<img src="/_resources/133d7f150a2645f99230cda754e6f579.png" /></p>
<h3 id="验证监控">验证监控</h3>
<p><img src="/_resources/d49284f3965344b99091e45ae67ce508.png" /><br />
<img src="/_resources/a5288214fff5417bb1e506957d811023.png" /></p>
<h2 id="被动模式">被动模式</h2>
<table>
<thead>
<tr>
<th>zabbix server</th>
<th>zabbix proxy</th>
<th>zabbix agent (被监控主机)</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.168.100.136</td>
<td>192.168.100.34</td>
<td>192.168.100.</td>
</tr>
</tbody>
</table>
<h3 id="proxy数据库修改">proxy数据库修改</h3>
<div><pre class="hljs"><code>mysql -uroot

<span class="hljs-comment"># 被动模式需要zabbix server主动连接，数据库不能仅由proxy访问</span>
UPDATE mysql.user
SET Host = <span class="hljs-string">'localhost'</span>
WHERE User = <span class="hljs-string">'zabbix'</span>;

grant all privileges on zabbix_proxy.* to zabbix@<span class="hljs-string">'192.168.100.%'</span>;

select host,user from mysql.user;</code></pre></div>
<h3 id="proxy文件-2">proxy文件</h3>
<div><pre class="hljs"><code>grep -v '^<span class="hljs-comment">#\|^$' /etc/zabbix/zabbix_proxy.conf</span>

<span class="hljs-attr">ProxyMode</span>=<span class="hljs-number">1</span>  <span class="hljs-comment"># 开启被动模式</span>
<span class="hljs-attr">Server</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span> <span class="hljs-comment"># zabbix server 主机IP</span>
<span class="hljs-attr">Hostname</span>=zabbix-proxy-passive <span class="hljs-comment"># 代理服务器名称，被动模式不要求和后面Web管理页的agent代理程序名称相同</span>
<span class="hljs-attr">LogFile</span>=/var/log/zabbix/zabbix_proxy.log 
<span class="hljs-attr">LogFileSize</span>=<span class="hljs-number">0</span>
<span class="hljs-attr">PidFile</span>=/run/zabbix/zabbix_proxy.pid
<span class="hljs-attr">SocketDir</span>=/run/zabbix
<span class="hljs-attr">DBHost</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.34</span>  <span class="hljs-comment"># 修改为Proxy数据库 IP地址</span>
<span class="hljs-attr">DBName</span>=zabbix_proxy
<span class="hljs-attr">DBUser</span>=zabbix
<span class="hljs-attr">DBPassword</span>=alopex
<span class="hljs-attr">SNMPTrapperFile</span>=/var/log/snmptrap/snmptrap.log
<span class="hljs-attr">Timeout</span>=<span class="hljs-number">4</span>
<span class="hljs-attr">LogSlowQueries</span>=<span class="hljs-number">3000</span>
<span class="hljs-attr">StatsAllowedIP</span>=<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>,<span class="hljs-number">192.168</span>.<span class="hljs-number">100.0</span>/<span class="hljs-number">24</span></code></pre></div>
<h3 id="agent文件-2">agent文件</h3>
<div><pre class="hljs"><code>grep -Ev '^<span class="hljs-comment">#|^$' /etc/zabbix/zabbix_agentd.conf </span>

<span class="hljs-attr">PidFile</span>=/run/zabbix/zabbix_agentd.pid
<span class="hljs-attr">LogFile</span>=/var/log/zabbix/zabbix_agentd.log
<span class="hljs-attr">LogFileSize</span>=<span class="hljs-number">0</span>
<span class="hljs-attr">Server</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.136</span>,<span class="hljs-number">192.168</span>.<span class="hljs-number">100.34</span>  <span class="hljs-comment"># 设置Proxy代理IP</span>
<span class="hljs-attr">Hostname</span>=<span class="hljs-number">192.168</span>.<span class="hljs-number">100.77</span>
<span class="hljs-attr">Timeout</span>=<span class="hljs-number">20</span>
<span class="hljs-attr">Include</span>=/etc/zabbix/zabbix_agentd.d/*.conf</code></pre></div>
<h3 id="前端配置-2">前端配置</h3>
<div><pre class="hljs"><code>sudo grep -Ev <span class="hljs-string">'^#|^$'</span> /etc/zabbix/zabbix_server.conf 
LogFile=/var/<span class="hljs-built_in">log</span>/zabbix/zabbix_server.log
LogFileSize=0
PidFile=/run/zabbix/zabbix_server.pid
SocketDir=/run/zabbix
DBName=zabbix
DBUser=zabbix
DBPassword=alopex
JavaGateway=192.168.100.121
StartJavaPollers=10
SNMPTrapperFile=/var/<span class="hljs-built_in">log</span>/snmptrap/snmptrap.log
Timeout=4
FpingLocation=/usr/bin/fping
Fping6Location=/usr/bin/fping6
LogSlowQueries=3000
StatsAllowedIP=127.0.0.1,192.168.100.0/24  <span class="hljs-comment"># 配置可通信IP地址段</span></code></pre></div>
<p><img src="/_resources/73bc211c0e344e58a1dbd73f5f0028d6.png" /></p>
<h3 id="验证监控-2">验证监控</h3>
<h2 id="参考">参考</h2>
<p><a title="https://www.cnblogs.com/yinzhengjie2020/p/12343765.html" href="https://www.cnblogs.com/yinzhengjie2020/p/12343765.html">zabbix proxy配置实战案例</a></p>
<h1 id="一键zabbix-agent脚本">一键zabbix agent脚本</h1>
<div><pre class="hljs"><code><span class="hljs-meta">#!/bin/bash</span>

<span class="hljs-comment"># 安装agent</span>
wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-4+ubuntu22.04_all.deb
dpkg -i zabbix-release_6.0-4+ubuntu22.04_all.deb
sed -i <span class="hljs-string">'s!http://repo.zabbix.com!https://mirrors.aliyun.com/zabbix!'</span> /etc/apt/sources.list.d/zabbix.list
apt update
apt install zabbix-agent

<span class="hljs-comment"># 主动被动二选一</span>
<span class="hljs-comment">## 被动模式配置修改</span>
<span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> -ne 1 ]
<span class="hljs-keyword">then</span>
   <span class="hljs-built_in">echo</span> <span class="hljs-string">"Usage: bash script.sh &lt;zabbix-server&gt;"</span>
   <span class="hljs-built_in">exit</span> -1
<span class="hljs-keyword">fi</span>
ZABBIX=<span class="hljs-variable">${1}</span>
sed -i <span class="hljs-string">"s/^Server=127.0.0.1/Server=<span class="hljs-variable">${ZABBIX}</span>/"</span> /etc/zabbix/zabbix_agentd.conf

<span class="hljs-comment">## 主动模式配置修改</span>
<span class="hljs-comment">#if [ $# -ne 2 ]</span>
<span class="hljs-comment">#then</span>
<span class="hljs-comment">#   echo "Usage: bash script.sh &lt;zabbix-server&gt; &lt;Hostname&gt;"</span>
<span class="hljs-comment">#   exit -1</span>
<span class="hljs-comment">#fi</span>
<span class="hljs-comment">#ZABBIX=${1}</span>
<span class="hljs-comment">#HOSTNAME=${2}</span>
<span class="hljs-comment">## sed -i "s/^Server=127.0.0.1/Server=${ZABBIX}/" /etc/zabbix/zabbix_agentd.conf</span>
<span class="hljs-comment">## sed -i "s/^ServerActive=127.0.0.1/ServerActive=${ZABBIX}/" /etc/zabbix/zabbix_agentd.conf</span>
<span class="hljs-comment">## sed -i "s/^Hostname=.*/Hostname=${HOSTNAME}/" /etc/zabbix/zabbix_agentd.conf</span>

systemctl restart zabbix-agent</code></pre></div>
<h1 id="一键zabbix-api添加zabbix-agent">一键zabbix api添加zabbix agent</h1>
<h2 id="api_create-被动模式">api_create (被动模式)</h2>
<div><pre class="hljs"><code><span class="hljs-meta">#!/bin/bash</span>

HOST=$(hostname -I | awk <span class="hljs-string">'{print $1}'</span>)
ZABBIX_SERVER=<span class="hljs-string">'my_zabbix.com'</span>
nginx_URL=<span class="hljs-string">"http://<span class="hljs-variable">${ZABBIX_SERVER}</span>/api_jsonrpc.php"</span>
apache_URL=<span class="hljs-string">"http://<span class="hljs-variable">${ZABBIX_SERVER}</span>/zabbix/api_jsonrpc.php"</span>

<span class="hljs-comment"># 选择web服务器类型指定URL</span>
URL=<span class="hljs-variable">$nginx_URL</span>

token=$(curl -s -XPOST -H <span class="hljs-string">"Content-Type: application/json-rpc"</span> -d <span class="hljs-string">'
{
"jsonrpc": "2.0",
"method": "user.login",
"params": {
  "user": "Admin",
  "password": "zabbix"
},
"id": 1,
"auth": null
}'</span> <span class="hljs-variable">$URL</span> | cut -d <span class="hljs-string">','</span> -f2 | cut -d <span class="hljs-string">'"'</span> -f4)

curl -s -XPOST -H <span class="hljs-string">"Content-Type: application/json-rpc"</span> -d <span class="hljs-string">'
{
"jsonrpc": "2.0",
"method": "host.create",
"params": {
  "host": "'</span><span class="hljs-variable">$HOST</span><span class="hljs-string">'",
  "name": "'</span>API-<span class="hljs-variable">$HOST</span><span class="hljs-string">'",
  "interfaces": [
    {
      "type": 1,
      "main": 1,
      "useip": 1,
      "ip": "'</span><span class="hljs-variable">$HOST</span><span class="hljs-string">'",
      "dns": "",
      "port": "10050"
    }
  ],
  "groups": [
    {
      "groupid": "2"
    }
  ],
  "templates": [
    {
      "templateid": "10001"
    }
  ]
},
"id": 1,
"auth": "'</span><span class="hljs-variable">$token</span><span class="hljs-string">'"
}'</span> <span class="hljs-variable">$URL</span> | python3 -m json.tool</code></pre></div>
<h2 id="api_create-主动模式">api_create (主动模式)</h2>
<div><pre class="hljs"><code><span class="hljs-meta">#!/bin/bash</span>

<span class="hljs-keyword">if</span> [[ <span class="hljs-variable">$#</span> -ne 1 ]]
<span class="hljs-keyword">then</span>
  <span class="hljs-built_in">echo</span> <span class="hljs-string">"usage: bash script.sh &lt;HOSTNAME&gt;"</span>
  <span class="hljs-built_in">exit</span> -1
<span class="hljs-keyword">fi</span>

HOST=$(hostname -I | awk <span class="hljs-string">'{print $1}'</span>)
HOSTNAME=<span class="hljs-variable">${1}</span>
ZABBIX_SERVER=<span class="hljs-string">'my_zabbix.com'</span>
nginx_URL=<span class="hljs-string">"http://<span class="hljs-variable">${ZABBIX_SERVER}</span>/api_jsonrpc.php"</span>
apache_URL=<span class="hljs-string">"http://<span class="hljs-variable">${ZABBIX_SERVER}</span>/zabbix/api_jsonrpc.php"</span>

<span class="hljs-comment"># 选择web服务器类型指定URL</span>
URL=<span class="hljs-variable">$nginx_URL</span>

token=$(curl -s -XPOST -H <span class="hljs-string">"Content-Type: application/json-rpc"</span> -d <span class="hljs-string">'
{
"jsonrpc": "2.0",
"method": "user.login",
"params": {
  "user": "Admin",
  "password": "zabbix"
},
"id": 1,
"auth": null
}'</span> <span class="hljs-variable">$URL</span> | cut -d <span class="hljs-string">','</span> -f2 | cut -d <span class="hljs-string">'"'</span> -f4)

curl -s -XPOST -H <span class="hljs-string">"Content-Type: application/json-rpc"</span> -d <span class="hljs-string">'
{
"jsonrpc": "2.0",
"method": "host.create",
"params": {
  "host": "'</span><span class="hljs-variable">$HOSTNAME</span><span class="hljs-string">'",
  "name": "'</span><span class="hljs-variable">$HOST</span><span class="hljs-string">'",
  "interfaces": [
    {
      "type": 1,
      "main": 1,
      "useip": 1,
      "ip": "'</span><span class="hljs-variable">$HOST</span><span class="hljs-string">'",
      "dns": "",
      "port": "10050"
    }
  ],
  "groups": [
    {
      "groupid": "2"
    }
  ],
  "templates": [
    {
      "templateid": "10343"
    }
  ]
},
"id": 1,
"auth": "'</span><span class="hljs-variable">$token</span><span class="hljs-string">'"
}'</span> <span class="hljs-variable">$URL</span> | python3 -m json.tool</code></pre></div>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[第一周作业]]></title>
            <guid>1bce478c5dc64adbb0030681a1d8ab08</guid>
            <pubDate>Tue, 02 Apr 2024 03:19:23 GMT</pubDate>
            <content:encoded><![CDATA[<nav class="table-of-contents"><ul><li><a href="#在虚拟机安装tomcat并部署服务并且实现会话共享">在虚拟机安装tomcat并部署服务，并且实现会话共享</a><ul><li><a href="#tomcat安装">tomcat安装</a><ul><li><a href="#包安装">包安装</a></li></ul></li><li><a href="#部署一个简单应用">部署一个简单应用</a></li><li><a href="#会话共享">会话共享</a><ul><li><a href="#session-绑定">session 绑定</a></li><li><a href="#session-复制">session 复制</a></li><li><a href="#session-server">session Server</a><ul><li><a href="#msm-解决方案">MSM 解决方案</a></li></ul></li></ul></li></ul></li><li><a href="#总结jvm内存结构和垃圾回收算法">总结JVM内存结构和垃圾回收算法</a><ul><li><a href="#jvm-内存管理">JVM 内存管理</a><ul><li><a href="#线程私有的内存区域">线程私有的内存区域</a><ul><li><a href="#程序计数器program-counter-register">程序计数器（Program Counter Register）</a></li><li><a href="#虚拟机栈vm-stack">虚拟机栈（VM Stack）</a></li><li><a href="#本地方法栈native-method-stack">本地方法栈（Native Method Stack）</a></li></ul></li><li><a href="#线程共享的内存区域">线程共享的内存区域</a><ul><li><a href="#堆heap">堆（Heap）</a></li><li><a href="#方法区method-area">方法区（Method Area）</a></li></ul></li></ul></li><li><a href="#垃圾回收机制">垃圾回收机制</a><ul><li><a href="#垃圾判断-what">垃圾判断 (what)</a></li><li><a href="#回收方式-how">回收方式 (how)</a><ul><li><a href="#复制算法coping">复制算法（Coping）</a></li></ul></li><li><a href="#标记清除算法mark-sweep">标记清除算法（Mark-Sweep）</a><ul><li><a href="#标记整理算法mark-compact">标记整理算法（Mark-Compact）</a></li><li><a href="#小结">小结</a></li></ul></li><li><a href="#回收思想-why">回收思想 (why)</a></li><li><a href="#垃圾收集器-which">垃圾收集器 (which)</a><ul><li><a href="#分类">分类</a></li><li><a href="#新生代">新生代</a></li><li><a href="#老年代">老年代</a></li><li><a href="#g1收集器">G1收集器</a></li></ul></li><li><a href="#总结表格">总结表格</a></li><li><a href="#回收时间-when">回收时间 (when)</a></li><li><a href="#收集策略-policy">收集策略 (policy)</a></li><li><a href="#yong-gc-minor-gc-的触发">Yong GC / Minor GC 的触发</a><ul><li><a href="#yong-gc-minor-gc-过程">Yong GC / Minor GC 过程</a></li><li><a href="#old-gc-major-gc-full-gc-的触发">Old GC / Major GC / Full GC 的触发</a></li><li><a href="#old-gc-major-gc-过程">Old GC / Major GC 过程</a></li><li><a href="#full-gc-过程">FULL GC 过程</a></li><li><a href="#minor-gc-vs-major-gc">Minor GC vs Major GC</a></li><li><a href="#survivor-区对象晋升位老年代">Survivor 区对象晋升位老年代</a></li><li><a href="#比例关系">比例关系</a></li></ul></li></ul></li></ul></li><li><a href="#总结安装nexus步骤和私有仓库实现">总结安装Nexus步骤和私有仓库实现</a><ul><li><a href="#安装">安装</a></li><li><a href="#运行">运行</a><ul><li><a href="#前台运行">前台运行</a></li><li><a href="#后台运行">后台运行</a></li><li><a href="#关闭运行">关闭运行</a></li></ul></li><li><a href="#配置启动脚本">配置启动脚本</a></li><li><a href="#首次登录">首次登录</a></li><li><a href="#自建apt仓库">自建apt仓库</a></li></ul></li></ul></nav><h1 id="在虚拟机安装tomcat并部署服务并且实现会话共享">在虚拟机安装tomcat并部署服务，并且实现会话共享</h1>
<h2 id="tomcat安装">tomcat安装</h2>
<h3 id="包安装">包安装</h3>
<div><pre class="hljs"><code><span class="hljs-comment"># CentOS / Rocky</span>
    <span class="hljs-comment"># 查询当前tomcat版本 (一般需要epel源)</span>
    yum list |grep tomcat

    <span class="hljs-comment"># 安装tomcat</span>
    yum -y install tomcat tomcat-admin-webapps tomcat-docs-webapp tomcat-webapps

    <span class="hljs-comment"># 开启tomcat</span>
    systemctl <span class="hljs-built_in">enable</span> --now tomcat.service

    <span class="hljs-comment"># 查看状态</span>
    systemctl status tomcat.service
    ss -tulnp
    journalctl -u tomcat.service
    ps aux|grep tomcat

    <span class="hljs-comment"># 验证</span>
    curl 127.0.0.1:8080

<span class="hljs-comment"># debian / ubuntu</span>
    <span class="hljs-comment"># 查询当前tomcat版本</span>
    apt list | grep tomcat

    <span class="hljs-comment"># 安装tomcat (该包名包含主版本号)</span>
    apt update &amp;&amp; apt -y install tomcat9 tomcat9-admin tomcat9- docs tomcat9-examples

    <span class="hljs-comment"># 开启tomcat</span>
    systemctl <span class="hljs-built_in">enable</span> --now tomcat.service

    <span class="hljs-comment"># 查看状态</span>
    systemctl status tomcat.service
    ss -tulnp
    journalctl -u tomcat.service
    ps aux|grep tomcat

    <span class="hljs-comment"># 验证</span>
    curl 127.0.0.1:8080</code></pre></div>
<h2 id="部署一个简单应用">部署一个简单应用</h2>
<ul>
<li>
<p>conf/server.xml</p>
<div><pre class="hljs"><code><span class="hljs-comment">&lt;!-- 使用默认应用路径    --&gt;</span>
<span class="hljs-comment">&lt;!-- alopex.net __&gt; webapps/ROOT	 --&gt;</span>
<span class="hljs-comment">&lt;!-- alopex.net __&gt; webapps/blog	 --&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">Host</span> <span class="hljs-attr">name</span>=<span class="hljs-string">"alopex.net"</span> <span class="hljs-attr">appBase</span>=<span class="hljs-string">"webapps"</span>
        <span class="hljs-attr">unpackWAR</span>=<span class="hljs-string">"true"</span> <span class="hljs-attr">autoDeploy</span>=<span class="hljs-string">"true"</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Context</span> <span class="hljs-attr">path</span>=<span class="hljs-string">"/blog"</span> <span class="hljs-attr">docBase</span>=<span class="hljs-string">"blog"</span> <span class="hljs-attr">reloadable</span>=<span class="hljs-string">"true"</span>/&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">Valve</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.valves.AccessLogValve"</span> <span class="hljs-attr">directory</span>=<span class="hljs-string">"logs"</span>
           <span class="hljs-attr">prefix</span>=<span class="hljs-string">"alopex_access_webapps_log"</span> <span class="hljs-attr">suffix</span>=<span class="hljs-string">".txt"</span>
           <span class="hljs-attr">pattern</span>=<span class="hljs-string">"%h %l %u %t <span class="hljs-symbol">&amp;quot;</span>%r<span class="hljs-symbol">&amp;quot;</span> %s %b"</span> /&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">Host</span>&gt;</span>

<span class="hljs-comment">&lt;!-- 访问路径与磁盘路径剥离类似于Nginx的alias   --&gt;</span>
<span class="hljs-comment">&lt;!-- alopex.com __&gt;       /www/alopex	 --&gt;</span>
<span class="hljs-comment">&lt;!-- alopex.com/blog __&gt;  /www/alopex/blog	 --&gt;</span>
<span class="hljs-comment">&lt;!-- alopex.com/blogX __&gt; /xxx/blogx	 --&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">Host</span> <span class="hljs-attr">name</span>=<span class="hljs-string">"alopex.com"</span> <span class="hljs-attr">appBase</span>=<span class="hljs-string">"/www/alopex"</span>
        <span class="hljs-attr">unpackWAR</span>=<span class="hljs-string">"true"</span> <span class="hljs-attr">autoDeploy</span>=<span class="hljs-string">"true"</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Context</span> <span class="hljs-attr">path</span>=<span class="hljs-string">""</span> <span class="hljs-attr">docBase</span>=<span class="hljs-string">""</span>/&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Context</span> <span class="hljs-attr">path</span>=<span class="hljs-string">"/blog"</span> <span class="hljs-attr">docBase</span>=<span class="hljs-string">"blog"</span> <span class="hljs-attr">reloadable</span>=<span class="hljs-string">"true"</span>/&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Context</span> <span class="hljs-attr">path</span>=<span class="hljs-string">"/blogX"</span> <span class="hljs-attr">docBase</span>=<span class="hljs-string">"/xxx/blogx"</span> <span class="hljs-attr">reloadable</span>=<span class="hljs-string">"true"</span>/&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">Valve</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.valves.AccessLogValve"</span> <span class="hljs-attr">directory</span>=<span class="hljs-string">"logs"</span>
           <span class="hljs-attr">prefix</span>=<span class="hljs-string">"alopex_access_log"</span> <span class="hljs-attr">suffix</span>=<span class="hljs-string">".txt"</span>
           <span class="hljs-attr">pattern</span>=<span class="hljs-string">"%h %l %u %t <span class="hljs-symbol">&amp;quot;</span>%r<span class="hljs-symbol">&amp;quot;</span> %s %b"</span> /&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">Host</span>&gt;</span></code></pre></div>
</li>
<li>
<p>生成文件</p>
<div><pre class="hljs"><code>tree /xxx/ /www/ ../webapps/blog/
/xxx/
└── blogx
    └── index.html
/www/
└── alopex
    ├── blog
    │   └── index.html
    └── index.html
../webapps/blog/
└── index.html
</code></pre></div>
</li>
<li>
<p>修改用户</p>
<blockquote>
<p>chown -R tomcat.tomcat blog/ /www/ /xxx/</p>
</blockquote>
</li>
<li>
<p>修改访问客户端<code>/etc/hosts</code><br />
<a href="https://www.adamsdesk.com/posts/sudo-echo-permission-denied/">Why Does Sudo Echo Fail with Permission Denied?</a></p>
<blockquote>
<p>echo "192.168.100.34 alopex.com alopex.net " | sudo tee -a /etc/hosts</p>
</blockquote>
</li>
<li>
<p>访问</p>
<ul>
<li><a title="http://alopex.net:8080" href="http://alopex.net:8080">http://alopex.net:8080</a> --&gt; /usr/local/apache-tomcat-9.0.87/webapps/ROOT</li>
<li><a title="http://alopex.net:8080/blog/" href="http://alopex.net:8080/blog/">http://alopex.net:8080/blog/</a> --&gt; /usr/local/apache-tomcat-9.0.87/webapps/blog</li>
</ul>
<blockquote></blockquote>
<ul>
<li><a title="http://alopex.com:8080/" href="http://alopex.com:8080/">http://alopex.com:8080/</a> --&gt; /www/alopex</li>
<li><a title="http://alopex.com:8080/blog/" href="http://alopex.com:8080/blog/">http://alopex.com:8080/blog/</a> --&gt; /www/alopex/blog</li>
<li><a title="http://alopex.com:8080/blogX/" href="http://alopex.com:8080/blogX/">http://alopex.com:8080/blogX/</a> --&gt; /xxx/blogx</li>
</ul>
</li>
</ul>
<h2 id="会话共享">会话共享</h2>
<ul>
<li>
<p>准备工作</p>
<ul>
<li>nginx主机 (nginx/1.18.0 )</li>
</ul>
<div><pre class="hljs"><code>sudo apt install nginx</code></pre></div>
<ul>
<li>tomcat服务器 (java/1.8.0_392, tomcat/9.0.31-1ubuntu0.4)</li>
</ul>
<div><pre class="hljs"><code>sudo apt install openjdk-8-jre
sudo apt install tomcat8
mv /var/lib/tomcat9/webapps/ROOT/index.html /var/lib/tomcat9/webapps/ROOT/index.html.bat

vim /var/lib/tomcat9/webapps/ROOT/index.jsp
&lt;%@ page language=<span class="hljs-string">"java"</span> %&gt;
&lt;html&gt;
  &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;&lt;font color=<span class="hljs-string">"red"</span>&gt;Tomcat1/2 &lt;/font&gt;&lt;/h1&gt;
    &lt;table align=<span class="hljs-string">"centre"</span> border=<span class="hljs-string">"1"</span>&gt;
      &lt;tr&gt;
        &lt;td&gt;Session ID&lt;/td&gt;
    &lt;% session.setAttribute(<span class="hljs-string">"abc"</span>,<span class="hljs-string">"abc"</span>); %&gt;
        &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt;Created on&lt;/td&gt;
        &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt;
     &lt;/tr&gt;
    &lt;/table&gt;
  &lt;/body&gt;
&lt;/html&gt;	

chown -R tomcat.tomcat /var/lib/tomcat9/webapps/ROOT</code></pre></div>
</li>
</ul>
<h3 id="session-绑定">session 绑定</h3>
<blockquote>
<p>特点：简单容实现<br />
缺点：如果目标服务器故障后，如果没有做sessoin持久化<br />
实际应用：实际生产很少选择该方式</p>
</blockquote>
<ul>
<li>
<p>nginx主机</p>
<div><pre class="hljs"><code>vim /etc/nginx/conf.d/tomcat.conf
upstream tomcat-server{
  <span class="hljs-comment"># ip_hash; # 对IP的前24位进行哈希绑定</span>
  <span class="hljs-comment"># hash $remote_addr consistent; # 根据客户端IP的全部位</span>
  <span class="hljs-comment"># hash $cookie_jsessionid consistent; # 通过cookie进行绑定，这样更有助于对主机区分而不是网段</span>
                                        <span class="hljs-comment"># (cookie即使是大写，这里也需要转为小写)</span>
  
  <span class="hljs-comment"># consistent 算法选项可以确保当后端服务器的数量发生变化时，仅有一小部分请求需要重新分配到其他服务器</span>
  <span class="hljs-comment"># 这对于维护会话的连续性和减少因服务器变动而导致的缓存失效非常有用。</span>
  server 192.168.100.121:8080;
  server 192.168.100.122:8080;
}

server {
  listen 192.168.100.120:80;
  location ~* \.(jsp|<span class="hljs-keyword">do</span>)$ {
    proxy_pass http://tomcat-server;
  }
}

systemctl restart nginx.service</code></pre></div>
</li>
<li>
<p>tomcat主机</p>
<div><pre class="hljs"><code>systemctl restart tomcat9.service</code></pre></div>
</li>
<li>
<p>测试</p>
<div><pre class="hljs"><code><span class="hljs-comment"># 浏览器测试</span>
http://192.168.100.120/index.jsp

<span class="hljs-comment"># curl测试</span>
curl http://192.168.100.120/index.jsp -c /tmp/cookie.txt
curl http://192.168.100.120/index.jsp -b /tmp/cookie.txt</code></pre></div>
</li>
</ul>
<h3 id="session-复制">session 复制</h3>
<blockquote>
<p>优点：Tomcat自己的提供的多播集群，通过多播将任何一台的session同步到其它节点；tomcat官方解决方案(建议tomcat<code>数量在4个节点之内</code>)<br />
缺点：Tomcat的同步节点不宜过多，互相即时通信同步session需要<code>大带宽</code>；每一台都拥有<code>全部session</code>，<code>内存损耗太多</code></p>
</blockquote>
<ul>
<li>
<p>nginx服务器</p>
<div><pre class="hljs"><code>vim /etc/nginx/conf.d/tomcat.conf
upstream tomcat-server{
  <span class="hljs-comment"># 轮循算法</span>
  server 192.168.100.121:8080;
  server 192.168.100.122:8080;
}

server {
  listen 192.168.100.120:80;
  location ~* \.(jsp|<span class="hljs-keyword">do</span>)$ {
    proxy_pass http://tomcat-server;
  }
}

systemctl restart nginx.service</code></pre></div>
</li>
<li>
<p>tomcat服务器</p>
<ul>
<li>tomcat9 参考<a title="https://tomcat.apache.org/tomcat-9.0-doc/cluster-howto.html" href="https://tomcat.apache.org/tomcat-9.0-doc/cluster-howto.html">文档</a></li>
<li><code>tomcat9</code> 搭配 <code>java11</code> <code>无法实现session同步</code></li>
<li>conf/server.xml
<ul>
<li><code>address=228.0.0.4</code>: 使用的是组播地址（223.0.0.0 - 239.0.0.0）</li>
<li><code>port=45564</code>: 组播udp端口</li>
<li><code>frequency=500</code>: 500ms 发送一次</li>
<li><code>dropTime=3000</code>: 故障阀值为3秒</li>
<li><code>address="auto"</code>: 监听地址,此项建议修改为当前主机的IP（<code>不支持0.0.0.0</code>），如果不修改可能会导致服务无法启动</li>
<li><code>port=4000</code>: 监听端口</li>
<li><code>autoBind=100</code>: 如果端口出现冲突，自动绑定端口范围<code>4000-4100</code></li>
<li><code>SelectorTime=5000</code>: 自动绑定超时时常<code>5s</code></li>
</ul>
<div><pre class="hljs"><code><span class="hljs-comment">&lt;!-- 在Engine层级添加  --&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">Cluster</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.ha.tcp.SimpleTcpCluster"</span>
             <span class="hljs-attr">channelSendOptions</span>=<span class="hljs-string">"8"</span>&gt;</span>

      <span class="hljs-tag">&lt;<span class="hljs-name">Manager</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.ha.session.DeltaManager"</span>
               <span class="hljs-attr">expireSessionsOnShutdown</span>=<span class="hljs-string">"false"</span>
               <span class="hljs-attr">notifyListenersOnReplication</span>=<span class="hljs-string">"true"</span>/&gt;</span>

      <span class="hljs-tag">&lt;<span class="hljs-name">Channel</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.tribes.group.GroupChannel"</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Membership</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.tribes.membership.McastService"</span>
                    <span class="hljs-attr">address</span>=<span class="hljs-string">"228.0.0.4"</span>
                    <span class="hljs-attr">port</span>=<span class="hljs-string">"45564"</span>
                    <span class="hljs-attr">frequency</span>=<span class="hljs-string">"500"</span>
                    <span class="hljs-attr">dropTime</span>=<span class="hljs-string">"3000"</span>/&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Receiver</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.tribes.transport.nio.NioReceiver"</span>
                  <span class="hljs-attr">address</span>=<span class="hljs-string">"auto"</span>
                  <span class="hljs-attr">port</span>=<span class="hljs-string">"4000"</span>
                  <span class="hljs-attr">autoBind</span>=<span class="hljs-string">"100"</span>
                  <span class="hljs-attr">selectorTimeout</span>=<span class="hljs-string">"5000"</span>
                  <span class="hljs-attr">maxThreads</span>=<span class="hljs-string">"6"</span>/&gt;</span>

        <span class="hljs-tag">&lt;<span class="hljs-name">Sender</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.tribes.transport.ReplicationTransmitter"</span>&gt;</span>
          <span class="hljs-tag">&lt;<span class="hljs-name">Transport</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.tribes.transport.nio.PooledParallelSender"</span>/&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-name">Sender</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Interceptor</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"</span>/&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">Interceptor</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.tribes.group.interceptors.MessageDispatchInterceptor"</span>/&gt;</span>
      <span class="hljs-tag">&lt;/<span class="hljs-name">Channel</span>&gt;</span>

      <span class="hljs-tag">&lt;<span class="hljs-name">Valve</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.ha.tcp.ReplicationValve"</span>
             <span class="hljs-attr">filter</span>=<span class="hljs-string">""</span>/&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-name">Valve</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.ha.session.JvmRouteBinderValve"</span>/&gt;</span>

      <span class="hljs-tag">&lt;<span class="hljs-name">Deployer</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.ha.deploy.FarmWarDeployer"</span>
                <span class="hljs-attr">tempDir</span>=<span class="hljs-string">"/tmp/war-temp/"</span>
                <span class="hljs-attr">deployDir</span>=<span class="hljs-string">"/tmp/war-deploy/"</span>
                <span class="hljs-attr">watchDir</span>=<span class="hljs-string">"/tmp/war-listen/"</span>
                <span class="hljs-attr">watchEnabled</span>=<span class="hljs-string">"false"</span>/&gt;</span>

      <span class="hljs-tag">&lt;<span class="hljs-name">ClusterListener</span> <span class="hljs-attr">className</span>=<span class="hljs-string">"org.apache.catalina.ha.session.ClusterSessionListener"</span>/&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">Cluster</span>&gt;</span></code></pre></div>
</li>
<li>webapps/ROOT/WEB-INFO/web.xml (<code>Make sure your web.xml has the &lt;distributable/&gt; element</code>)<div><pre class="hljs"><code><span class="hljs-meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-name">web-app</span> <span class="hljs-attr">xmlns</span>=<span class="hljs-string">"http://xmlns.jcp.org/xml/ns/javaee"</span>
  <span class="hljs-attr">xmlns:xsi</span>=<span class="hljs-string">"http://www.w3.org/2001/XMLSchema-instance"</span>
  <span class="hljs-attr">xsi:schemaLocation</span>=<span class="hljs-string">"http://xmlns.jcp.org/xml/ns/javaee
                      http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd"</span>
  <span class="hljs-attr">version</span>=<span class="hljs-string">"4.0"</span>
  <span class="hljs-attr">metadata-complete</span>=<span class="hljs-string">"true"</span>&gt;</span>

  <span class="hljs-tag">&lt;<span class="hljs-name">display-name</span>&gt;</span>Welcome to Tomcat<span class="hljs-tag">&lt;/<span class="hljs-name">display-name</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>
     Welcome to Tomcat
  <span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span>
  <span class="hljs-comment">&lt;!-- 添加此行 --&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">distributable</span>/&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">web-app</span>&gt;</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="session-server">session Server</h3>
<h4 id="msm-解决方案">MSM 解决方案</h4>
<blockquote>
<p>当前MSM<code>不支持 tomcat 10</code>版本<br />
(memcached session manager) 提供将Tomcat的session保持到memcached或Redis的程序，可以实现高可用</p>
</blockquote>
<ul>
<li>
<p><a title="https://github.com/magro/memcached-session-manager" href="https://github.com/magro/memcached-session-manager">项目连接</a></p>
</li>
<li>
<p>支持Tomcat的 6.x、7.x、8.x、9.x</p>
<ul>
<li>memcached-session-manager-2.3.2.jar</li>
<li>memcached-session-manager-tc8-2.3.2.jar</li>
</ul>
</li>
<li>
<p>Session数据的序列化、反序列化类</p>
<ul>
<li>官方推荐kyro</li>
<li>在webapp中WEB-INF/lib/下</li>
</ul>
</li>
<li>
<p>驱动类</p>
<ul>
<li>memcached(spymemcached.jar)</li>
<li>Redis(jedis.jar)</li>
</ul>
</li>
<li>
<p>配置</p>
</li>
</ul>
<div><pre class="hljs"><code><span class="hljs-comment"># 在 $CATALINA_HOME/lib/ 目录下放入如需包</span>
kryo-3.0.3.jar
asm-5.2.jar
objenesis-2.6.jar
reflectasm-1.11.9.jar
minlog-1.3.1.jar
kryo-serializers-0.45.jar
msm-kryo-serializer-2.3.2.jar
memcached-session-manager-tc8-2.3.2.jar
spymemcached-2.12.3.jar
memcached-session-manager-2.3.2.jar

<span class="hljs-comment"># sticky 模式</span>
&gt; 即前端tomcat和后端memcached有关联(粘性)关系

<span class="hljs-comment"># 粘性一般为交叉粘性，因此主机n1,对应failoverNodes为n1;同理主机n2,对应failoverNodes为n2</span>
<span class="hljs-comment"># memcachedNodes="n1:host1.yourdomain.com:11211,n2:host2.yourdomain.com:11211"</span>
<span class="hljs-comment"># memcached的节点: n1、n2只是别名，可以重新命名。</span>
<span class="hljs-comment"># failoverNodes 为故障转移节点，n1是备用节点，n2是主存储节点。另一台Tomcat将此处的n1改为n2，</span>

<span class="hljs-comment"># 修改$CATALINA_HOME/conf/context.xml</span>
<span class="hljs-comment"># 其主节点是n1，备用节点是n2。</span>
    <span class="hljs-comment"># n1 (192.168.100.121) 配置 </span>
    &lt;Context&gt;
    &lt;Manager className=<span class="hljs-string">"de.javakaffee.web.msm.MemcachedBackupSessionManager"</span>
             memcachedNodes=<span class="hljs-string">"n1:192.168.100.121:11211,n2:192.168.100.122:11211"</span>
             failoverNodes=<span class="hljs-string">"n1"</span>
             requestUriIgnorePattern=<span class="hljs-string">".*\.(ico|png|gif|jpg|css|js)$"</span>
             transcoderFactoryClass=<span class="hljs-string">"de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"</span>/&gt;
    &lt;/Context&gt;
    <span class="hljs-comment"># n2 (192.168.100.122) 配置</span>
    &lt;Context&gt;
    &lt;Manager className=<span class="hljs-string">"de.javakaffee.web.msm.MemcachedBackupSessionManager"</span>
             memcachedNodes=<span class="hljs-string">"n1:192.168.100.121:11211,n2:192.168.100.122:11211"</span>
             failoverNodes=<span class="hljs-string">"n2"</span>
             requestUriIgnorePattern=<span class="hljs-string">".*\.(ico|png|gif|jpg|css|js)$"</span>
             transcoderFactoryClass=<span class="hljs-string">"de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"</span>/&gt;
    &lt;/Context&gt;


    <span class="hljs-comment"># 查看启动日志</span>
    journal -u tomcat9.service
    Mar 19 13:19:52 n2 tomcat9[86253]: --------
    Mar 19 13:19:52 n2 tomcat9[86253]: -  finished initialization:
    Mar 19 13:19:52 n2 tomcat9[86253]: - sticky: <span class="hljs-literal">true</span>
    Mar 19 13:19:52 n2 tomcat9[86253]: - operation timeout: 1000
    Mar 19 13:19:52 n2 tomcat9[86253]: - node ids: [n1]
    Mar 19 13:19:52 n2 tomcat9[86253]: - failover node ids: [n2]
    Mar 19 13:19:52 n2 tomcat9[86253]: - storage key prefix: null
    Mar 19 13:19:52 n2 tomcat9[86253]: - locking mode: null (expiration: 5s)
    Mar 19 13:19:52 n2 tomcat9[86253]: --------</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-comment"># non-sticky 模式</span>
&gt; 即前端tomcat和后端memcached无关联(无粘性)关系，从msm 1.4.0之后版本开始支持non-sticky模式。

<span class="hljs-comment"># 在 $CATALINA_HOME/lib/ 目录下放入如需包</span>
kryo-3.0.3.jar
asm-5.2.jar
objenesis-2.6.jar
reflectasm-1.11.9.jar
minlog-1.3.1.jar
kryo-serializers-0.45.jar
msm-kryo-serializer-2.3.2.jar
memcached-session-manager-tc8-2.3.2.jar
spymemcached-2.12.3.jar
memcached-session-manager-2.3.2.jar

    <span class="hljs-comment"># 修改$CATALINA_HOME/conf/context.xml</span>
    <span class="hljs-comment"># n1 (192.168.100.121) 配置</span>
    &lt;Context&gt;
    &lt;Manager className=<span class="hljs-string">"de.javakaffee.web.msm.MemcachedBackupSessionManager"</span>
             memcachedNodes=<span class="hljs-string">"n1:192.168.100.121:11211,n2:192.168.100.122:11211"</span>
             sticky=<span class="hljs-string">"false"</span>
             requestUriIgnorePattern=<span class="hljs-string">".*\.(ico|png|gif|jpg|css|js)$"</span>
             transcoderFactoryClass=<span class="hljs-string">"de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"</span>/&gt;
    &lt;/Context&gt;</code></pre></div>
<ul>
<li>检查memcached脚本 (配置完成后测试)
<ul>
<li><code>sudo apt install python3-pip &amp;&amp; pip3 install python-memcached</code></li>
<li><a>显示memcache内容</a></li>
</ul>
</li>
</ul>
<h1 id="总结jvm内存结构和垃圾回收算法">总结JVM内存结构和垃圾回收算法</h1>
<h2 id="jvm-内存管理">JVM 内存管理</h2>
<p><img src="/_resources/556a3219e39543ca97d38494668252ac.png" /></p>
<h3 id="线程私有的内存区域">线程私有的内存区域</h3>
<h4 id="程序计数器program-counter-register">程序计数器（Program Counter Register）</h4>
<p>程序计数器是一块较小的内存空间（可能位于cpu的寄存器，有待确认），可以看做是当前字节码指令执行的行号指示器，记录了当前正在执行的虚拟机字节码指令地址。每个线程都有各自独立的程序计数器，注意如果正在执行的是 Native方法，则程序计数器为空（Undifined），并且 JVM 规范中并<code>没有对程序计数器定义 OutOfMemoryError 异常</code>。</p>
<h4 id="虚拟机栈vm-stack">虚拟机栈（VM Stack）</h4>
<p>虚拟机栈也是线程私有的，它描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每一个方法从调用直至完成的过程，就对应着一个栈帧在虚拟机栈中入栈和出栈的过程。</p>
<p>虚拟机栈帧中，<code>局部变量表</code>是比较为人所熟知的，也就是平常所说的“栈”，局部变量表所需的内存空间在编译期间分配完成，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法<code>运行期间</code>不会改变局部变量表的大小。</p>
<p>虚拟机栈有两种异常情况：</p>
<ol>
<li><code>StackOverflowError</code>：线程请求的栈深度大于虚拟机所允许的深度，特别是方法的递归调用时</li>
<li><code>OutOfMemoryError</code>：虚拟机栈无法满足线程所申请的空间需求，即使经过动态扩展仍然无法满足时抛出</li>
</ol>
<h4 id="本地方法栈native-method-stack">本地方法栈（Native Method Stack）</h4>
<p>本地方法栈与虚拟机栈相似，不过服务于本地方法，有些虚拟机将这两个区域合二为一。本地方法栈中抛出异常的情况与虚拟机栈相同。</p>
<h3 id="线程共享的内存区域">线程共享的内存区域</h3>
<h4 id="堆heap">堆（Heap）</h4>
<p>通常来说，堆是Java虚拟机管理的内存中<code>最大的一块</code>，被所有线程共享，在虚拟机启动时创建，堆的作用就是存储对象实例。</p>
<p>堆也是垃圾收集器所管理的主要区域，因此很多时候也被称作<code>GC堆</code>。从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，因此堆还可以被细分为：<code>新生代</code>和<code>老年代</code>。再继续细分可以分为：<code>Eden空间</code>、<code>From Survivor空间</code>、<code>To Survivor空间</code>等，从内存分配的角度来看，线程共享的堆中还可以划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB）。</p>
<p>堆可以是<code>物理上不连续的空间</code>，只要<code>逻辑上是连续的</code>即可，-Xmx和-Xms参数可以控制堆的最大和最小值。</p>
<p>堆的空间大小不满足时将抛出<code>OutOfMemoryError异常</code>。</p>
<h4 id="方法区method-area">方法区（Method Area）</h4>
<p>用于存储已被虚拟机加载的<code>类信息</code>、<code>常量</code>、<code>静态变量</code>、<code>JIT编译后的代码</code>等数据。Java虚拟机规范将方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做<code>Non-Heap</code>（非堆）。</p>
<p>方法区同样会抛出<code>OutOfMemoryError异常</code>。</p>
<p>在方法区中有一部分区域用来存储编译期产生的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。这里需要说明一点，常量并不是只能在编译期产生，运行期间也会产生新的常量并被发在常量池中，如 String 类的 intern() 方法。</p>
<h2 id="垃圾回收机制">垃圾回收机制</h2>
<p>JVM 管理的内存中，线程私有的<code>虚拟机栈</code>、<code>本地方法栈</code>以及<code>程序计数器</code>都是随着线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出有条不紊的进行入栈和出栈。<br />
这部分内存区域随着线程结束或者方法退出自然的就被释放回收了，因此这部分不需要过多考虑回收问题。而 <code>Java 堆</code>和<code>方法区</code>则不一样，这部分内存的分配和回收都是动态的。垃圾收集器关注的区域主要指的是这部分内存。</p>
<h3 id="垃圾判断-what">垃圾判断 (what)</h3>
<blockquote>
<p>GC 在垃圾回收的时候首先需要判断哪些对象时仍在使用，哪些是已经不再使用了</p>
</blockquote>
<ul>
<li><code>引用计数法</code>
<ul>
<li>给对象添加一个引用计数器，每当有一个地方引用计数器就加 1，引用失效时计数器就减 1</li>
<li>因此哪些计数器为 0 的对象都是不再被引用需要回收的对象</li>
<li>优点: 实现简单、效率也高</li>
<li>缺点: 无法解决对象之间相互引用的情况 (相互引用成一个整体，但并无其他对象对其调用)</li>
</ul>
</li>
<li><code>达性分析法</code> (HotSpot 默认)
<ul>
<li>通过一系列称为 <code>GC Roots</code> 的对象作为起点开始向下进行搜索，搜索走过的路径叫做<code>引用链</code></li>
<li>如果一个对象<code>没有任何引用链与其相连</code>时说明该对象不可达，即不可能再被使用到</li>
<li>可作为 <code>GC Roots</code> 的对象
<ul>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象</li>
<li>本地方法栈中 Native 方法引用的对象</li>
<li>方法区中的常量引用的对象</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="回收方式-how">回收方式 (how)</h3>
<h4 id="复制算法coping">复制算法（Coping）</h4>
<p>这种算法将可用内存按照容量划分为大小相等的两部分，每次只使用其中一半，当这一半使用完了就将其中还存活的对象复制到另一块内存上，然后对这一块内存进行回收，循环往复。优点是<code>实现简单、运行高效</code>。缺点就是可用<code>内存缩小到了原来的一半</code>，这个代价稍微有点高！</p>
<p>这种算法主要被用来回收新生代，因为新生代中的对象百分之九十八都是“朝生夕死”，也就是说大部分内存都会被回收掉，那就没有必要按照 1:1 的比例划分内存空间，而是将内存分为较大的一块 <code>Eden</code> 空间和两块较小的 <code>Survivor</code> 空间。每次使用 <code>Eden</code> 和其中一块 <code>Survivor</code> 区（from），当回收时将其中的存活对象复制到另外一块 <code>Survivor</code> 区，把 <code>Eden</code> 和刚才用过的 <code>Survivor</code> 区清理掉。<code>HotSpot</code> 虚拟机默认的 <code>Eden</code> 和 <code>Survivor</code> 内存比例是 <code>8:1</code>，也就是说每次新生代的可用空间为整个新生代容量的 90%，这样内存的利用率很高，一定程度上避免了上面提到的可用内存折半的缺点。但是我们并没有办法保证每次回收都只有不到 10% 的对象存活（因为存活的对象会被复制到 survivor to 区，这部分只占了 10%），这样就有可能出现 <code>Survivor</code> 内存不够用，需要依赖其它内存（老年代）进行分配担保。<br />
显然在<code>对象存活率较高</code>的情况下这种算法效率就会降低。</p>
<h3 id="标记清除算法mark-sweep">标记清除算法（Mark-Sweep）</h3>
<p>这时最基础的收集算法，分为 “标记” 和“清除”两个阶段：首先按照上面介绍的方法标记出需要回收的对象，标记完成后统一对被标记的对象内存进行回收。显然这种方式会导致<code>产生大量不连续的内存碎片</code>，从而导致后面再需要分配较大对象时<code>无法找到足够的连续内存</code>，从而提前触发另一次垃圾收集。</p>
<h4 id="标记整理算法mark-compact">标记整理算法（Mark-Compact）</h4>
<p>老年代由于存活率比较高（想想为什么），因此并不适合上面提到的复制算法，针对其特点，“<code>标记 - 整理</code>”的算法被提出来。其标记过程与 “<code>标记 - 清除</code>” 算法的过程一样，但后续并不是直接对标记对象进行清理，而是让存活的对象都向一端移动，然后直接清理掉边界以外的区域。</p>
<h4 id="小结">小结</h4>
<p>当代虚拟机都采用 “分代收集” 的思想，一般根据对象存活周期将 Java 堆分为<code>新生代</code>和<code>老年代</code>，分别根据其特点选择相应的收集算法：<code>新生代对象</code>存活率低，则采用 <code>复制算法</code> 只需要对极少比例的存活对象进行复制即可完成收集；而<code>老年代</code>因为存活率高，没有额外空间对其进行分配担保，就必须使用 “<code>标记 - 清理</code>”或者 “<code>标记 - 整理</code>” 算法 来回收。</p>
<h3 id="回收思想-why">回收思想 (why)</h3>
<blockquote>
<p>对任何 “活” 的对象，一定能最终追溯到其存活在<code>堆栈</code>或<code>静态存储区</code>中的引用。<br />
基于此从<code>堆栈</code>和<code>静态存储区</code>开始遍历所有的引用，就能找到所有 “活” 的对象，对这些对象进行标记，将其余的对象回收。</p>
</blockquote>
<ul>
<li>实现方式
<ul>
<li><code>停止 - 复制模式</code> (对应大空间，回收空间连续)
<ul>
<li>先暂停程序运行，将所有活得对象从当前堆复制到另一个堆，没有复制的对象都当作垃圾回收，复制到新堆时对象会被一个挨着一个整齐的排列，这样便可以按照前面说的移动 “堆指针” 的方式直接分配新空间了。当然这种 “复制移动” 式的回收方法效率较低，通常做法是按需从堆中分配几块较大的内存，复制动作发生在这几块<code>较大的内存之间</code>。</li>
</ul>
</li>
<li><code>标记 - 清扫模式</code> (对应小空间，回收空间不连续)
<ul>
<li>前一种 “停止 - 复制” 模式在垃圾较少的情况下效率仍然很低下，因为这时大量的复制行为其实没有必要，于是另一种新的方法。遍历所有引用进而<code>找到所有存活的对象</code>并对其标记，标记完成以后将<code>没有标记的对象清理</code>，这个过程中并不做任何复制。当然这样的话剩下的堆<code>空间并不是连续的</code>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="垃圾收集器-which">垃圾收集器 (which)</h3>
<ul>
<li>串行垃圾回收器：一个GC线程完成回收工作
<ul>
<li><img src="/_resources/7e90ff860cb4420dbfc1a76fadc6109e.png" /></li>
</ul>
</li>
<li>并行垃圾回收器：多个GC线程同时一起完成回收工作，充分利用CPU资源
<ul>
<li><img src="/_resources/e7655cc5a99b4991a9353ca648c309b6.png" /></li>
</ul>
</li>
<li>并行和并发
<ul>
<li><code>并行</code>（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。</li>
<li><code>并发</code>（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行。而垃圾收集程序运行在另一个CPU上。</li>
</ul>
</li>
<li>吞吐量（Throughput）
<ul>
<li>吞吐量就是<code>CPU用于运行用户代码的时间与CPU总消耗时间的比值</code></li>
<li>即: 吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）。</li>
<li>假设虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。</li>
</ul>
</li>
</ul>
<h4 id="分类">分类</h4>
<p><img src="/_resources/fca2e5d8870e4a59acef34905d67aff9.png" /></p>
<blockquote>
<p><code>JVM 1.8</code> 默认的垃圾回收器：<code> Parallel Scavenge</code> + <code>ParallelOld</code>,所以大多数都是针对此进行调优</p>
</blockquote>
<h4 id="新生代">新生代</h4>
<ul>
<li>Serial收集器
<ul>
<li>最基本、发展历史最悠久的收集器，它是采用复制算法的新生代收集器，曾经（<code>JDK 1.3.1之前</code>）是虚拟机新生代收集的唯一选择。</li>
<li>一个单线程收集器，只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集时，必须暂停其他所有的工作线程，直至Serial收集器收集结束为止（“Stop The World”）</li>
<li>这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说是<code>难以接受</code>的。</li>
<li>Serial收集器对于运行在Client模式下的虚拟机来说是一个很不错的选择。</li>
<li><img src="/_resources/9b6426243ef144ddbb74a7c60860ff9f.png" /></li>
</ul>
</li>
<li>ParNew 收集器
<ul>
<li>Serial收集器的<code>多线程版本</code>，它也是一个新生代收集器。除了使用多线程进行垃圾收集外，其余行为包括Serial收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与Serial收集器完全相同，两者共用了相当多的代码。</li>
<li>ParNew 收集器在<code>单CPU</code>的环境中绝对不会有比Serial收集器有更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越。</li>
<li><img src="/_resources/e4102632ac8d4eb59c5f0cfc2d5e2a04.png" /></li>
</ul>
</li>
<li>Parallel Scavenge 收集器
<ul>
<li>个并行的多线程新生代收集器，它也使用复制算法。Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是达到一个<code>可控制的吞吐量</code>（Throughput）。</li>
<li>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而<code>高吞吐量则可以高效率地利用CPU时间</code>，<code>尽快完成程序的运算任务</code>，主要适合在后台运算而<code>不需要太多交互的任务</code>。</li>
</ul>
</li>
</ul>
<h4 id="老年代">老年代</h4>
<ul>
<li>Serial Old收集器
<ul>
<li>Serial收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”（Mark-Compact）算法。 此收集器的主要意义也是在于给<code>Client模式</code>下的虚拟机使用。</li>
<li><img src="/_resources/238bbb5df7274354b8c630ffe6f7fa88.png" /></li>
</ul>
</li>
<li>Parallel Old收集器
<ul>
<li>是<code>Parallel Scavenge</code>收集器的老年代版本，使用多线程和“标记-整理”算法，“吞吐量优先”收集器终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。</li>
<li><img src="/_resources/7b43fbc61461486ab107e1dc5010e27a.png" /></li>
</ul>
</li>
<li>CMS收集器
<ul>
<li>以获取<code>最短回收停顿时间</code>为目标的收集器，它非常符合那些集中在互联网站或者<code>B/S</code>系统的服务端上的Java应用</li>
<li>CMS收集器工作的整个流程分为以下4个步骤：
<ul>
<li><code>初始标记</code>（CMS initial mark）：仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。</li>
<li><code>并发标记</code>（CMS concurrent mark）：进行GC Roots Tracing的过程，在整个过程中耗时最长。</li>
<li><code>重新标记</code>（CMS remark）：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要“Stop The World”。</li>
<li><code>并发清除</code>（CMS concurrent sweep）</li>
</ul>
</li>
<li>由于整个过程中耗时最长的<code>并发标记</code>和<code>并发清除</code>过程收集器线程都可以与用户线程一起工作。所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。</li>
<li><img src="/_resources/be90f86dcfd3447d8a08220be5a81cc2.png" /></li>
</ul>
</li>
</ul>
<h4 id="g1收集器">G1收集器</h4>
<blockquote>
<p>收集器是当今收集器技术发展最前沿的成果之一，它是一款面向<code>服务端</code>应用的垃圾收集器<br />
HotSpot开发团队赋予它的使命是（在比较长期的）未来可以<code>替换掉</code>JDK 1.5中发布的<code>CMS</code>收集器。<br />
<code>并行与并发</code> G1 能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。</p>
<p><code>分代收集</code> 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。</p>
<p><code>空间整合</code> G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。</p>
<p><code>可预测的停顿</code> 这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了</p>
</blockquote>
<ul>
<li><img src="/_resources/9152055cb6694bbba1afccc17d525ee0.png" /></li>
</ul>
<h3 id="总结表格">总结表格</h3>
<p><img src="/_resources/af2f453bd203428f8299e731fb0a15d3.png" /></p>
<h3 id="回收时间-when">回收时间 (when)</h3>
<ul>
<li><code>Partial GC</code>(局部 GC): 并不收集整个 <code>GC</code> 堆的模式
<ul>
<li><code>Young GC</code>: 只收集 <code>young gen</code> 的 <code>GC</code>，<code>Young GC</code> 还有种说法就叫做 "<code>Minor GC</code>"</li>
<li><code>Old GC</code>: 只收集<code>old gen</code>的<code>GC</code>。只有垃圾收集器<code>CMS</code>的 <code>concurrent collection</code> 是这个模式</li>
<li><code>Mixed GC</code>: 收集整个<code>young gen</code> 以及<code>部分old gen</code>的GC。只有垃圾收集器 <code>G1</code>有这个模式</li>
</ul>
</li>
<li><code>Full GC</code>: 收集整个堆，包括 <code>新生代</code>，<code>老年代</code>，<code>永久代</code>(在 JDK 1.8及以后，永久代被移除，换为<code>metaspace</code> 元空间)等所有部分的模式</li>
</ul>
<h3 id="收集策略-policy">收集策略 (policy)</h3>
<p><img src="/_resources/2c642b3ddd014c90867f6dbdf6f722e2.png" /></p>
<h3 id="yong-gc-minor-gc-的触发">Yong GC / Minor GC 的触发</h3>
<blockquote>
<p>当 <code>Eden</code> 区的空间耗尽时 Java 虚拟机便会触发一次 <code>Minor GC</code> 来收集新生代的垃圾<br />
存活下来的对象，则会被送到 <code>Survivor</code> 区<br />
在进行Yong GC时，通常会使用一种称为"<code>Stop-the-World</code>"的方式来暂停应用程序的执行。</p>
</blockquote>
<h4 id="yong-gc-minor-gc-过程">Yong GC / Minor GC 过程</h4>
<blockquote>
<p>当发生 <code>Minor GC</code> 时，<code>Eden</code> 区和 <code>from</code> 指向的 <code>Survivor</code> 区中的存活对象会被复制(此处采用<code>标记复制</code>算法)到 <code>to</code> 指向的 <code>Survivor</code> 区中<br />
然后交换 <code>from</code> 和 <code>to</code> 指针，以保证下一次 <code>Minor GC</code> 时，<code>to</code> 指向的 <code>Survivor</code> 区还是空的。<br />
<code>from</code> 与 <code>to</code> 只是两个指针，它们变动的，<code>to</code> 指针指向的 <code>Survivor</code> 区是空的。</p>
</blockquote>
<h4 id="old-gc-major-gc-full-gc-的触发">Old GC / Major GC / Full GC 的触发</h4>
<ul>
<li>显式的调用 <code>System.gc()</code>
<ul>
<li>应<code>避免</code>在代码中显式调用此方法，让虚拟机自己去管理它的内存</li>
</ul>
</li>
<li><code>serial GC</code> 中
<ul>
<li>老年代内存剩余已经小于之前年轻代晋升老年代的平均大小</li>
</ul>
</li>
<li><code>CMS</code> 等并发收集器中
<ul>
<li>每隔一段时间检查一下老年代内存的使用量，超过一定比例时进行 <code>Full GC</code> 回收</li>
</ul>
</li>
</ul>
<h4 id="old-gc-major-gc-过程">Old GC / Major GC 过程</h4>
<blockquote>
<p>进行<code>Major GC</code>（大型垃圾回收）时，主要是针对Java堆中的<code>老年代</code>进行回收<br />
首先会<code>标记老年代中的存活对象</code>，然后<code>清理未被标记的对象</code>，释放它们所占用的内存空间。<br />
可能会导致应用<code>程序的停顿</code>，因为在执行垃圾回收时需要暂停应用程序的执行</p>
</blockquote>
<h4 id="full-gc-过程">FULL GC 过程</h4>
<blockquote>
<p>对整个Java堆进行垃圾回收的过程</p>
<ol>
<li>暂停应用程序：为了执行FULL GC，垃圾回收器会暂停应用程序的执行。这个停顿时间的长短取决于具体的垃圾收集器和应用程序的大小。</li>
<li>年轻代垃圾回收：首先，垃圾回收器会执行年轻代的垃圾回收，类似于Yong GC的过程。它会标记和清理年轻代中的垃圾对象，并将存活对象复制到生存带或老年代中。</li>
<li>生存带垃圾回收：接下来，垃圾回收器会对生存带进行垃圾回收。生存带是年轻代中的两个区域之一，用于存放经过一次年轻代垃圾回收后仍然存活的对象。垃圾回收器会标记和清理生存带中的垃圾对象，并将存活对象复制到另一个生存带或老年代中。</li>
<li>老年代垃圾回收：最后，垃圾回收器会对老年代进行垃圾回收。老年代是存放存活时间较长的对象的区域。垃圾回收器会标记和清理老年代中的垃圾对象，并释放它们所占用的内存空间。</li>
<li>内存整理：在FULL GC过程中，垃圾回收器可能会进行内存整理操作，以减少内存碎片化。它会将存活的对象进行整理，使得内存布局更加紧凑。<br />
恢复应用程序执行：完成FULL GC后，垃圾回收器会恢复应用程序的执行，使其继续运行。</li>
</ol>
</blockquote>
<h4 id="minor-gc-vs-major-gc">Minor GC vs Major GC</h4>
<blockquote>
<p><code>Minor GC</code> 可能会引起<code>短暂的STW</code>暂停。当进行 <code>Minor GC</code> 时，为了确保安全性，JVM 需要在某些特定<br />
的点上暂停所有应用程序的线程，以便更新一些关键的数据结构。<br />
这些暂停通常是非常短暂的，通常在<code>毫秒级别</code>，并且很少对应用程序的性能产生显著影响。</p>
</blockquote>
<blockquote>
<p><code>Major GC</code>的暂停时间通常会比<code>Minor GC</code>的暂停<code>时间更长</code>，因为老年代的容量通常比年轻代大得多。<br />
这意味着在收集和整理大量内存时，需要更多的时间来完成垃圾收集操作。</p>
</blockquote>
<h4 id="survivor-区对象晋升位老年代">Survivor 区对象晋升位老年代</h4>
<blockquote>
<p>JVM 会记录 <code>Survivor</code> 区中的对象在 <code>from</code> 和 <code>to</code> 之间一共被来回复制的次数<br />
一个对象被复制的次数为 <code>15</code> （参数 <code>-XX:+MaxTenuringThreshold</code>），该对象将被晋升为至老年代<br />
OR<br />
单个 <code>Survivor</code> 区已经被占用了 50%（参数: <code>-XX:TargetSurvivorRatio</code>）<br />
复制次数较高的对象也会被晋升至老年代</p>
</blockquote>
<h4 id="比例关系">比例关系</h4>
<p><img src="/_resources/a1c7c6afb050480f99e1060bef7acf60.png" /><br />
默认JVM试图分配最大内存的总内存的<code>1/4</code>,初始化默认总内存为总内存的<code>1/64</code>,年青代中heap的<code>1/3</code>，老年代占<code>2/3</code></p>
<h1 id="总结安装nexus步骤和私有仓库实现">总结安装Nexus步骤和私有仓库实现</h1>
<h2 id="安装">安装</h2>
<div><pre class="hljs"><code><span class="hljs-comment"># 安装要求</span>
<span class="hljs-comment"># 要求内存8G以上，太小比如4G以下会导致无法启动</span>

<span class="hljs-comment"># 下载 (需要外网)</span>
&gt; https://help.sonatype.com/en/download.html
wget https://download.sonatype.com/nexus/3/nexus-3.66.0-02-unix.tar.gz

<span class="hljs-comment"># 解压</span>
tar -xf nexus-3.66.0-02-unix.tar.gz  -C /usr/<span class="hljs-built_in">local</span>/

<span class="hljs-comment"># 链接文件</span>
ln -s /usr/<span class="hljs-built_in">local</span>/nexus-3.66.0-02/ /usr/<span class="hljs-built_in">local</span>/nexus
ln -s /usr/<span class="hljs-built_in">local</span>/nexus/bin/nexus /usr/bin/

<span class="hljs-comment"># 配置</span>
    <span class="hljs-comment">## 运行用户配置</span>
    vim /usr/<span class="hljs-built_in">local</span>/nexus/bin/nexus
    run_as_user=<span class="hljs-string">"root"</span>

    <span class="hljs-comment">## 运行端口配置</span>
    vim /usr/<span class="hljs-built_in">local</span>/nexus/etc/nexus-default.properties
    application-port=8081
    application-host=0.0.0.0
    nexus-args=<span class="hljs-variable">${jetty.etc}</span>/jetty.xml,<span class="hljs-variable">${jetty.etc}</span>/jetty-http.xml,<span class="hljs-variable">${jetty.etc}</span>/jetty-requestlog.xml
    nexus-context-path=/
    ...
    
    <span class="hljs-comment">## JVM 优化配置</span>
    vim /usr/<span class="hljs-built_in">local</span>/nexus/bin/nexus.vmoptions
    -Xms2703m
    -Xmx2703m
    -XX:MaxDirectMemorySize=2703m
    ...</code></pre></div>
<h2 id="运行">运行</h2>
<h3 id="前台运行">前台运行</h3>
<blockquote>
<p>nexus run</p>
<blockquote>
<p>可以看到运行状态，方便确认启动日志</p>
</blockquote>
</blockquote>
<h3 id="后台运行">后台运行</h3>
<blockquote>
<p>nexus start</p>
</blockquote>
<h3 id="关闭运行">关闭运行</h3>
<blockquote>
<p>nexus stop<br />
<img src="/_resources/0221ea55b29e4e1387aba33d12501548.png" /></p>
</blockquote>
<h2 id="配置启动脚本">配置启动脚本</h2>
<ul>
<li>
<p>vim /etc/systemd/system/nexus.service</p>
<div><pre class="hljs"><code>[Unit]
Description=nexus service
After=network.target

[Service]
Type=forking
LimitNOFILE=65536
ExecStart=/usr/<span class="hljs-built_in">local</span>/nexus/bin/nexus start
ExecStop=/usr/<span class="hljs-built_in">local</span>/nexus/bin/nexus stop
User=root
<span class="hljs-comment">#User=nexus</span>
Restart=on-abort

[Install]
WantedBy=multi-user.target</code></pre></div>
</li>
<li>
<p>重新加载daemon</p>
<ul>
<li><code>systemctl daemon-reload</code></li>
</ul>
</li>
</ul>
<h2 id="首次登录">首次登录</h2>
<ul>
<li>查看密码 <code>/usr/local/sonatype-work/nexus3/admin.password</code><br />
<img src="/_resources/1972240e8db94939ac7db5c72e1c8d0d.png" /></li>
<li>登录重置<br />
<img src="/_resources/dc405a5fd5d9490a9fa27c251c420315.png" /></li>
<li>确认访问方式 (默认为匿名登录，生产建议打开匿名访问功能,无需登录就可以下载资源)<br />
<img src="/_resources/e0594bfc6a30485ab8d18ee0a2a1141c.png" /></li>
<li>管理员界面<br />
<img src="/_resources/79e894f0d47b48589dbf0d00a99b6d45.png" /></li>
</ul>
<h2 id="自建apt仓库">自建apt仓库</h2>
<p><img src="/_resources/5fa0ae5854894619aa6713c1453708ea.png" /></p>
<p><img src="/_resources/979e517aa1c54887bc80cd87e482c5cc.png" /></p>
<p><img src="/_resources/b8aee9f49f294db8888b23adc0a420ef.png" /></p>
<p><img src="/_resources/bc9234dbfb554d6889189336eb7ebd08.png" /></p>
<div><pre class="hljs"><code>/etc/apt/sources.list

deb http://192.168.100.121:8081/repository/ubuntu-proxy/ focal main restricted universe multiverse</code></pre></div>
<p><img src="/_resources/795ed58d2e994c278c83138503f49999.png" /></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hello world]]></title>
            <guid>20d5c160bdf84fc19cf99afb20c340dd</guid>
            <pubDate>Sat, 30 Mar 2024 13:51:36 GMT</pubDate>
            <content:encoded><![CDATA[<h1 id="hey">Hey</h1>
<p>This is the first post, testing everyting is ok.<br />
<img src="/_resources/dcfea66944514cff82a8e689c4cbe653.png" /></p>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Byte Byte Go 图]]></title>
            <guid>9ad6880a0e8c46039ae7c1a4c7adec23</guid>
            <pubDate>Sun, 21 Jan 2024 10:08:29 GMT</pubDate>
            <content:encoded><![CDATA[<h1 id="k8s-service-type">K8S service type</h1>
<p><img src="/_resources/ddb262f46b8840d28c216313e7b86daa.png" /></p>
<h1 id="rest-api-design">REST API Design</h1>
<p><img src="/_resources/ca5468c9a25d4ce68bc3f648dd55520f.jpeg" /></p>
<h1 id="top-6-log-parsing-commands">Top 6 log parsing commands</h1>
<p><img src="/_resources/e3e450a0738244f28d356846a0e9d94f.png" /></p>
<h1 id="8-popular-network-protocol">8 popular network protocol</h1>
<p><img src="/_resources/05ed2d25ba8c454fa2227bd553892c66.png" /></p>
<h1 id="sql-execution">SQL execution</h1>
<p><img src="/_resources/f8ee64388c7546b5a2c9afa31e140c3f.png" /></p>
<h1 id="jwt">JWT</h1>
<p><img src="/_resources/558c699e875a4ea8ad78d46df00a305d.png" /></p>
<h1 id="data-structure-power-your-database">data structure power your database</h1>
<p><img src="/_resources/9368ba6228594d29869970cf261b2721.png" /></p>
<h1 id="http-methods">HTTP methods</h1>
<p><img src="/_resources/2678b89f576f40f796c003cc9b976c9b.png" /></p>
<h1 id="linux-directory">Linux directory</h1>
<p><img src="/_resources/7e33fbe5a75f4dc08b4541f5fe7e4696.png" /></p>
<h1 id="when-you-type-url">When you type URL</h1>
<p><img src="/_resources/63a6fd8820a04e479980cf8e4a6d7c88.png" /></p>
<h1 id="forward-proxy-vs-rever-proxy">forward proxy vs rever proxy</h1>
<p><img src="/_resources/936a8886f0994dc288d25f21d0e223c8.png" /></p>
<h1 id="how-https-work">How https work</h1>
<p><img src="/_resources/a6401043babd4d19a5973cb7bbd822a2.png" /></p>
<h1 id="how-does-message-queue-evolve">How does message queue evolve</h1>
<p><img src="/_resources/a8e06fa592a3487d90904681ae5cf68e.png" /></p>
<h1 id="linux-network-tools">Linux network tools</h1>
<p><img src="/_resources/12143acf7a234feeab985017dad35cc7.png" /></p>
<h1 id="linux-boot-process">Linux boot process</h1>
<p><img src="/_resources/c3474e2c84aa48bcb91556e66623920c.png" /></p>
<h1 id="why-k8s">Why k8s</h1>
<p><img src="/_resources/69154c4b84a441be866266de73048132.png" /></p>
<h1 id="top-4-type-of-queus">Top 4 type of queus</h1>
<p><img src="/_resources/96f3ba31621c4090b170204ceaca437f.png" /></p>
<h1 id="defence-of-security-in-linux">Defence of security in linux</h1>
<p><img src="/_resources/bc24264ea2be4f4290a63fe69350725e.png" /></p>
<h1 id="security-search-engine">security search engine</h1>
<p><img src="/_resources/da03376cad4a4dfd827af7cd1eb7299a.png" /></p>
]]></content:encoded>
        </item>
    </channel>
</rss>